<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cognitive Bias Codex</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            padding: 20px;
	    background-color: white;
	    color: red;
            text-align: left;
        }
        h1, h2, h3, h4 {
            margin: 10px 0;
        }
        #summary {
            font-size: x-large;
        }
    </style>
</head>
<body>
    <div id="item-container">
        <h1 id="name"></h1>
        <h1 id="summary"></h1>
        <h1 id="subcategory"></h1>
        <h1 id="category"></h1>
    </div>

    <script>
        // Inline JSON data array (example)
        const data = [
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Availability heuristic",
        "article": "Availability_heuristic",
        "summary": "\u003cp\u003eThe \u003cb\u003eavailability heuristic\u003c/b\u003e, also known as \u003cb\u003eavailability bias\u003c/b\u003e, is a mental shortcut that relies on immediate examples that come to a given person's mind when evaluating a specific topic, concept, method, or decision. This heuristic, operating on the notion that, if something can be recalled, it must be important, or at least more important than alternative solutions not as readily recalled, is inherently biased toward recently acquired information.\n\u003c/p\u003e\u003cp\u003eThe mental availability of an action's consequences is positively related to those consequences' perceived magnitude. In other words, the easier it is to recall the consequences of something, the greater those consequences are often perceived to be. Most notably, people often rely on the content of their recall if its implications are not called into question by the difficulty they have in recalling it.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Attentional bias",
        "article": "Attentional_bias",
        "summary": "\u003cp\u003e\u003cb\u003eAttentional bias\u003c/b\u003e refers to how a person's perception is affected by selective factors in their attention. Attentional biases may explain an individual's failure to consider alternative possibilities when occupied with an existing train of thought. For example, cigarette smokers have been shown to possess an attentional bias for smoking-related cues around them, due to their brain's altered reward sensitivity. Attentional bias has also been associated with clinically relevant symptoms such as anxiety and depression.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Illusory truth effect",
        "article": "Illusory_truth_effect",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\u003cp\u003eThe \u003cb\u003eillusory truth effect\u003c/b\u003e (also known as the \u003cb\u003eillusion of truth effect\u003c/b\u003e, \u003cb\u003evalidity effect\u003c/b\u003e, \u003cb\u003etruth effect\u003c/b\u003e, or the \u003cb\u003ereiteration effect\u003c/b\u003e) is the tendency to believe false information to be correct after repeated exposure. This phenomenon was first identified in a 1977 study at Villanova University and Temple University. When truth is assessed, people rely on whether the information is in line with their understanding or if it feels familiar. The first condition is logical, as people compare new information with what they already know to be true. Repetition makes statements easier to process relative to new, unrepeated statements, leading people to believe that the repeated conclusion is more truthful. The illusory truth effect has also been linked to hindsight bias, in which the recollection of confidence is skewed after the truth has been received.\n\u003c/p\u003e\u003cp\u003eIn a 2012 study, researchers discovered that familiarity can overpower rationality and that repetitively hearing that a certain statement is wrong can paradoxically cause it to feel right. Researchers observed the illusory truth effect's impact even on participants who knew the correct answer to begin with but were persuaded to believe otherwise through the repetition of a falsehood, to \"processing fluency\".\n\u003c/p\u003e\u003cp\u003eThe illusory truth effect plays a significant role in fields such as advertising, news media, and political propaganda.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Mere-exposure effect",
        "article": "Mere-exposure_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003emere-exposure effect\u003c/b\u003e is a psychological phenomenon by which people tend to develop liking or disliking for things merely because they are familiar with them. In social psychology, this effect is sometimes called the \u003cb\u003efamiliarity principle\u003c/b\u003e. The effect has been demonstrated with many kinds of things, including words, Chinese characters, paintings, pictures of faces, geometric figures, and sounds. In studies of interpersonal attraction, the more often people see a person, the more pleasing and likeable they find that person.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Context effect",
        "article": "Context_effect",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\n\n\u003cp\u003eA \u003cb\u003econtext effect\u003c/b\u003e is an aspect of cognitive psychology that describes the influence of environmental factors on one's perception of a stimulus.  The impact of context effects is considered to be part of top-down design.  The concept is supported by the theoretical approach to perception known as constructive perception.  Context effects can impact our daily lives in many ways such as word recognition, learning abilities, memory, and object recognition.  It can have an extensive effect on marketing and consumer decisions.  For example, research has shown that the comfort level of the floor that shoppers are standing on while reviewing products can affect their assessments of product's quality, leading to higher assessments if the floor is comfortable and lower ratings if it is uncomfortable. Because of effects such as this, context effects are currently studied predominantly in marketing.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Cue-dependent forgetting",
        "article": "Cue-dependent_forgetting",
        "summary": "\u003cp\u003e\u003cb\u003eCue-dependent forgetting\u003c/b\u003e, or \u003cb\u003eretrieval failure\u003c/b\u003e, is the failure to recall information without memory \u003ci\u003ecues\u003c/i\u003e. The term either pertains to \u003ci\u003esemantic cues\u003c/i\u003e, \u003ci\u003estate-dependent\u003c/i\u003e cues or \u003ci\u003econtext-dependent\u003c/i\u003e cues.\n\u003c/p\u003e\u003cp\u003eUpon performing a search for files in a computer, its memory is scanned for words. Relevant files containing this word or string of words are displayed. This is \u003ci\u003enot\u003c/i\u003e how memory in the human mind works. Instead, information stored in the memory is retrieved by way of association with other memories. Some memories can not be recalled by simply thinking about them. Rather, one must think about something associated with it.\n\u003c/p\u003e\u003cp\u003eFor example, if someone tries and fails to recollect the memories he had about a vacation he went on, and someone mentions the fact that he hired a classic car during this vacation, this may make him remember all sorts of things from that trip, such as what he ate there, where he went and what books he read.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Mood-congruent memory bias",
        "article": "Mood_congruence",
        "summary": "\u003cp\u003e\u003cb\u003eMood congruence\u003c/b\u003e is the consistency between a person's emotional state with the broader situations and circumstances being experienced by the persons at that time. By contrast, \u003cb\u003emood incongruence\u003c/b\u003e occurs when the individual's reactions or emotional state appear to be in conflict with the situation. In the context of psychosis, hallucinations and delusions may be considered mood congruent (such as feelings of personal inadequacy, guilt, or worthlessness during a bipolar disorder depressive episode) or incongruent.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Frequency illusion",
        "article": "Frequency_illusion",
        "summary": "\u003cp\u003eThe \u003cb\u003efrequency illusion\u003c/b\u003e (also known as the \u003cb\u003eBaader–Meinhof phenomenon\u003c/b\u003e) is a cognitive bias in which a person notices a specific concept, word, or product more frequently after recently becoming aware of it.\n\u003c/p\u003e\u003cp\u003eThe name \"Baader–Meinhof phenomenon\" was coined in 1994 by Terry Mullen in a letter to the \u003ci\u003eSt. Paul Pioneer Press\u003c/i\u003e. The letter describes how, after mentioning the name of the German terrorist group Baader–Meinhof once, he kept noticing it. This led to other readers sharing their own experiences of the phenomenon, leading it to gain recognition. It was not until 2005, when Stanford linguistics professor Arnold Zwicky wrote about this effect on his blog, that the name \"frequency illusion\" was coined.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Baader-Meinhof Phenomenon",
        "article": "Frequency_illusion",
        "summary": "\u003cp\u003eThe \u003cb\u003efrequency illusion\u003c/b\u003e (also known as the \u003cb\u003eBaader–Meinhof phenomenon\u003c/b\u003e) is a cognitive bias in which a person notices a specific concept, word, or product more frequently after recently becoming aware of it.\n\u003c/p\u003e\u003cp\u003eThe name \"Baader–Meinhof phenomenon\" was coined in 1994 by Terry Mullen in a letter to the \u003ci\u003eSt. Paul Pioneer Press\u003c/i\u003e. The letter describes how, after mentioning the name of the German terrorist group Baader–Meinhof once, he kept noticing it. This led to other readers sharing their own experiences of the phenomenon, leading it to gain recognition. It was not until 2005, when Stanford linguistics professor Arnold Zwicky wrote about this effect on his blog, that the name \"frequency illusion\" was coined.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Empathy gap",
        "article": "Empathy_gap",
        "summary": "\u003cp\u003eAn \u003cb\u003eempathy gap\u003c/b\u003e, sometimes referred to as an \u003cb\u003eempathy bias\u003c/b\u003e, is a breakdown or reduction in empathy (the ability to recognize, understand, and share another's thoughts and feelings) where it might otherwise be expected to occur. Empathy gaps may occur due to a failure in the process of empathizing or as a consequence of stable personality characteristics, and may reflect either a lack of ability or motivation to empathize.\n\u003c/p\u003e\u003cp\u003eEmpathy gaps can be interpersonal (toward others) or intrapersonal (toward the self, e.g. when predicting one's own future preferences). A great deal of social psychological research has focused on intergroup empathy gaps, their underlying psychological and neural mechanisms, and their implications for downstream behavior (e.g. prejudice toward outgroup members).\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Omission bias",
        "article": "Omission_bias",
        "summary": "\u003cp\u003e\u003cb\u003eOmission bias\u003c/b\u003e is the phenomenon in which people prefer omission (inaction) over commission (action) and people tend to judge harm as a result of commission more negatively than harm as a result of omission. It can occur due to a number of processes, including psychological inertia, the perception of transaction costs, and the perception that commissions are more causal than omissions. In social political terms the Universal Declaration of Human Rights establishes how basic human rights are to be assessed in article 2, as \"without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status.\" criteria that are often subject to one or another form of omission bias.   It is controversial as to whether omission bias is a cognitive bias or is often rational. The bias is often showcased through the trolley problem and has also been described as an explanation for the endowment effect and status quo bias.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice things already primed in memory or repeated often",
        "name": "Base rate fallacy",
        "article": "Base_rate_fallacy",
        "summary": "\u003cp\u003eThe \u003cb\u003ebase rate fallacy\u003c/b\u003e, also called \u003cb\u003ebase rate neglect\u003c/b\u003e or \u003cb\u003ebase rate bias\u003c/b\u003e, is a type of fallacy in which people tend to ignore the base rate (e.g., general prevalence) in favor of the individuating information (i.e., information pertaining only to a specific case). For example, if someone hears that a friend is very shy and quiet, they might think the friend is more likely to be a librarian than a salesperson, even though there are far more salespeople than librarians overall - hence making it more likely that their friend is actually a salesperson. Base rate neglect is a specific form of the more general extension neglect.\n\u003c/p\u003e\u003cp\u003eIt is also called the \u003cb\u003eprosecutor's fallacy\u003c/b\u003e or \u003cb\u003edefense attorney's fallacy\u003c/b\u003e when applied to the results of statistical tests (such as DNA tests) in the context of law proceedings. These terms were introduced by William C. Thompson and Edward Schumann in 1987, although it has been argued that their definition of the prosecutor's fallacy extends to many additional invalid imputations of guilt or liability that are not analyzable as errors in base rates or Bayes's theorem.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "Bizarre, funny, visually striking, or anthropomorphic things stick out more than non-bizarre/unfunny things",
        "name": "Bizarreness effect",
        "article": "Bizarreness_effect",
        "summary": "\u003cp\u003e\u003cb\u003eBizarreness effect \u003c/b\u003eis the tendency of bizarre material to be better remembered than common material. The scientific evidence for its existence is contested. Some research suggests it does exist, some suggests it doesn't exist and some suggests it leads to worse remembering.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "Bizarre, funny, visually striking, or anthropomorphic things stick out more than non-bizarre/unfunny things",
        "name": "Humor effect",
        "article": "List_of_cognitive_biases#Humor_effect",
        "summary": "\u003cp\u003eCognitive biases are systematic patterns of deviation from norm and/or rationality in judgment. They are often studied in psychology, sociology and behavioral economics.\n\u003c/p\u003e\u003cp\u003eAlthough the reality of most of these biases is confirmed by reproducible research, there are often controversies about how to classify these biases or how to explain them. Several theoretical causes are known for some cognitive biases, which provides a classification of biases by their common generative mechanism (such as noisy information-processing). Gerd Gigerenzer has criticized the framing of cognitive biases as errors in judgment, and favors interpreting them as arising from rational deviations from logical thought.\n\u003c/p\u003e\u003cp\u003eExplanations include information-processing rules (i.e., mental shortcuts), called \u003ci\u003eheuristics\u003c/i\u003e, that the brain uses to produce decisions or judgments. Biases have a variety of forms and appear as cognitive (\"cold\") bias, such as mental noise, or motivational (\"hot\") bias, such as when beliefs are distorted by wishful thinking. Both effects can be present at the same time.\n\u003c/p\u003e\u003cp\u003eThere are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill; a way to establish a connection with the other person.\n\u003c/p\u003e\u003cp\u003eAlthough this research overwhelmingly involves human subjects, some findings that demonstrate bias have been found in non-human animals as well. For example, loss aversion has been shown in monkeys and hyperbolic discounting has been observed in rats, pigeons, and monkeys.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Too Much Information",
        "subcategory": "Bizarre, funny, visually striking, or anthropomorphic things stick out more than non-bizarre/unfunny things",
        "name": "Von Restorff effect",
        "article": "Von_Restorff_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003eVon Restorff effect\u003c/b\u003e, also known as the \"\u003cb\u003eisolation effect\u003c/b\u003e\", predicts that when multiple homogeneous stimuli are presented, the stimulus that differs from the rest is more likely to be remembered. The theory was coined by German psychiatrist and pediatrician Hedwig von Restorff (1906–1962), who, in her 1933 study, found that when participants were presented with a list of categorically similar items with one distinctive, isolated item on the list, memory for the item was improved.\n\u003c/p\u003e\u003cp\u003eThe study utilized the \u003ci\u003eisolation paradigm\u003c/i\u003e, which refers to a distinctive feature of an item in a list that differs from the others by way of dimension. Such distinctiveness, leading to the von Restorff effect, can be generated from changing the meaningfulness or physical nature of the stimulus in some way, such as in size, shape, color, spacing and underlining.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "Bizarre, funny, visually striking, or anthropomorphic things stick out more than non-bizarre/unfunny things",
        "name": "Picture superiority effect",
        "article": "Picture_superiority_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003epicture superiority effect\u003c/b\u003e refers to the phenomenon in which pictures and images are more likely to be remembered than are words. This effect has been demonstrated in numerous experiments using different methods. It is based on the notion that \"human memory is extremely sensitive to the symbolic modality of presentation of event information\". Explanations for the picture superiority effect are not concrete and are still being debated, however an evolutionary explanation is that sight has a long history stretching back millions of years and was crucial to survival in the past, whereas reading is a relatively recent invention, and requires specific cognitive processes, such as decoding symbols and linking them to meaning.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "Bizarre, funny, visually striking, or anthropomorphic things stick out more than non-bizarre/unfunny things",
        "name": "Self-relevance effect",
        "article": "Self-reference_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003eself-reference effect\u003c/b\u003e is a tendency for people to encode information differently depending on whether they are implicated in the information. When people are asked to remember information when it is related in some way to themselves, the recall rate can be improved.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "Bizarre, funny, visually striking, or anthropomorphic things stick out more than non-bizarre/unfunny things",
        "name": "Negativity bias",
        "article": "Negativity_bias",
        "summary": "\u003cp\u003eThe \u003cb\u003enegativity bias\u003c/b\u003e, also known as the \u003cb\u003enegativity effect\u003c/b\u003e, is a cognitive bias that, even when positive or neutral things of equal intensity occur, things of a more negative nature (e.g. unpleasant thoughts, emotions, or social interactions; harmful/traumatic events) have a greater effect on one's psychological state and processes than neutral or positive things.  In other words, something very positive will generally have less of an impact on a person's behavior and cognition than something equally emotional but negative.  The negativity bias has been investigated within many different domains, including the formation of impressions and general evaluations; attention, learning, and memory; and decision-making and risk considerations.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice when something has changed",
        "name": "Anchoring",
        "article": "Anchoring_(cognitive_bias)",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐x5tjl\nCached time: 20240701121954\nCache expiry: 2592000\nReduced expiry: false\nComplications: [is‐preview]\nCPU time usage: 0.003 seconds\nReal time usage: 0.004 seconds\nPreprocessor visited node count: 0/1000000\nPost‐expand include size: 0/2097152 bytes\nTemplate argument size: 0/2097152 bytes\nHighest expansion depth: 0/100\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 0/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%    0.000      1 -total\n--\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice when something has changed",
        "name": "Conservatism",
        "article": "Conservatism_(belief_revision)",
        "summary": "\u003cp\u003eIn cognitive psychology and decision science, \u003cb\u003econservatism\u003c/b\u003e or \u003cb\u003econservatism bias\u003c/b\u003e is a bias  which refers to the tendency to revise one's belief insufficiently when presented with new evidence. This bias describes human belief revision in which people over-weigh the prior distribution (base rate) and under-weigh new sample evidence when compared to Bayesian belief-revision.\n\u003c/p\u003e\u003cp\u003eAccording to the theory, \"opinion change is very orderly, and usually proportional to the numbers of Bayes' theorem – but it is insufficient in amount\". In other words, people update their prior beliefs as new evidence becomes available, but they do so more slowly than they would if they used Bayes' theorem.\n\u003c/p\u003e\u003cp\u003eThis bias was discussed by Ward Edwards in 1968, who reported on experiments like the following one:\n\u003c/p\u003e\n\u003cblockquote\u003e\u003cp\u003eThere are two bookbags, one containing 700 red and 300 blue chips, the other containing 300 red and 700 blue. Take one of the bags. Now, you sample, randomly, with replacement after each chip. In 12 samples, you get 8 reds and 4 blues. what is the probability that this is the predominantly red bag?\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eMost subjects chose an answer around .7. The correct answer according to Bayes' theorem is closer to .97 ( based on Bayes' theorem:\u003cspan\u003e\u003cspan\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {0.7^{8}\\times 0.3^{4}}{0.7^{8}\\times 0.3^{4}+0.3^{8}\\times 0.7^{4}}}}\"\u003e\n  \u003csemantics\u003e\n    \u003cmrow class=\"MJX-TeXAtom-ORD\"\u003e\n      \u003cmstyle displaystyle=\"true\" scriptlevel=\"0\"\u003e\n        \u003cmrow class=\"MJX-TeXAtom-ORD\"\u003e\n          \u003cmfrac\u003e\n            \u003cmrow\u003e\n              \u003cmsup\u003e\n                \u003cmn\u003e0.7\u003c/mn\u003e\n                \u003cmrow class=\"MJX-TeXAtom-ORD\"\u003e\n                  \u003cmn\u003e8\u003c/mn\u003e\n                \u003c/mrow\u003e\n              \u003c/msup\u003e\n              \u003cmo\u003e×\u003c!-- × --\u003e\u003c/mo\u003e\n              \u003cmsup\u003e\n                \u003cmn\u003e0.3\u003c/mn\u003e\n                \u003cmrow class=\"MJX-TeXAtom-ORD\"\u003e\n                  \u003cmn\u003e4\u003c/mn\u003e\n                \u003c/mrow\u003e\n              \u003c/msup\u003e\n            \u003c/mrow\u003e\n            \u003cmrow\u003e\n              \u003cmsup\u003e\n                \u003cmn\u003e0.7\u003c/mn\u003e\n                \u003cmrow class=\"MJX-TeXAtom-ORD\"\u003e\n                  \u003cmn\u003e8\u003c/mn\u003e\n                \u003c/mrow\u003e\n              \u003c/msup\u003e\n              \u003cmo\u003e×\u003c!-- × --\u003e\u003c/mo\u003e\n              \u003cmsup\u003e\n                \u003cmn\u003e0.3\u003c/mn\u003e\n                \u003cmrow class=\"MJX-TeXAtom-ORD\"\u003e\n                  \u003cmn\u003e4\u003c/mn\u003e\n                \u003c/mrow\u003e\n              \u003c/msup\u003e\n              \u003cmo\u003e+\u003c/mo\u003e\n              \u003cmsup\u003e\n                \u003cmn\u003e0.3\u003c/mn\u003e\n                \u003cmrow class=\"MJX-TeXAtom-ORD\"\u003e\n                  \u003cmn\u003e8\u003c/mn\u003e\n                \u003c/mrow\u003e\n              \u003c/msup\u003e\n              \u003cmo\u003e×\u003c!-- × --\u003e\u003c/mo\u003e\n              \u003cmsup\u003e\n                \u003cmn\u003e0.7\u003c/mn\u003e\n                \u003cmrow class=\"MJX-TeXAtom-ORD\"\u003e\n                  \u003cmn\u003e4\u003c/mn\u003e\n                \u003c/mrow\u003e\n              \u003c/msup\u003e\n            \u003c/mrow\u003e\n          \u003c/mfrac\u003e\n        \u003c/mrow\u003e\n      \u003c/mstyle\u003e\n    \u003c/mrow\u003e\n    \u003cannotation encoding=\"application/x-tex\"\u003e{\\displaystyle {\\frac {0.7^{8}\\times 0.3^{4}}{0.7^{8}\\times 0.3^{4}+0.3^{8}\\times 0.7^{4}}}}\u003c/annotation\u003e\n  \u003c/semantics\u003e\n\u003c/math\u003e\u003c/span\u003e\u003c/span\u003e). Edwards suggested that people updated beliefs conservatively, in accordance with Bayes' theorem, but more slowly. They updated from .5 incorrectly according to an observed bias in several experiments.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice when something has changed",
        "name": "Contrast effect",
        "article": "Contrast_effect",
        "summary": "\u003cp\u003eA \u003cb\u003econtrast effect\u003c/b\u003e is the enhancement or diminishment, relative to normal, of perception, cognition or related performance as a result of successive (immediately previous) or simultaneous exposure to a stimulus of lesser or greater value in the same dimension. (Here, normal perception, cognition or performance is that which would be obtained in the absence of the comparison stimulus—i.e., one based on all previous experience.)\n\u003c/p\u003e\u003cp\u003ePerception example: A neutral gray target will appear lighter or darker than it does in isolation when immediately preceded by, or simultaneously compared to, respectively, a dark gray or light gray target.\n\u003c/p\u003e\u003cp\u003eCognition example: A person will appear more or less attractive than that person does in isolation when immediately preceded by, or simultaneously compared to, respectively, a less or more attractive person.\n\u003c/p\u003e\u003cp\u003ePerformance example: A laboratory rat will work faster, or slower, during a stimulus predicting a given amount of reward when that stimulus and reward are immediately preceded by, or alternated with, respectively, different stimuli associated with either a lesser or greater amount of reward.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice when something has changed",
        "name": "Distinction bias",
        "article": "Distinction_bias",
        "summary": "\u003cp\u003e\u003cb\u003eDistinction bias\u003c/b\u003e, a concept of decision theory, is the tendency to view two options as more distinctive when evaluating them simultaneously than when evaluating them separately.\n\u003c/p\u003e\u003cp\u003eOne writer has presented what he called \"a simplistic view\" of distinction bias: When asked if someone would like an apple, they may say \"Yes\". So, an apple is placed before them and they begin to eat it and are happy. But what if two apples were placed on the table - one was the one they would have happily eaten and the other which is slightly fresher looking. The individual will choose the fresher apple and eat it and be happy but if asked, \"would you have enjoyed eating that other apple\", they would likely say \"No\". Even though in the alternate, no-choice reality they were perfectly happy with the apple. Moreover, if presented with five apples on a table, they might examine each apple so that they would be sure they had the best one, even though the time spent making that decision would be wasted. The reason for this is that distinction bias causes individuals to \"over-examine and over-value the differences between things as we scrutinize them.\"\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice when something has changed",
        "name": "Focusing effect",
        "article": "Anchoring#Focusing_effect",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐m8rqx\nCached time: 20240701121955\nCache expiry: 2592000\nReduced expiry: false\nComplications: [is‐preview]\nCPU time usage: 0.003 seconds\nReal time usage: 0.003 seconds\nPreprocessor visited node count: 0/1000000\nPost‐expand include size: 0/2097152 bytes\nTemplate argument size: 0/2097152 bytes\nHighest expansion depth: 0/100\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 0/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%    0.000      1 -total\n--\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice when something has changed",
        "name": "Framing effect",
        "article": "Framing_effect_(psychology)",
        "summary": "\u003cp\u003eThe \u003cb\u003eframing effect\u003c/b\u003e is a cognitive bias in which people decide between options based on whether the options are presented with positive or negative connotations. Individuals have a tendency to make risk-avoidant choices when options are positively framed, while selecting more loss-avoidant options when presented with a negative frame. In studies of the bias, options are presented in terms of the probability of either losses or gains. While differently expressed, the options described are in effect identical. Gain and loss are defined in the scenario as descriptions of outcomes, for example, lives lost or saved, patients treated or not treated, monetary gains or losses.\n\u003c/p\u003e\u003cp\u003eProspect theory posits that a loss is more significant than the equivalent gain, that a sure gain (certainty effect and pseudocertainty effect) is favored over a probabilistic gain, and that a probabilistic loss is preferred to a definite loss. One of the dangers of framing effects is that people are often provided with options within the context of only one of the two frames.\n\u003c/p\u003e\u003cp\u003eThe concept helps to develop an understanding of frame analysis within social movements, and also in the formation of political opinion where spin plays a large role in political opinion polls that are framed to encourage a response beneficial to the organization that has commissioned the poll. It has been suggested that the use of the technique is discrediting political polls themselves. The effect is reduced, or even eliminated, if ample credible information is provided to people.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice when something has changed",
        "name": "Money illusion",
        "article": "Money_illusion",
        "summary": "\u003cp\u003eIn economics, \u003cb\u003emoney illusion\u003c/b\u003e, or \u003cb\u003eprice illusion\u003c/b\u003e, is a cognitive bias where money is thought of in nominal, rather than real terms. In other words, the face value (nominal value) of money is mistaken for its purchasing power (real value) at a previous point in time. Viewing purchasing power as measured by the nominal value is false, as modern fiat currencies have no intrinsic value and their real value depends purely on the price level. The term was coined by Irving Fisher in \u003ci\u003eStabilizing the Dollar\u003c/i\u003e. It was popularized by John Maynard Keynes in the early twentieth century, and Irving Fisher wrote an important book on the subject, \u003ci\u003eThe Money Illusion\u003c/i\u003e, in 1928.\n\u003c/p\u003e\u003cp\u003eThe existence of money illusion is disputed by monetary economists  who contend that people act rationally (i.e. think in real prices) with regard to their wealth. Eldar Shafir, Peter A. Diamond, and Amos Tversky (1997) have provided  empirical evidence for the existence of the effect and it has been shown to affect behaviour in a variety of experimental and real-world situations.\n\u003c/p\u003e\u003cp\u003eShafir et al. also state that money illusion influences economic behaviour in three main ways:\n\u003c/p\u003e\n\u003cul\u003e\u003cli\u003ePrice stickiness. Money illusion has been proposed as one reason why nominal prices are slow to change even where inflation has caused real prices to fall or costs to rise.\u003c/li\u003e\n\u003cli\u003eContracts and laws are not indexed to inflation as frequently as one would rationally expect.\u003c/li\u003e\n\u003cli\u003eSocial discourse, in formal media and more generally, reflects some confusion about real and nominal value.\u003c/li\u003e\u003c/ul\u003e\n\u003cp\u003eMoney illusion can also influence people's perceptions of outcomes. Experiments have shown that people generally perceive an approximate 2% cut in nominal income with no change in monetary value as unfair, but see a 2% rise in nominal income where there is 4% inflation as fair, despite them being almost rational equivalents. This result is consistent with the 'Myopic Loss Aversion theory'. Furthermore, the money illusion means nominal changes in price can influence demand even if real prices have remained constant.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice when something has changed",
        "name": "Weber-Fechner law",
        "article": "Weber-Fechner_law",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐kljxr\nCached time: 20240701121955\nCache expiry: 2592000\nReduced expiry: false\nComplications: [is‐preview]\nCPU time usage: 0.050 seconds\nReal time usage: 0.064 seconds\nPreprocessor visited node count: 206/1000000\nPost‐expand include size: 10596/2097152 bytes\nTemplate argument size: 759/2097152 bytes\nHighest expansion depth: 7/100\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 0/5000000 bytes\nLua time usage: 0.010/10.000 seconds\nLua memory usage: 627499/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%   48.406      1 Template:R_from_modification\n100.00%   48.406      1 -total\n 93.75%   45.381      1 Template:Redirect_template\n 19.03%    9.212     11 Template:Tl\n  5.94%    2.874     22 Template:Nowrap\n  4.90%    2.374      1 Template:Em\n--\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Confirmation bias",
        "article": "Confirmation_bias",
        "summary": "\u003cp\u003e\n\n\u003cb\u003eConfirmation bias\u003c/b\u003e (also \u003cb\u003econfirmatory bias\u003c/b\u003e, \u003cb\u003emyside bias\u003c/b\u003e, or \u003cb\u003econgeniality bias\u003c/b\u003e) is the tendency to search for, interpret, favor, and recall information in a way that confirms or supports one's prior beliefs or values. People display this bias when they select information that supports their views, ignoring contrary information, or when they interpret ambiguous evidence as supporting their existing attitudes. The effect is strongest for desired outcomes, for emotionally charged issues, and for deeply entrenched beliefs. Confirmation bias is insuperable for most people, but they can manage it, for example, by education and training in critical thinking skills.\n\u003c/p\u003e\u003cp\u003eBiased search for information, biased interpretation of this information, and biased memory recall, have been invoked to explain four specific effects:\n\u003c/p\u003e\n\u003col\u003e\u003cli\u003e\u003ci\u003eattitude polarization\u003c/i\u003e (when a disagreement becomes more extreme even though the different parties are exposed to the same evidence)\u003c/li\u003e\n\u003cli\u003e\u003ci\u003ebelief perseverance\u003c/i\u003e (when beliefs persist after the evidence for them is shown to be false)\u003c/li\u003e\n\u003cli\u003ethe \u003ci\u003eirrational primacy effect\u003c/i\u003e (a greater reliance on information encountered early in a series)\u003c/li\u003e\n\u003cli\u003e\u003ci\u003eillusory correlation\u003c/i\u003e (when people falsely perceive an association between two events or situations).\u003c/li\u003e\u003c/ol\u003e\n\u003cp\u003eA series of psychological experiments in the 1960s suggested that people are biased toward confirming their existing beliefs. Later work re-interpreted these results as a tendency to test ideas in a one-sided way, focusing on one possibility and ignoring alternatives. Explanations for the observed biases include wishful thinking and the limited human capacity to process information. Another proposal is that people show confirmation bias because they are pragmatically assessing the costs of being wrong, rather than investigating in a neutral, scientific way.\n\u003c/p\u003e\u003cp\u003eFlawed decisions due to confirmation bias have been found in a wide range of political, organizational, financial and scientific contexts. These biases contribute to overconfidence in personal beliefs and can maintain or strengthen beliefs in the face of contrary evidence. For example, confirmation bias produces systematic errors in scientific research based on inductive reasoning (the gradual accumulation of supportive evidence). Similarly, a police detective may identify a suspect early in an investigation, but then may only seek confirming rather than disconfirming evidence. A medical practitioner may prematurely focus on a particular disorder early in a diagnostic session, and then seek only confirming evidence. In social media, confirmation bias is amplified by the use of filter bubbles, or \"algorithmic editing\", which display to individuals only information they are likely to agree with, while excluding opposing views.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Congruence bias",
        "article": "Congruence_bias",
        "summary": "\u003cp\u003e\u003cb\u003eCongruence bias\u003c/b\u003e is the tendency of people to over-rely on testing their initial hypothesis (the most \u003ci\u003econgruent\u003c/i\u003e one) while neglecting to test alternative hypotheses. That is, people rarely try experiments that could disprove their initial belief, but rather try to repeat their initial results. It is a special case of the confirmation bias.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Post-purchase rationalization",
        "article": "Choice-supportive_bias",
        "summary": "\u003cp\u003e\u003cb\u003eChoice-supportive bias\u003c/b\u003e or \u003cb\u003epost-purchase rationalization\u003c/b\u003e is the tendency to retroactively ascribe positive attributes to an option one has selected and/or to demote the forgone options. It is part of cognitive science, and is a distinct cognitive bias that occurs once a decision is made. For example, if a person chooses option A instead of option B, they are likely to ignore or downplay the faults of option A while amplifying or ascribing new negative faults to option B. Conversely, they are also likely to notice and amplify the advantages of option A and not notice or de-emphasize those of option B.\n\u003c/p\u003e\u003cp\u003eWhat is remembered about a decision can be as important as the decision itself, especially in determining how much regret or satisfaction one experiences. Research indicates that the process of making and remembering choices yields memories that tend to be distorted in predictable ways.\n\u003c/p\u003e\u003cp\u003eIn cognitive science, one predictable way that memories of choice options are distorted is that positive aspects tend to be remembered as part of the chosen option, whether or not they originally were part of that option, and negative aspects tend to be remembered as part of rejected options. Once an action has been taken, the ways in which we evaluate the effectiveness of what we did may be biased. It is believed this may influence our future decision-making. These biases may be stored as memories, which are attributions that we make about our mental experiences based on their subjective qualities, our prior knowledge and beliefs, our motives and goals, and the social context. True and false memories arise by the same mechanism because when the brain processes and stores information, it cannot tell the difference where they came from.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Choice-supportive bias",
        "article": "Choice-supportive_bias",
        "summary": "\u003cp\u003e\u003cb\u003eChoice-supportive bias\u003c/b\u003e or \u003cb\u003epost-purchase rationalization\u003c/b\u003e is the tendency to retroactively ascribe positive attributes to an option one has selected and/or to demote the forgone options. It is part of cognitive science, and is a distinct cognitive bias that occurs once a decision is made. For example, if a person chooses option A instead of option B, they are likely to ignore or downplay the faults of option A while amplifying or ascribing new negative faults to option B. Conversely, they are also likely to notice and amplify the advantages of option A and not notice or de-emphasize those of option B.\n\u003c/p\u003e\u003cp\u003eWhat is remembered about a decision can be as important as the decision itself, especially in determining how much regret or satisfaction one experiences. Research indicates that the process of making and remembering choices yields memories that tend to be distorted in predictable ways.\n\u003c/p\u003e\u003cp\u003eIn cognitive science, one predictable way that memories of choice options are distorted is that positive aspects tend to be remembered as part of the chosen option, whether or not they originally were part of that option, and negative aspects tend to be remembered as part of rejected options. Once an action has been taken, the ways in which we evaluate the effectiveness of what we did may be biased. It is believed this may influence our future decision-making. These biases may be stored as memories, which are attributions that we make about our mental experiences based on their subjective qualities, our prior knowledge and beliefs, our motives and goals, and the social context. True and false memories arise by the same mechanism because when the brain processes and stores information, it cannot tell the difference where they came from.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Selective perception",
        "article": "Selective_perception",
        "summary": "\u003cp\u003e\u003cb\u003eSelective perception\u003c/b\u003e is the tendency not to notice and more quickly forget stimuli that cause emotional discomfort and contradict prior beliefs. For example, a teacher may have a favorite student because they are biased by in-group favoritism. The teacher ignores the student's poor attainment. Conversely, they might not notice the progress of their least favorite student. It can also occur when consuming mass media, allowing people to see facts and opinions they like while ignoring those that do not fit with particular opinions, values, beliefs, or frame of reference. Psychologists believe this process occurs automatically.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Observer-expectancy effect",
        "article": "Observer-expectancy_effect",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\n\u003cp\u003eThe \u003cb\u003eobserver-expectancy effect\u003c/b\u003e is a form of reactivity in which a researcher's cognitive bias causes them to subconsciously influence the participants of an experiment. Confirmation bias can lead to the experimenter interpreting results incorrectly because of the tendency to look for information that conforms to their hypothesis, and overlook information that argues against it. It is a significant threat to a study's internal validity, and is therefore typically controlled using a double-blind experimental design.\n\u003c/p\u003e\u003cp\u003eIt may include conscious or unconscious influences on subject behavior including creation of demand characteristics that influence subjects, and altered or selective recording of experimental results themselves.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Experimenter's bias",
        "article": "Observer-expectancy_effect",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\n\u003cp\u003eThe \u003cb\u003eobserver-expectancy effect\u003c/b\u003e is a form of reactivity in which a researcher's cognitive bias causes them to subconsciously influence the participants of an experiment. Confirmation bias can lead to the experimenter interpreting results incorrectly because of the tendency to look for information that conforms to their hypothesis, and overlook information that argues against it. It is a significant threat to a study's internal validity, and is therefore typically controlled using a double-blind experimental design.\n\u003c/p\u003e\u003cp\u003eIt may include conscious or unconscious influences on subject behavior including creation of demand characteristics that influence subjects, and altered or selective recording of experimental results themselves.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Observer effect",
        "article": "Observer-expectancy_effect",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\n\u003cp\u003eThe \u003cb\u003eobserver-expectancy effect\u003c/b\u003e is a form of reactivity in which a researcher's cognitive bias causes them to subconsciously influence the participants of an experiment. Confirmation bias can lead to the experimenter interpreting results incorrectly because of the tendency to look for information that conforms to their hypothesis, and overlook information that argues against it. It is a significant threat to a study's internal validity, and is therefore typically controlled using a double-blind experimental design.\n\u003c/p\u003e\u003cp\u003eIt may include conscious or unconscious influences on subject behavior including creation of demand characteristics that influence subjects, and altered or selective recording of experimental results themselves.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Expectation bias",
        "article": "Observer-expectancy_effect",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\n\u003cp\u003eThe \u003cb\u003eobserver-expectancy effect\u003c/b\u003e is a form of reactivity in which a researcher's cognitive bias causes them to subconsciously influence the participants of an experiment. Confirmation bias can lead to the experimenter interpreting results incorrectly because of the tendency to look for information that conforms to their hypothesis, and overlook information that argues against it. It is a significant threat to a study's internal validity, and is therefore typically controlled using a double-blind experimental design.\n\u003c/p\u003e\u003cp\u003eIt may include conscious or unconscious influences on subject behavior including creation of demand characteristics that influence subjects, and altered or selective recording of experimental results themselves.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Ostrich effect",
        "article": "Ostrich_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003eostrich effect\u003c/b\u003e, also known as the \u003cb\u003eostrich problem\u003c/b\u003e, was originally coined by Galai \u0026amp; Sade (2003). The name comes from the common (but false) legend that ostriches bury their heads in the sand to avoid danger. This effect is a cognitive bias where people tend to “bury their head in the sand” and avoid potentially negative but useful information, such as feedback on progress, to avoid psychological discomfort.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Subjective validation",
        "article": "Subjective_validation",
        "summary": "\u003cp\u003e\u003cb\u003eSubjective validation\u003c/b\u003e, sometimes called \u003cb\u003epersonal validation effect\u003c/b\u003e, is a cognitive bias by which people will consider a statement or another piece of information to be correct if it has any personal meaning or significance to them. People whose opinion is affected by subjective validation will perceive two unrelated events (i.e., a coincidence) to be related because their personal beliefs demand that they be related. Closely related to the Forer effect, subjective validation is an important element in cold reading. It is considered to be the main reason behind most reports of paranormal phenomena. According to Bob Carroll, psychologist Ray Hyman is considered to be the foremost expert on cold reading.\n\u003c/p\u003e\u003cp\u003eThe term \u003ci\u003esubjective validation\u003c/i\u003e first appeared in the 1980 book \u003ci\u003eThe Psychology of the Psychic\u003c/i\u003e by David F. Marks and Richard Kammann.\n\u003c/p\u003e\u003cp\u003eSubjective validation describes the tendency of people to believe or accept an idea or statement if it presents to them in a personal and positive way. An example of subjective validation can be found in horoscopes, which often make vague, easily generalized personal statements, sometimes referred to as \"Barnum statements\", designed to apply to nearly any individual, such as: \"You have a great deal of unused capacity, which you have not turned to your advantage.\" This can cause one to attribute future success to the horoscope and feel as if their belief in it has been validated. In essence, subjective validation is a confirmation bias towards information that personally benefits one's self-esteem.\n\u003c/p\u003e\u003cp\u003eMany of the validations that are given are not necessarily because they are true about recipients but because people wish it was true about themselves; people tend to think of themselves in terms of values that are important to them, even if they don't show those values. They tend to believe they do, and they tend to believe it the more they hear it and read it about themselves.\n\u003c/p\u003e\u003cp\u003eThis effect can be seen when it comes to health. For example, if someone enjoys eating bacon and they were to come across an article that talks about bacon being healthy, they will tend to believe it more because this \"validates\" eating more bacon.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Continued influence effect",
        "article": "Confirmation_bias#continued_influence_effect",
        "summary": "\u003cp\u003e\n\n\u003cb\u003eConfirmation bias\u003c/b\u003e (also \u003cb\u003econfirmatory bias\u003c/b\u003e, \u003cb\u003emyside bias\u003c/b\u003e, or \u003cb\u003econgeniality bias\u003c/b\u003e) is the tendency to search for, interpret, favor, and recall information in a way that confirms or supports one's prior beliefs or values. People display this bias when they select information that supports their views, ignoring contrary information, or when they interpret ambiguous evidence as supporting their existing attitudes. The effect is strongest for desired outcomes, for emotionally charged issues, and for deeply entrenched beliefs. Confirmation bias is insuperable for most people, but they can manage it, for example, by education and training in critical thinking skills.\n\u003c/p\u003e\u003cp\u003eBiased search for information, biased interpretation of this information, and biased memory recall, have been invoked to explain four specific effects:\n\u003c/p\u003e\n\u003col\u003e\u003cli\u003e\u003ci\u003eattitude polarization\u003c/i\u003e (when a disagreement becomes more extreme even though the different parties are exposed to the same evidence)\u003c/li\u003e\n\u003cli\u003e\u003ci\u003ebelief perseverance\u003c/i\u003e (when beliefs persist after the evidence for them is shown to be false)\u003c/li\u003e\n\u003cli\u003ethe \u003ci\u003eirrational primacy effect\u003c/i\u003e (a greater reliance on information encountered early in a series)\u003c/li\u003e\n\u003cli\u003e\u003ci\u003eillusory correlation\u003c/i\u003e (when people falsely perceive an association between two events or situations).\u003c/li\u003e\u003c/ol\u003e\n\u003cp\u003eA series of psychological experiments in the 1960s suggested that people are biased toward confirming their existing beliefs. Later work re-interpreted these results as a tendency to test ideas in a one-sided way, focusing on one possibility and ignoring alternatives. Explanations for the observed biases include wishful thinking and the limited human capacity to process information. Another proposal is that people show confirmation bias because they are pragmatically assessing the costs of being wrong, rather than investigating in a neutral, scientific way.\n\u003c/p\u003e\u003cp\u003eFlawed decisions due to confirmation bias have been found in a wide range of political, organizational, financial and scientific contexts. These biases contribute to overconfidence in personal beliefs and can maintain or strengthen beliefs in the face of contrary evidence. For example, confirmation bias produces systematic errors in scientific research based on inductive reasoning (the gradual accumulation of supportive evidence). Similarly, a police detective may identify a suspect early in an investigation, but then may only seek confirming rather than disconfirming evidence. A medical practitioner may prematurely focus on a particular disorder early in a diagnostic session, and then seek only confirming evidence. In social media, confirmation bias is amplified by the use of filter bubbles, or \"algorithmic editing\", which display to individuals only information they are likely to agree with, while excluding opposing views.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We are drawn to details that confirm our own existing beliefs",
        "name": "Semmelweis reflex",
        "article": "Semmelweis_reflex",
        "summary": "\u003cp\u003eThe \u003cb\u003eSemmelweis reflex\u003c/b\u003e or \"\u003cb\u003eSemmelweis effect\u003c/b\u003e\" is a metaphor for the reflex-like tendency to reject new evidence or new knowledge because it contradicts established norms, beliefs, or paradigms.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice flaws in others more easily than we notice flaws in ourselves",
        "name": "Bias blind spot",
        "article": "Bias_blind_spot",
        "summary": "\u003cp\u003eThe \u003cb\u003ebias blind spot\u003c/b\u003e is the cognitive bias of recognizing the impact of biases on the judgment of others, while failing to see the impact of biases on one's own judgment. The term was created by Emily Pronin, a social psychologist from Princeton University's Department of Psychology, with colleagues Daniel Lin and Lee Ross. The bias blind spot is named after the visual blind spot. Most people appear to exhibit the bias blind spot. In a sample of more than 600 residents of the United States, more than 85% believed they were less biased than the average American. Only one participant believed that they were more biased than the average American. People do vary with regard to the extent to which they exhibit the bias blind spot. This phenomenon has been successfully replicated and it appears that in general, stronger personal free will beliefs are associated with bias blind spot. It appears to be a stable individual difference that is measurable.\n\u003c/p\u003e\u003cp\u003eThe bias blind spot appears to be a true blind spot in that it is unrelated to actual decision making ability. Performance on indices of decision making competence are not related to individual differences in bias blind spot. In other words, most people appear to believe that they are less biased than others, regardless of their actual decision making ability.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice flaws in others more easily than we notice flaws in ourselves",
        "name": "Naïve cynicism",
        "article": "Naïve_cynicism",
        "summary": "\u003cp\u003e\u003cb\u003eNaïve cynicism\u003c/b\u003e is a philosophy of mind, cognitive bias and form of psychological egoism that occurs when people naïvely expect more egocentric bias in others than actually is the case.\n\u003c/p\u003e\n\n\u003cp\u003eThe term was formally proposed by Justin Kruger and Thomas Gilovich and has been studied across a wide range of contexts including: negotiations, group-membership, marriage, economics, government policy and more.\n\u003c/p\u003e"
    },
    {
        "category": "Too Much Information",
        "subcategory": "We notice flaws in others more easily than we notice flaws in ourselves",
        "name": "Naïve realism",
        "article": "Naïve_realism_(psychology)",
        "summary": "\u003cp\u003eIn social psychology, \u003cb\u003enaïve realism\u003c/b\u003e is the human tendency to believe that we see the world around us objectively, and that people who disagree with us must be uninformed, irrational, or biased.\n\u003c/p\u003e\u003cp\u003eNaïve realism provides a theoretical basis for several other cognitive biases, which are systematic errors when it comes to thinking and making decisions. These include the false consensus effect, actor–observer bias, bias blind spot, and fundamental attribution error, among others.\n\u003c/p\u003e\u003cp\u003eThe term, as it is used in psychology today, was coined by social psychologist Lee Ross and his colleagues in the 1990s. It is related to the philosophical concept of naïve realism, which is the idea that our senses allow us to perceive objects directly and without any intervening processes. Social psychologists in the mid-20th century argued against this stance and proposed instead that perception is inherently subjective.\n\u003c/p\u003e\u003cp\u003eSeveral prominent social psychologists have studied naïve realism experimentally, including Lee Ross, Andrew Ward, Dale Griffin, Emily Pronin, Thomas Gilovich, Robert Robinson, and Dacher Keltner. In 2010, the \u003ci\u003eHandbook of Social Psychology\u003c/i\u003e recognized naïve realism as one of \"four hard-won insights about human perception, thinking, motivation and behavior that ... represent important, indeed foundational, contributions of social psychology.\"\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Confabulation",
        "article": "Confabulation",
        "summary": "\u003cp\u003eIn psychology, \u003cb\u003econfabulation\u003c/b\u003e is a memory error consisting of the production of fabricated, distorted, or misinterpreted memories about oneself or the world. It is generally associated with certain types of brain damage (especially aneurysm in the anterior communicating artery) or a specific subset of dementias. While still an area of ongoing research, the basal forebrain is implicated in the phenomenon of confabulation. People who confabulate present with incorrect memories ranging from subtle inaccuracies to surreal fabrications, and may include confusion or distortion in the temporal framing (timing, sequence or duration) of memories. In general, they are very confident about their recollections, even when challenged with contradictory evidence.\n\u003c/p\u003e\u003cp\u003eConfabulation occurs when individuals mistakenly recall false information, without intending to deceive. Brain damage, dementia, and anticholinergic toxidrome can cause this distortion. Two types of confabulation exist: provoked and spontaneous, with two distinctions: verbal and behavioral. Verbal statements, false information, and the patient's unawareness of the distortion are all associated with this phenomenon. Personality structure also plays a role in confabulation.\n\u003c/p\u003e\u003cp\u003eNumerous theories have been developed to explain confabulation. Neuro­psycho­log­i­cal theories suggest that cognitive dysfunction causes the distortion. Self-identity theories posit that people confabulate to preserve themselves. The temporality theory believes that confabulation occurs when an individual cannot place events properly in time. The monitoring and strategic retrieval account theories argue that confabulation arises when individuals cannot recall memories correctly or monitor them after retrieval. The executive control and fuzzy-trace theories also attempt to explain why confabulation happens.\n\u003c/p\u003e\u003cp\u003eConfabulation can occur with nervous system injuries or illnesses, including Korsakoff's syndrome, Alzheimer's disease, schizophrenia, and traumatic brain injury. It is believed that the right frontal lobe of the brain is damaged, causing false memories. Children are especially susceptible to forced confabulation as they are highly impressionable. Feedback can increase confidence in false memories. In rare cases, confabulation occurs in ordinary individuals.\n\u003c/p\u003e\u003cp\u003eDifferent memory tests, including recognition tasks and free recall tasks, can be used to study confabulation. Treatment depends on the underlying cause of the distortion. Ongoing research aims to develop a standard test battery to discern between different types of confabulations, distinguish delusions from confabulations, understand the role of unconscious processes, and identify pathological and nonpathological confabulations.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Clustering illusion",
        "article": "Clustering_illusion",
        "summary": "\u003cp\u003eThe \u003cb\u003eclustering illusion\u003c/b\u003e is the tendency to erroneously consider the inevitable \"streaks\" or \"clusters\" arising in small samples from random distributions to be non-random. The illusion is caused by a human tendency to underpredict the amount of variability likely to appear in a small sample of random or pseudorandom data.\n\u003c/p\u003e\n\n\u003cp\u003eThomas Gilovich, an early author on the subject, argued that the effect occurs for different types of random dispersions. Some might perceive patterns in stock market price fluctuations over time, or clusters in two-dimensional data such as the locations of impact of World War II V-1 flying bombs on maps of London. Although Londoners developed specific theories about the pattern of impacts within London, a statistical analysis by R. D. Clarke originally published in 1946 showed that the impacts of V-2 rockets on London were a close fit to a random distribution.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Insensitivity to sample size",
        "article": "Insensitivity_to_sample_size",
        "summary": "\u003cp\u003e\u003cb\u003eInsensitivity to sample size\u003c/b\u003e is a cognitive bias that occurs when people judge the probability of obtaining a sample statistic without respect to the sample size. For example, in one study, subjects assigned the same probability to the likelihood of obtaining a mean height of above six feet [183 cm] in samples of 10, 100, and 1,000 men. In other words, variation is more likely in smaller samples, but people may not expect this.\n\u003c/p\u003e\u003cp\u003eIn another example, Amos Tversky and Daniel Kahneman asked subjects\n\u003c/p\u003e\n\u003cblockquote\u003e\u003cp\u003eA certain town is served by two hospitals. In the larger hospital about 45 babies are born each day, and in the smaller hospital about 15 babies are born each day. As you know, about 50% of all babies are boys. However, the exact percentage varies from day to day. Sometimes it may be higher than 50%, sometimes lower.\n\u003c/p\u003e\u003cp\u003eFor a period of 1 year, each hospital recorded the days on which more than 60% of the babies born were boys. Which hospital do you think recorded more such days?\n\u003c/p\u003e\n\u003col\u003e\u003cli\u003eThe larger hospital\u003c/li\u003e\n\u003cli\u003eThe smaller hospital\u003c/li\u003e\n\u003cli\u003eAbout the same (that is, within 5% of each other) \u003c/li\u003e\u003c/ol\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e56% of subjects chose option 3, and 22% of subjects respectively chose options 1 or 2. However, according to sampling theory the larger hospital is much more likely to report a sex ratio close to 50% on a given day than the smaller hospital which requires that the correct answer to the question is the smaller hospital (see the law of large numbers).\n\u003c/p\u003e\u003cp\u003eRelative neglect of sample size were obtained in a different study of statistically sophisticated psychologists.\n\u003c/p\u003e\u003cp\u003eTversky and Kahneman explained these results as being caused by the representativeness heuristic, according to which people intuitively judge samples as having similar properties to their population without taking other considerations into effect. A related bias is the clustering illusion, in which people under-expect streaks or runs in small samples. Insensitivity to sample size is a subtype of extension neglect.\n\u003c/p\u003e\u003cp\u003eTo illustrate this point, Howard Wainer and Harris L. Zwerling demonstrated that kidney cancer rates are lowest in counties that are mostly rural, sparsely populated, and located in traditionally Republican states in the Midwest, the South, and the West, but that they are also \u003ci\u003ehighest\u003c/i\u003e in counties that are mostly rural, sparsely populated, and located in traditionally Republican states in the Midwest, the South, and the West. While various environmental and economic reasons could be advanced for these facts, Wainer and Zwerlig argue that this is an artifact of sample size.  Because of the small sample size, the incidence of a certain kind of cancer in small rural counties is more likely to be further from the mean, in one direction or another, than the incidence of the same kind of cancer in much more heavily populated urban counties.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Neglect of probability",
        "article": "Neglect_of_probability",
        "summary": "\u003cp\u003eThe \u003cb\u003eneglect of probability\u003c/b\u003e, a type of cognitive bias, is the tendency to disregard probability when making a decision under uncertainty and is one simple way in which people regularly violate the normative rules for decision making. Small risks are typically either neglected entirely or hugely overrated. The continuum between the extremes is ignored. The term \u003cb\u003eprobability neglect\u003c/b\u003e was coined by Cass Sunstein.\n\u003c/p\u003e\u003cp\u003eThere are many related ways in which people violate the normative rules of decision making with regard to probability including the hindsight bias, the neglect of prior base rates effect, and the gambler's fallacy. However, this bias is different, in that, rather than incorrectly using probability, the actor disregards it.\n\u003c/p\u003e\u003cp\u003e\"We have no intuitive grasp of risk and thus distinguish poorly among different threats,\" Dobelli has written. \"The more serious the threat and the more emotional the topic (such as radioactivity), the less reassuring a reduction in risk seems to us.\"\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Anecdotal fallacy",
        "article": "Anecdotal_evidence",
        "summary": "\u003cp\u003e\u003cb\u003eAnecdotal evidence\u003c/b\u003e is evidence based only on personal observation, collected in a casual or non-systematic manner. \n\u003c/p\u003e\u003cp\u003eWhen used in advertising or promotion of a product, service, or idea, anecdotal reports are often called a testimonial, which are highly regulated in some jurisdictions.\n\u003c/p\u003e\u003cp\u003eAnecdotal evidence may be considered within the scope of scientific method as some anecdotal evidence can be both empirical and verifiable, e.g. in the use of case studies in medicine. Other anecdotal evidence, however, does not qualify as scientific evidence, because its nature prevents it from being investigated by the scientific method. Where only one or a few anecdotes are presented, there is a larger chance that they may be unreliable due to cherry-picked or otherwise non-representative samples of typical cases. Similarly, psychologists have found that due to cognitive bias people are more likely to remember notable or unusual examples rather than typical examples. Thus, even when accurate, anecdotal evidence is not necessarily representative of a typical experience. Accurate determination of whether an anecdote is typical requires statistical evidence. Misuse of anecdotal evidence in the form of argument from anecdote is an informal fallacy and is sometimes referred to as the \"person who\" fallacy (\"I know a person who...\"; \"I know of a case where...\" etc.) which places undue weight on experiences of close peers which may not be typical.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Illusion of validity",
        "article": "Illusion_of_validity",
        "summary": "\u003cp\u003e\u003cb\u003eIllusion of validity\u003c/b\u003e is a cognitive bias in which a person overestimates their ability to interpret and predict accurately the outcome when analyzing a set of data, in particular when the data analyzed show a very consistent pattern—that is, when the data \"tell\" a coherent story.\n\u003c/p\u003e\u003cp\u003eThis effect persists even when the person is aware of all the factors that limit the accuracy of their predictions, that is when the data and/or methods used to judge them lead to highly fallible predictions.\n\u003c/p\u003e\u003cp\u003eDaniel Kahneman, Paul Slovic, and Amos Tversky explain the illusion as follows: \"people often predict by selecting the output...that is most representative of the input....The confidence they have in their prediction depends primarily on the degree of representativeness...with little or no regard for the factors that limit predictive accuracy. Thus, people express great confidence in the prediction that a person is a librarian when given a description of his personality which matches the stereotype of librarians, even if the description is scanty, unreliable, or outdated. The unwarranted confidence which is produced by a good fit between the predicted outcome and the input information may be called the illusion of validity.\"\n\u003c/p\u003e\u003cp\u003eConsistent patterns may be observed when input variables are highly redundant or correlated, which may increase subjective confidence. However, a number of highly correlated inputs should not increase confidence much more than only one of the inputs; instead higher confidence should be merited when a number of highly \u003ci\u003eindependent\u003c/i\u003e inputs show a consistent pattern.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Masked-man fallacy",
        "article": "Masked-man_fallacy",
        "summary": "\u003cp\u003eIn philosophical logic, the \u003cb\u003emasked-man fallacy\u003c/b\u003e (also known as the \u003cb\u003eintensional fallacy\u003c/b\u003e or \u003cb\u003eepistemic fallacy\u003c/b\u003e) is committed when one makes an illicit use of Leibniz's law in an argument. Leibniz's law states that if A and B are the same object, then A and B are indiscernible (that is, they have all the same properties). By \u003ci\u003emodus tollens\u003c/i\u003e, this means that if one object has a certain property, while another object does not have the same property, the two objects cannot be identical. The fallacy is \"epistemic\" because it posits an immediate identity between a subject's knowledge of an object with the object itself, failing to recognize that Leibniz's Law is not capable of accounting for intensional contexts.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Recency illusion",
        "article": "Recency_illusion",
        "summary": "\u003cp\u003eThe \u003cb\u003erecency illusion\u003c/b\u003e is the belief or impression, on the part of someone who has only recently become aware of a long-established phenomenon, that the phenomenon itself must be of recent origin. The term was coined by Arnold Zwicky, a linguist at Stanford University who is primarily interested in examples involving words, meanings, phrases, and grammatical constructions. However, use of the term is not restricted to linguistic phenomena: Zwicky has defined it simply as, \"the belief that things \u003ci\u003eyou\u003c/i\u003e have noticed only recently are in fact recent\".\n\u003c/p\u003e\u003cp\u003eAccording to Zwicky, the illusion is caused by selective attention.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Gambler's fallacy",
        "article": "Gambler's_fallacy",
        "summary": "\u003cp\u003eThe \u003cb\u003egambler's fallacy\u003c/b\u003e, also known as the \u003cb\u003eMonte Carlo fallacy\u003c/b\u003e or the \u003cb\u003efallacy of the maturity of chances\u003c/b\u003e, is the belief that, if an event (whose occurrences are independent and identically distributed) has occurred less frequently than expected, it is more likely to happen again in the future (or vice versa). The fallacy is commonly associated with gambling, where it may be believed, for example, that the next dice roll is more than usually likely to be six because there have recently been fewer than the expected number of sixes.\n\u003c/p\u003e\u003cp\u003eThe term  \"Monte Carlo fallacy\" originates from an example of the phenomenon, in which the roulette wheel spun black 26 times in succession at the Monte Carlo Casino in 1913.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Hot-hand fallacy",
        "article": "Hot-hand_fallacy",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐nsxbg\nCached time: 20240701122000\nCache expiry: 2592000\nReduced expiry: false\nComplications: [vary‐revision‐sha1, is‐preview]\nCPU time usage: 0.023 seconds\nReal time usage: 0.035 seconds\nPreprocessor visited node count: 43/1000000\nPost‐expand include size: 1131/2097152 bytes\nTemplate argument size: 0/2097152 bytes\nHighest expansion depth: 8/100\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 0/5000000 bytes\nLua time usage: 0.006/10.000 seconds\nLua memory usage: 627552/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%   28.351      1 Template:R_from_move\n100.00%   28.351      1 -total\n 71.82%   20.362      1 Template:Redirect_template\n 22.11%    6.267      1 Template:R_from_move/except\n--\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Illusory correlation",
        "article": "Illusory_correlation",
        "summary": "\u003cp\u003eIn psychology, \u003cb\u003eillusory correlation\u003c/b\u003e is the phenomenon of perceiving a relationship between variables (typically people, events, or behaviors) even when no such relationship exists. A false association may be formed because rare or novel occurrences are more salient and therefore tend to capture one's attention. This phenomenon is one way stereotypes form and endure. Hamilton \u0026amp; Rose (1980) found that stereotypes can lead people to expect certain groups and traits to fit together, and then to overestimate the frequency with which these correlations actually occur. These stereotypes can be learned and perpetuated without any actual contact occurring between the holder of the stereotype and the group it is about.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Pareidolia",
        "article": "Pareidolia",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003ePareidolia\u003c/b\u003e (\u003cspan\u003e\u003c/span\u003e; \u003cspan\u003e\u003cspan\u003ealso US: \u003c/span\u003e\u003c/span\u003e) is the tendency for perception to impose a meaningful interpretation on a nebulous stimulus, usually visual, so that one detects an object, pattern, or meaning where there is none. Pareidolia is a type of apophenia.\n\u003c/p\u003e\u003cp\u003eCommon examples include  perceived images of animals, faces, or objects in cloud formations; seeing faces in inanimate objects; or lunar pareidolia like the Man in the Moon or the Moon rabbit. The concept of pareidolia may extend to include hidden messages in recorded music played in reverse or at higher- or lower-than-normal speeds, and hearing voices (mainly indistinct) or music in random noise, such as that produced by air conditioners or by fans.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We tend to find stories and patterns even when looking at sparse data",
        "name": "Anthropomorphism",
        "article": "Anthropomorphism#Psychology",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\n\n\u003c/p\u003e\n\n\n\u003cp\u003e\u003cb\u003eAnthropomorphism\u003c/b\u003e is the attribution of human traits, emotions, or intentions to non-human entities. It is considered to be an innate tendency of human psychology. Personification is the related attribution of human form and characteristics to abstract concepts such as nations, emotions, and natural forces, such as seasons and weather. Both have ancient roots as storytelling and artistic devices, and most cultures have traditional fables with anthropomorphized animals as characters. People have also routinely attributed human emotions and behavioral traits to wild as well as domesticated animals.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Group attribution error",
        "article": "Group_attribution_error",
        "summary": "\u003cp\u003eThe \u003cb\u003egroup attribution error\u003c/b\u003e refers to people's tendency to believe either\n\u003c/p\u003e\n\u003col\u003e\u003cli\u003ethe characteristics of an individual group member are reflective of the group as a whole, or\u003c/li\u003e\n\u003cli\u003ea group's decision outcome must reflect the preferences of individual group members, even when external information is available suggesting otherwise.\u003c/li\u003e\u003c/ol\u003e\n\u003cp\u003eThe group attribution error shares an attribution bias analogous to the fundamental attribution error. Rather than focusing on individual's behavior, it relies on group outcomes and attitudes as its main basis for conclusions.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Ultimate attribution error",
        "article": "Ultimate_attribution_error",
        "summary": "\u003cp\u003eThe \u003cb\u003eultimate attribution error\u003c/b\u003e is a type of attribution error which describes how attributions of outgroup behavior are more negative than ingroup behavior. As a cognitive bias, the error results in negative outgroup behavior being more likely to be attributed to factors internal and specific to the actor, such as personality, and the attribution of negative ingroup behavior to external factors such as luck or circumstance. The bias reinforces negative stereotypes and prejudice about the outgroup and favouritism of the ingroup through positive stereotypes. The theory also extends to the bias that positive acts performed by ingroup members are more likely a result of their personality.\n\u003c/p\u003e\u003cp\u003eFour categories have been identified that describe the negative attribution of positive outgroup behaviour. First, that the outgroup member is an exception to a general rule; second, that the member was lucky or had specific advantages; third, that the member was highly motivated; and lastly that the behaviour as attributable to situational causes. \n\u003c/p\u003e\u003cp\u003eThe concept and term originates in an article by Thomas F. Pettigrew in 1979 as an extension of the fundamental attribution error which was identified in 1958. Since its publication, which at the time lacked a strong empirical basis, there has been some support for the theory. The specific categorisation originally proposed had only some empirical support for broader categories of motivational and cognitive attribution.  The bias is related to intergroup attribution bias.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Stereotyping",
        "article": "Stereotype",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\n\n\n\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\n\n\u003cp\u003eIn social psychology, a \u003cb\u003estereotype\u003c/b\u003e is a generalized belief about a particular category of people. It is an expectation that people might have about every person of a particular group. The type of expectation can vary; it can be, for example, an expectation about the group's personality, preferences, appearance or ability.  Stereotypes are often overgeneralized, inaccurate, and resistant to new information. A stereotype does not necessarily need to be a negative assumption. They may be positive, neutral, or negative.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Essentialism",
        "article": "Essentialism",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\u003cp\u003e\u003cb\u003eEssentialism\u003c/b\u003e is the view that objects have a set of attributes that are necessary to their identity. In early Western thought, Platonic idealism held that all things have such an \"essence\"—an \"idea\" or \"form\". In \u003ci\u003eCategories\u003c/i\u003e, Aristotle similarly proposed that all objects have a substance that, as George Lakoff put it, \"make the thing what it is, and without which it would be not \u003ci\u003ethat\u003c/i\u003e kind of thing\". The contrary view—non-essentialism—denies the need to posit such an \"essence\". Essentialism has been controversial from its beginning. In the \u003ci\u003eParmenides\u003c/i\u003e dialogue, Plato depicts Socrates questioning the notion, suggesting that if we accept the idea that every beautiful thing or just action partakes of an essence to be beautiful or just, we must also accept the \"existence of separate essences for hair, mud, and dirt\".\n\u003c/p\u003e\u003cp\u003eOlder social theories were often conceptually essentialist. In biology and other natural sciences, essentialism provided the rationale for taxonomy at least until the time of Charles Darwin. The role and importance of essentialism in modern biology is still a matter of debate. Beliefs which posit that social identities such as race, ethnicity, nationality, or gender are essential characteristics have been central to many discriminatory or extremist ideologies. For instance, psychological essentialism is correlated with racial prejudice. Essentialist views about race have also been shown to diminish empathy when dealing with members of another racial group. In medical sciences, essentialism can lead to a reified view of identities, leading to fallacious conclusions and potentially unequal treatment.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Functional fixedness",
        "article": "Functional_fixedness",
        "summary": "\u003cp\u003e\u003cb\u003eFunctional fixedness\u003c/b\u003e is a cognitive bias that limits a person to use an object only in the way it is traditionally used. The concept of functional fixedness originated in Gestalt psychology, a movement in psychology that emphasizes holistic processing. Karl Duncker defined functional fixedness as being a mental block against using an object in a new way that is required to solve a problem. This \"block\" limits the ability of an individual to use components given to them to complete a task, as they cannot move past the original purpose of those components. For example, if someone needs a paperweight, but they only have a hammer, they may not see how the hammer can be used as a paperweight. Functional fixedness is this inability to see a hammer's use as anything other than for pounding nails; the person couldn't think to use the hammer in a way other than in its conventional function.\n\u003c/p\u003e\u003cp\u003eWhen tested, 5-year-old children show no signs of functional fixedness. It has been argued that this is because at age 5, any goal to be achieved with an object is equivalent to any other goal. However, by age 7, children have acquired the tendency to treat the originally intended purpose of an object as special.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Moral credential effect",
        "article": "Self-licensing",
        "summary": "\u003cp\u003e\u003cb\u003eSelf-licensing\u003c/b\u003e (also \u003cb\u003emoral self-licensing\u003c/b\u003e, \u003cb\u003emoral licensing\u003c/b\u003e, or \u003cb\u003elicensing effect\u003c/b\u003e) is a term used in social psychology and marketing to describe the subconscious phenomenon whereby increased confidence and security in one's self-image or self-concept tends to make that individual worry less about the consequences of subsequent immoral behavior and, therefore, more likely to make immoral choices and act immorally. In simple terms, self-licensing occurs when people allow themselves to indulge after doing something positive first; for example, drinking a diet soda with a greasy hamburger and fries can lead one to subconsciously discount the negative attributes of the meal's high caloric and cholesterol content.\n\u003c/p\u003e\u003cp\u003eA large subset of this effect, the \u003cb\u003emoral credential effect\u003c/b\u003e, is a bias that occurs when a person's track record as a good egalitarian establishes in them an unconscious ethical certification, endorsement, or license that increases the likelihood of less egalitarian decisions later. This effect occurs even when the audience or moral peer group is unaware of the affected person's previously established moral credential. For example, individuals who had the opportunity to recruit a woman or Black person in one setting were more likely to say later, in a different setting, that a job would be better suited for a man or a white person. Similar effects also appear to occur when a person observes another person from a group they identify with making an egalitarian decision.\n\u003c/p\u003e\u003cp\u003eSelf-licensing can have negative societal consequences since it has a permissive effect on behaviors such as racial prejudice and discrimination, selfishness, poor dietary and health habits, and excessive energy consumption.\n\u003c/p\u003e\u003cp\u003eBut recent scholarship has failed to replicate seminal studies of the licensing effect, and meta-analysis found it to be exaggerated by publication bias. Furthermore, where licensing typically assumes that a good deed is the cause that makes subsequent transgressions more likely, an alternative (or additional) account is that people are faced with a temptation to do something morally dubious, and use a prior good deed as an excuse or reason why it is allowed for them to indulge. \n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Just-world hypothesis",
        "article": "Just-world_hypothesis",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐dlq84\nCached time: 20240701122002\nCache expiry: 2592000\nReduced expiry: false\nComplications: [vary‐revision‐sha1, is‐preview]\nCPU time usage: 0.066 seconds\nReal time usage: 0.088 seconds\nPreprocessor visited node count: 110/1000000\nPost‐expand include size: 4744/2097152 bytes\nTemplate argument size: 1099/2097152 bytes\nHighest expansion depth: 13/100\nExpensive parser function count: 1/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 1653/5000000 bytes\nLua time usage: 0.036/10.000 seconds\nLua memory usage: 786425/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%   77.509      1 -total\n100.00%   77.509      1 Template:Redirect_shell\n 95.14%   73.744      1 Template:Mbox\n 16.54%   12.822      1 Template:R_from_move\n  7.80%    6.049      1 Template:R_from_move/except\n  6.69%    5.186      1 Template:Redirect_template\n  3.22%    2.498      1 Template:Talk_other\n--\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Argument from fallacy",
        "article": "Argument_from_fallacy",
        "summary": "\u003cp\u003e\u003cb\u003eArgument from fallacy\u003c/b\u003e is the formal fallacy of analyzing an argument and inferring that, since it contains a fallacy, its \u003ci\u003econclusion\u003c/i\u003e must be false. It is also called \u003cb\u003eargument to logic\u003c/b\u003e  (\u003ci\u003e\u003cb\u003eargumentum ad logicam\u003c/b\u003e\u003c/i\u003e), the \u003cb\u003efallacy fallacy\u003c/b\u003e, the \u003cb\u003efallacist's fallacy\u003c/b\u003e, and the \u003cb\u003ebad reasons fallacy\u003c/b\u003e.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Authority bias",
        "article": "Authority_bias",
        "summary": "\u003cp\u003e\u003cb\u003eAuthority bias\u003c/b\u003e is the tendency to attribute greater accuracy to the opinion of an authority figure (unrelated to its content) and be more influenced by that opinion. An individual is more influenced by the opinion of this authority figure, believing their views to be more credible, and hence place greater emphasis on the authority figure's viewpoint and are more likely to obey them. This concept is considered one of the social cognitive biases or collective cognitive biases.\n\u003c/p\u003e\u003cp\u003eHumans generally have a deep-seated duty to authority and tend to comply when requested by an authority figure. Some scholars explain that individuals are motivated to view authority as deserving of their position and this legitimacy leads people to accept and obey the decisions that it makes. System justification theory articulates this phenomenon, particularly within its position that there is a psychological motivation for believing in the steadiness, stability and justness of the current social system.\n\u003c/p\u003e\u003cp\u003eAuthority bias can be measured concerning respect for authority, where higher respect for authority positively correlates with the increased likelihood of exhibiting authority bias. Respect for authority is measured using the Respect for Authority Index (RAI), which averages responses on deference to the police. A higher score on the RAI is indicative of higher respect for authority, and hence strengthening the execution of authority bias.\n\u003c/p\u003e\u003cp\u003eCultural differences in the strength of authority bias have been identified, in which the differences in edits made to Wikipedia articles by administrators and regular users were compared for accuracy. In Western Europe, the bias has a negligible effect. In Eastern Europe, the bias is larger and the administrator's edits are perceived as more likely to be true (despite the edits being inaccurate), indicating a cultural difference in the extent to which authority bias is experienced.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Automation bias",
        "article": "Automation_bias",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\n\u003cp\u003e\u003cb\u003eAutomation bias\u003c/b\u003e is the propensity for humans to favor suggestions from automated decision-making systems and to ignore contradictory information made without automation, even if it is correct. Automation bias stems from the social psychology literature that found a bias in human-human interaction that showed that people assign more positive evaluations to decisions made by humans than to a neutral object. The same type of positivity bias has been found for human-automation interaction, where the automated decisions are rated more positively than neutral. This has become a growing problem for decision making as intensive care units, nuclear power plants, and aircraft cockpits have increasingly integrated computerized system monitors and decision aids to mostly factor out possible human error. Errors of automation bias tend to occur when decision-making is dependent on computers or other automated aids and the human is in an observatory role but able to make decisions. Examples of automation bias range from urgent matters like flying a plane on automatic pilot to such mundane matters as the use of spell-checking programs.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Bandwagon effect",
        "article": "Bandwagon_effect",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1126788409\"\u003e\n\u003cp\u003eThe \u003cb\u003ebandwagon effect\u003c/b\u003e is a psychological phenomenon where people  adopt certain behaviors, styles, or attitudes simply because others are doing so. More specifically, it is a cognitive bias by which public opinion or behaviours can alter due to particular actions and beliefs rallying amongst the public. It is a psychological phenomenon whereby the rate of uptake of beliefs, ideas, fads and trends increases with respect to the proportion of others who have already done so. As more people come to believe in something, others also \"hop on the bandwagon\" regardless of the underlying evidence.\n\u003c/p\u003e\u003cp\u003eFollowing others' actions or beliefs can occur because of conformism or deriving information from others. Much of the influence of the bandwagon effect comes from the desire to 'fit in' with peers; by making similar selections as other people, this is seen as a way to gain access to a particular social group. An example of this is fashion trends wherein the increasing popularity of a certain garment or style encourages more acceptance. When individuals make rational choices based on the information they receive from others, economists have proposed that information cascades can quickly form in which people ignore their personal information signals and follow the behaviour of others. Cascades explain why behaviour is fragile as people understand that their behaviour is based on a very limited amount of information. As a result, fads form easily but are also easily dislodged. The phenomenon is observed in various fields, such as economics, political science, medicine, and psychology. In social psychology, people's tendency to align their beliefs and behaviors with a group is known as 'herd mentality' or 'groupthink'. The \u003cb\u003ereverse bandwagon effect\u003c/b\u003e (also known as the snob effect in certain contexts) is a cognitive bias that causes people to avoid doing something, because they believe that other people are doing it.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We fill in characteristics from stereotypes, generalities, and prior histories",
        "name": "Placebo effect",
        "article": "Placebo",
        "summary": "\u003cp\u003eA \u003cb\u003eplacebo\u003c/b\u003e (\u003cspan\u003e\u003c/span\u003e \u003ci title=\"English pronunciation respelling\"\u003eplə-\u003cspan\u003eSEE\u003c/span\u003e-boh\u003c/i\u003e) is a substance or treatment which is designed to have no therapeutic value. Common placebos include inert tablets (like sugar pills), inert injections (like saline), sham surgery, and other procedures.\n\u003c/p\u003e\u003cp\u003ePlacebos are used in randomized clinical trials to test the efficacy of medical treatments. In a placebo-controlled clinical trial any change in the control group is known as the \u003ci\u003eplacebo response\u003c/i\u003e, and the difference between this and the result of no treatment is the \u003ci\u003eplacebo effect\u003c/i\u003e. Placebos in clinical trials should ideally be indistinguishable from so-called verum treatments under investigation, except for the latter's particular hypothesized medicinal effect. This is to shield test participants (with their consent) from knowing who is getting the placebo and who is getting the treatment under test, as patients' and clinicians' expectations of efficacy can influence results.\n\u003c/p\u003e\u003cp\u003eThe idea of a placebo effect was discussed in 18th century psychology, but became more prominent in the 20th century. Modern studies find that placebos can affect some outcomes such as pain and nausea, but otherwise do not generally have important clinical effects. Improvements that patients experience after being treated with a placebo can also be due to unrelated factors, such as regression to the mean (a statistical effect where an unusually high or low measurement is likely to be followed by a less extreme one). The use of placebos in clinical medicine raises ethical concerns, especially if they are disguised as an active treatment, as this introduces dishonesty into the doctor–patient relationship and bypasses informed consent.\n\u003c/p\u003e\u003cp\u003ePlacebos are also popular because they can sometimes produce relief through psychological mechanisms (a phenomenon known as the \"placebo effect\"). They can affect how patients perceive their condition and encourage the body's chemical processes for relieving pain and a few other symptoms, but have no impact on the disease itself.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We imagine things and people we're familiar with or fond of as better",
        "name": "Out-group homogeneity bias",
        "article": "Out-group_homogeneity",
        "summary": "\u003cp\u003eThe \u003cb\u003eout-group homogeneity effect\u003c/b\u003e is the perception of out-group members as more similar to one another than are in-group members, e.g. \"they are alike; we are diverse\". Perceivers tend to have impressions about the diversity or variability of group members around those central tendencies or typical attributes of those group members. Thus, outgroup stereotypicality judgments are overestimated, supporting the view that out-group stereotypes are overgeneralizations. The term \"outgroup homogeneity effect\", \"outgroup homogeneity bias\" or \"relative outgroup homogeneity\" have been explicitly contrasted with \"outgroup homogeneity\" in general, the latter referring to perceived outgroup variability unrelated to perceptions of the ingroup.\n\u003c/p\u003e\u003cp\u003eThe outgroup homogeneity effect is sometimes referred to as \"outgroup homogeneity bias\". Such nomenclature hints at a broader meta-theoretical debate that is present in the field of social psychology. This debate centres on the validity of heightened perceptions of ingroup and outgroup homogeneity, where some researchers view the homogeneity effect as an example of cognitive bias and error, while other researchers view the effect as an example of normal and often adaptive social perception. The out-group homogeneity effect has been found using a wide variety of different social groups, from political and racial groups to age and gender groups.\n\u003c/p\u003e\u003cp\u003eThe out-group homogeneity effect is part of a broader field of research that examines perceived group variability. This area includes in-group homogeneity effects as well as out-group homogeneity effects, and it also deals with perceived group variability effects that are not linked to in-group/out-group membership, such as effects that are related to the power, status, and size of groups. The out-group homogeneity effect has been found using a wide variety of different social groups, from political and racial groups to age and gender groups. The implications of this effect on stereotyping have been noted.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We imagine things and people we're familiar with or fond of as better",
        "name": "Cross-race effect",
        "article": "Cross-race_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003ecross-race effect\u003c/b\u003e (sometimes called \u003cb\u003ecross-race bias\u003c/b\u003e, \u003cb\u003eother-race bias\u003c/b\u003e, \u003cb\u003eown-race bias\u003c/b\u003e or \u003cb\u003eother-race effect\u003c/b\u003e) is the tendency to more easily recognize faces that belong to one's own racial group, or racial groups that one has been in contact with. In social psychology, the cross-race effect is described as the \"ingroup advantage,\" whereas in other fields, the effect can be seen as a specific form of the \"ingroup advantage\" since it is only applied in interracial or inter-ethnic situations. The cross-race effect is thought to contribute to difficulties in cross-race identification, as well as implicit racial bias.\n\u003c/p\u003e\u003cp\u003eA number of theories as to why the cross-race effect exists have been conceived, including social cognition and perceptual expertise. However, no model has been able to fully account for the full body of evidence. \n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We imagine things and people we're familiar with or fond of as better",
        "name": "In-group favoritism",
        "article": "In-group_favoritism",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eIn-group favoritism\u003c/b\u003e, sometimes known as \u003cb\u003ein-group–out-group bias\u003c/b\u003e, \u003cb\u003ein-group bias\u003c/b\u003e, \u003cb\u003eintergroup bias\u003c/b\u003e, or \u003cb\u003ein-group preference\u003c/b\u003e, is a pattern of favoring members of one's in-group over out-group members. This can be expressed in evaluation of others, in allocation of resources, and in many other ways.\n\u003c/p\u003e\u003cp\u003eThis effect has been researched by many psychologists and linked to many theories related to group conflict and prejudice. The phenomenon is primarily viewed from a social psychology standpoint. Studies have shown that in-group favoritism arises as a result of the formation of cultural groups. These cultural groups can be divided based on seemingly trivial observable traits, but with time, populations grow to associate certain traits with certain behavior, increasing covariation. This then incentivizes in-group bias.\n\u003c/p\u003e\u003cp\u003eTwo prominent theoretical approaches to the phenomenon of in-group favoritism are realistic conflict theory and social identity theory. Realistic conflict theory proposes that intergroup competition, and sometimes intergroup conflict, arises when two groups have opposing claims to scarce resources. In contrast, social identity theory posits a psychological drive for positively distinct social identities as the general root cause of in-group favoring behavior.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We imagine things and people we're familiar with or fond of as better",
        "name": "Halo effect",
        "article": "Halo_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003ehalo effect\u003c/b\u003e (sometimes called the \u003cb\u003ehalo error\u003c/b\u003e) is the proclivity for positive impressions of a person, company, country, brand, or product in one area to positively influence one's opinion or feelings. Halo effect is \"the name given to the phenomenon whereby evaluators tend to be influenced by their previous judgments of performance or personality.\" The halo effect is a cognitive bias which can prevent someone from forming an image of a person, a product or a brand based on the sum of all objective circumstances at hand.\n\u003c/p\u003e\u003cp\u003eThe term was coined by Edward Thorndike. A simplified example of the halo effect is a person, after noticing that an individual in a photograph is attractive, well groomed, and properly attired, then assuming, using a mental heuristic, that the person in the photograph is a good person based upon the rules of their own social concept. This constant error in judgment is reflective of the individual's preferences, prejudices, ideology, aspirations, and social perception.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We imagine things and people we're familiar with or fond of as better",
        "name": "Cheerleader effect",
        "article": "Cheerleader_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003echeerleader effect\u003c/b\u003e, also known as the \u003cb\u003egroup attractiveness effect\u003c/b\u003e or the \u003cb\u003efriend effect\u003c/b\u003e, is a proposed cognitive bias which causes people to perceive individuals as 1.5–2.0% more attractive in a group than when seen alone. The first paper to report this effect was written by Drew Walker and Edward Vul, in 2013.\n\u003c/p\u003e\u003cp\u003ePhysical attractiveness implies individuals' preferences in a sexual selection based on the evolutionary psychology. In 1979, Donald Symons first proposed this evolutionary explanation, suggesting that the evolving physical attractiveness results from mate assessment favoring partners who exhibited signs of good health and fertility, including face averageness. This preference was proved to be shared across cultures. Two parts constitute physical attractiveness, and most former studies investigated underlying mechanisms leading to cheerleader effect specifically in its subset, facial attractiveness. Nevertheless, a study has recognized this effect in another physical appearance indicator, human body perceptions.\n\u003c/p\u003e\u003cp\u003eThe effect size of the cheerleader effect is not modulated by the presentation time, the number of individuals surrounding the target, spatial arrangement of the faces in the group. However, another study argued that the arrangement of faces in the group might influence this effect since people's central viewing tendency might affect observers to focus more on the perceived attractiveness of the middle face in the group.\n\u003c/p\u003e\u003cp\u003eFindings of this effect are interdisciplinary in applications. Based on them, mate choice, marketing, and social media tactics are designed to increase the attractiveness of a target individual or item via the help of the group.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We imagine things and people we're familiar with or fond of as better",
        "name": "Positivity effect",
        "article": "Positivity_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003epositivity effect\u003c/b\u003e is the ability to constructively analyze a situation where the desired results are not achieved, but still obtain positive feedback that assists one's future progression.\n\u003c/p\u003e\u003cp\u003eEmpirical research findings suggest that the positivity effect can be influenced by internal positive speech, where engaging in constructive self-dialogue can significantly improve one’s ability to perceive and react to challenging situations more optimistically.\n\u003c/p\u003e\u003cp\u003eThe findings of a study show that the optimism bias in future-oriented thinking fulfils a self-improvement purpose while also suggesting this bias probably reflects a common underpinning motivational process across various future-thinking domains, either episodic or semantic.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We imagine things and people we're familiar with or fond of as better",
        "name": "Not invented here",
        "article": "Not_invented_here",
        "summary": "\u003cp\u003e\u003cb\u003eNot invented here\u003c/b\u003e (\u003cb\u003eNIH\u003c/b\u003e) is the tendency to avoid using or buying products, research, standards, or knowledge from external origins. It is usually adopted by social, corporate, or institutional cultures. Research illustrates a strong bias against ideas from the outside.\n\u003c/p\u003e\u003cp\u003eThe reasons for not wanting to use the work of others are varied, but can include a desire to support a local economy instead of paying royalties to a foreign license-holder, fear of patent infringement, lack of understanding of the foreign work, an unwillingness to acknowledge or value the work of others, jealousy, belief perseverance, or forming part of a wider turf war. As a social phenomenon, this tendency can manifest itself as an unwillingness to adopt an idea or product because it originates from another culture, a form of tribalism and/or an inadequate effort in choosing the right approach for the business.\n\u003c/p\u003e\u003cp\u003eThe term is typically used in a pejorative sense. The opposite predisposition is sometimes called \"proudly found elsewhere\" (PFE) or \"invented elsewhere\".\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We imagine things and people we're familiar with or fond of as better",
        "name": "Reactive devaluation",
        "article": "Reactive_devaluation",
        "summary": "\u003cp\u003e\u003cb\u003eReactive devaluation\u003c/b\u003e is a cognitive bias that occurs when a proposal is devalued if it appears to originate from an antagonist. The bias was proposed by Lee Ross and Constance Stillinger (1988).\n\u003c/p\u003e\u003cp\u003eReactive devaluation could be caused by loss aversion or attitude polarization, or naïve realism.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We imagine things and people we're familiar with or fond of as better",
        "name": "Well-traveled road effect",
        "article": "Well_travelled_road_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003ewell travelled road effect\u003c/b\u003e is a cognitive bias in which travellers will estimate the time taken to traverse routes differently depending on their familiarity with the route. Frequently travelled routes are assessed as taking a shorter time than unfamiliar routes. This effect creates errors when estimating the most efficient route to an unfamiliar destination, when one candidate route includes a familiar route, whilst the other candidate route includes no familiar routes. The effect is most salient when subjects are driving, but is still detectable for pedestrians and users of public transport. The effect has been observed for centuries but was first studied scientifically in the 1980s and 1990s following from earlier \"heuristics and biases\" work undertaken by Daniel Kahneman and Amos Tversky.\n\u003c/p\u003e\u003cp\u003eMuch like the Stroop task, it is hypothesised that drivers use less cognitive effort when traversing familiar routes and therefore underestimate the time taken to traverse the familiar route.  The well travelled road effect has been hypothesised as a reason that self-reported experience curve effects are overestimated.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We simplify probabilities and numbers to make them easier to think about",
        "name": "Mental accounting",
        "article": "Mental_accounting",
        "summary": "\u003cp\u003e\u003cb\u003eMental accounting\u003c/b\u003e (or \u003cb\u003epsychological accounting\u003c/b\u003e) is a model of consumer behaviour developed by Richard Thaler that attempts to describe the process whereby people code, categorize and evaluate economic outcomes. Mental accounting incorporates the economic concepts of prospect theory and transactional utility theory to evaluate how people create distinctions between their financial resources in the form of mental accounts, which in turn impacts the buyer decision process and reaction to economic outcomes.  People are presumed to make mental accounts as a self control strategy to manage and keep track of their spending and resources. People budget money into mental accounts for savings (e.g., saving for a home) or expense categories (e.g., gas money, clothing, utilities). People also are assumed to make mental accounts to facilitate savings for larger purposes (e.g., a home or college tuition). Mental accounting can result in people demonstrating greater loss aversion for certain mental accounts, resulting in cognitive bias that incentivizes systematic departures from consumer rationality. Through increased understanding of mental accounting differences in decision making based on different resources, and different reactions based on similar outcomes can be greater understood.  \n\u003c/p\u003e\u003cp\u003eAs Thaler puts it, “All organizations, from General Motors down to single person households, have explicit and/or implicit accounting systems. The accounting system often influences decisions in unexpected ways”. Particularly, individual expenses will usually not be considered in conjunction with the present value of one’s total wealth; they will be instead considered in the context of two accounts: the current budgetary period (this could be a monthly process due to bills, or yearly due to an annual income), and the category of expense.  People can even have multiple mental accounts for the same kind of resource. A person may use different monthly budgets for grocery shopping and eating out at restaurants, for example, and constrain one kind of purchase when its budget has run out while not constraining the other kind of purchase, even though both expenditures draw on the same fungible resource (income).\n\u003c/p\u003e\u003cp\u003eOne detailed application of mental accounting, the Behavioral Life Cycle Hypothesis posits that people mentally frame assets as belonging to either current income, current wealth or future income and this has implications for their behavior as the accounts are largely non-fungible and marginal propensity to consume out of each account is different. \n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We simplify probabilities and numbers to make them easier to think about",
        "name": "Appeal to probability fallacy",
        "article": "Appeal_to_probability",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1097763485\"\u003e\n\u003cp\u003eAn \u003cb\u003eappeal to probability\u003c/b\u003e (or \u003cb\u003eappeal to possibility\u003c/b\u003e, also known as \u003ci\u003epossibiliter ergo probabiliter\u003c/i\u003e, \"possibly, therefore probably\") is the logical fallacy of taking something for granted because it is possibly the case.  The fact that an event is possible does not imply that the event is probable, nor that the event was realized. \n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We simplify probabilities and numbers to make them easier to think about",
        "name": "Normalcy bias",
        "article": "Normalcy_bias",
        "summary": "\u003cp\u003e\u003cb\u003eNormalcy bias\u003c/b\u003e, or \u003cb\u003enormality bias\u003c/b\u003e, is a cognitive bias which leads people to disbelieve or minimize threat warnings. Consequently, individuals underestimate the likelihood of a disaster, when it might affect them, and its potential adverse effects. The normalcy bias causes many people to prepare inadequately for natural disasters, market crashes, and calamities caused by human error. About 80% of people reportedly display normalcy bias during a disaster.\n\u003c/p\u003e\u003cp\u003eThe normalcy bias can manifest in response to warnings about disasters and actual catastrophes. Such events can range in scale from incidents such as traffic collisions to global catastrophic risk. The event may involve social constructionism phenomena such as loss of money in market crashes, or direct threats to continuity of life: as in natural disasters like a tsunami or violence in war.\n\u003c/p\u003e\u003cp\u003eNormalcy bias has also been called \u003ci\u003eanalysis paralysis\u003c/i\u003e, \u003ci\u003ethe ostrich effect\u003c/i\u003e, and by first responders, \u003ci\u003ethe negative panic\u003c/i\u003e. The opposite of normalcy bias is overreaction, or worst-case scenario bias, in which small deviations from normality are dealt with as signals of an impending catastrophe.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We simplify probabilities and numbers to make them easier to think about",
        "name": "Murphy's Law",
        "article": "Murphy's_law",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1033289096\"\u003e\n\u003cp\u003e\u003cb\u003eMurphy's law\u003c/b\u003e is an adage or epigram that is typically stated as: \"Anything that can go wrong will go wrong.\" In some formulations, it is extended to \"Anything that can go wrong will go wrong, and at the worst possible time.\"\n\u003c/p\u003e\u003cp\u003eThough similar statements and concepts have been made over the course of history, the law itself was coined by, and is named after, American aerospace engineer Edward A. Murphy Jr.; its exact origins are debated, but it is generally agreed it originated from Murphy and his team following a mishap during rocket sled tests some time between 1948 and 1949, and was finalized and first popularized by testing project head John Stapp during a later press conference. Murphy's original quote was the precautionary design advice that \"If there are two or more ways to do something and one of those results in a catastrophe, then someone will do it that way.\"\n\u003c/p\u003e\u003cp\u003eThe law entered wider public knowledge in the late 1970s with the publication of Arthur Bloch's 1977 book \u003ci\u003eMurphy's Law, and Other Reasons Why Things Go WRONG\u003c/i\u003e, which included other variations and corollaries of the law. Since then, Murphy's law has remained a popular (and occasionally misused) adage, though its accuracy has been disputed by academics. \n\u003c/p\u003e\u003cp\u003eSimilar \"laws\" include Sod's law, Finagle's law, and Yhprum's law, among others.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We simplify probabilities and numbers to make them easier to think about",
        "name": "Zero sum bias",
        "article": "Zero-sum_thinking",
        "summary": "\u003cp\u003e\u003cb\u003eZero-sum thinking\u003c/b\u003e perceives situations as zero-sum games, where one person's gain would be another's loss. The term is derived from game theory. However, unlike the game theory concept, zero-sum thinking refers to a psychological construct—a person's subjective interpretation of a situation. Zero-sum thinking is captured by the saying \"your gain is my loss\" (or conversely, \"your loss is my gain\"). Rozycka-Tran et al. (2015) defined zero-sum thinking as:\n\u003c/p\u003e\n\u003cblockquote\u003e\u003cp\u003eA general belief system about the antagonistic nature of social relations, shared by people in a society or culture and based on the implicit assumption that a finite amount of goods exists in the world, in which one person's winning makes others the losers, and vice versa ... a relatively permanent and general conviction that social relations are like a zero-sum game. People who share this conviction believe that success, especially economic success, is possible only at the expense of other people's failures.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cb\u003eZero-sum bias\u003c/b\u003e is a cognitive bias towards zero-sum thinking; it is people's tendency to intuitively judge that a situation is zero-sum, even when this is not the case. This bias promotes \u003cb\u003ezero-sum fallacies\u003c/b\u003e, false beliefs that situations are zero-sum. Such fallacies can cause other false judgements and poor decisions. In economics, \"zero-sum fallacy\" generally refers to the fixed-pie fallacy.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We simplify probabilities and numbers to make them easier to think about",
        "name": "Survivorship bias",
        "article": "Survivorship_bias",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eSurvivorship bias\u003c/b\u003e or \u003cb\u003esurvival bias\u003c/b\u003e is the logical error of concentrating on entities that passed a selection process while overlooking those that did not. This can lead to incorrect conclusions because of incomplete data.  \n\u003c/p\u003e\u003cp\u003eSurvivorship bias is a form of selection bias that can lead to overly optimistic beliefs because multiple failures are overlooked, such as when companies that no longer exist are excluded from analyses of financial performance. It can also lead to the false belief that the successes in a group have some special property, rather than just coincidence as in correlation \"proves\" causality.\n\u003c/p\u003e\u003cp\u003eAnother kind of survivorship bias would involve thinking that an incident happened in a particular way because the only people who were involved in the incident who can speak about it are those who survived it. Even if one knew that some people are dead, they would not have their voice to add to the conversation, making it biased.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We simplify probabilities and numbers to make them easier to think about",
        "name": "Subadditivity effect",
        "article": "Subadditivity_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003esubadditivity effect\u003c/b\u003e is the tendency to judge probability of the whole to be less than the probabilities of the parts.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We simplify probabilities and numbers to make them easier to think about",
        "name": "Denomination effect",
        "article": "Denomination_effect",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\n\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\n\u003cp\u003eThe \u003cb\u003edenomination effect\u003c/b\u003e is a form of cognitive bias relating to currency, suggesting people may be less likely to spend larger currency denominations than their equivalent value in smaller denominations. It was proposed by Priya Raghubir, professor at the New York University Stern School of Business, and Joydeep Srivastava, professor at University of Maryland, in their 2009 paper \"Denomination Effect\".\n\u003c/p\u003e\u003cp\u003eRaghubir and Srivastava conducted three studies in their research on the denomination effect; their findings suggested people may be more likely to spend money represented by smaller denominations and that consumers may prefer to receive money in a large denomination when there is a need to control spending. The denomination effect can occur when large denominations are perceived as less exchangeable than smaller denominations.\n\u003c/p\u003e\u003cp\u003eThe effect's influence on spending decisions has implications throughout various sectors in society, including consumer welfare, monetary policy and the finance industry. For example, during the Great Recession, one businessman observed employees using more coins rather than banknotes in an office vending machine, perceiving the customers used coins to feel thriftier. Raghubir and Srivastava also suggested the effect may involve incentives to alter future behavior and that a large denomination can serve as a mechanism to prevent the urge to spend.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We simplify probabilities and numbers to make them easier to think about",
        "name": "The magical number 7 ± 2",
        "article": "The_Magical_Number_Seven,_Plus_or_Minus_Two",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\n\u003c/p\u003e\u003cp\u003e\"\u003cb\u003eThe Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information\u003c/b\u003e\" is one of the most highly cited papers in psychology. It was written by the cognitive psychologist George A. Miller of Harvard University's Department of Psychology and published in 1956 in \u003ci\u003ePsychological Review\u003c/i\u003e. It is often interpreted to argue that the number of objects an average human can hold in short-term memory is 7 ± 2. This has occasionally been referred to as \u003ci\u003eMiller's law\u003c/i\u003e.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We think we know what other people are thinking",
        "name": "Illusion of transparency",
        "article": "Illusion_of_transparency",
        "summary": "\u003cp\u003eThe \u003cb\u003eillusion of transparency\u003c/b\u003e is a tendency for people to overestimate the degree to which their personal mental state is known by others. Another manifestation of the illusion of transparency (sometimes called the observer's illusion of transparency) is a tendency for people to overestimate how well they understand others' personal mental states. This cognitive bias is similar to the illusion of asymmetric insight.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We think we know what other people are thinking",
        "name": "Curse of knowledge",
        "article": "Curse_of_knowledge",
        "summary": "\u003cp\u003eThe \u003cb\u003ecurse of knowledge\u003c/b\u003e is a cognitive bias that occurs when an individual, who is communicating with others, assumes that others have information that is only available to themselves, assuming they all share a background and understanding. This bias is also called by some authors the \u003cb\u003ecurse of expertise\u003c/b\u003e.\n\u003c/p\u003e\u003cp\u003eFor example, in a classroom setting, teachers may have difficulty if they cannot put themselves in the position of the student. A knowledgeable professor might no longer remember the difficulties that a young student encounters when learning a new subject for the first time. This curse of knowledge also explains the danger behind thinking about student learning based on what appears best to faculty members, as opposed to what has been verified with students. \n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We think we know what other people are thinking",
        "name": "Spotlight effect",
        "article": "Spotlight_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003espotlight effect\u003c/b\u003e is the psychological phenomenon by which people tend to believe they are being noticed more than they really are. Being that one is constantly in the center of one's own world, an \u003ci\u003eaccurate\u003c/i\u003e evaluation of how much one is noticed by others is uncommon. The reason for the spotlight effect is the innate tendency to forget that although one is the center of one's own world, one is not the center of everyone else's. This tendency is especially prominent when one does something atypical.\n\u003c/p\u003e\u003cp\u003eResearch has empirically shown that such drastic over-estimation of one's effect on others is widely common. Many professionals in social psychology encourage people to be conscious of the spotlight effect and to allow this phenomenon to moderate the extent to which one believes one is in a social spotlight.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We think we know what other people are thinking",
        "name": "Extrinsic incentive error",
        "article": "Extrinsic_incentives_bias",
        "summary": "\u003cp\u003eThe \u003cb\u003eextrinsic incentives bias\u003c/b\u003e is an attributional bias according to which people attribute relatively more to \"extrinsic incentives\" (such as monetary reward) than to \"intrinsic incentives\" (such as learning a new skill) when weighing the motives of others rather than themselves.\n\u003c/p\u003e\u003cp\u003eIt is a counter-example to the fundamental attribution error as according to the extrinsic bias others are presumed to have \u003ci\u003esituational\u003c/i\u003e motivations while oneself is seen as having \u003ci\u003edispositional\u003c/i\u003e motivations. This is the opposite of what the fundamental attribution error would predict. It also might help to explain some of the backfiring effects that can occur when extrinsic incentives are attached to activities that people are intrinsically motivated to do. The term was first proposed by Chip Heath, citing earlier research by others in management science. \n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We think we know what other people are thinking",
        "name": "Illusion of asymmetric insight",
        "article": "Illusion_of_asymmetric_insight",
        "summary": "\u003cp\u003eThe \u003cb\u003eillusion of asymmetric insight\u003c/b\u003e is a cognitive bias whereby people perceive their knowledge of others to surpass other people's knowledge of them. This bias \"has been traced to people's tendency to view their own spontaneous or off-the-cuff responses to others' questions as relatively unrevealing even though they view others' similar responses as meaningful\".\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Telescoping effect",
        "article": "Telescoping_effect",
        "summary": "\u003cp\u003eIn cognitive psychology, the \u003cb\u003etelescoping effect\u003c/b\u003e (or \u003cb\u003etelescoping bias\u003c/b\u003e) refers to the temporal displacement of an event whereby people perceive recent events as being more remote than they are and distant events as being more recent than they are. The former is known as \u003cb\u003ebackward telescoping\u003c/b\u003e or \u003cb\u003etime expansion\u003c/b\u003e, and the latter as is known as \u003cb\u003eforward telescoping\u003c/b\u003e.\n\u003c/p\u003e\u003cp\u003eThe approximate time frame in which events switch from being displaced backward in time to forward in time is three years, with events occurring three years in the past being equally likely to be reported with forward telescoping bias as with backward telescoping bias. Although telescoping occurs in both the forward and backward directions, in general the effect is to increase the number of events reported too recently. This net effect in the forward direction is because forces that impair memory, such as lack of salience, also impair time perception.\n\u003c/p\u003e\u003cp\u003eTelescoping leads to an over-reporting of the frequency of events. This over-reporting is because participants include events beyond the period, either events that are too recent for the target time period (backward telescoping) or events that are too old for the target time period (forward telescoping).\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Rosy retrospection",
        "article": "Rosy_retrospection",
        "summary": "\u003cp\u003e\u003cb\u003eRosy retrospection\u003c/b\u003e is a proposed psychological phenomenon of recalling the past more positively than it was actually experienced.\n\u003c/p\u003e\u003cp\u003eThe highly unreliable nature of human memory is well-documented and accepted amongst psychologists. Some research suggests that negative emotions are exaggerated in memory as well as positive ones.  \n\u003c/p\u003e\u003cp\u003eDespite being a cognitive bias which distorts a one's view of reality, it is suggested that rosy retrospection serves a useful purpose in increasing self-esteem and sense of well-being.\n\u003c/p\u003e\u003cp\u003eSimplifications and exaggerations of memories (such as occurs in rosy retrospection) may also make it easier for the brain to store long-term memories, as removing details may reduce the burden of those memories by requiring fewer neural connections.\n\u003c/p\u003e\u003cp\u003eDeclinism - the predisposition to view the past more favourably and the future more negatively - may be related to cognitive biases like rosy retrospection.\n\u003c/p\u003e\u003cp\u003eRosy retrospection is very closely related to the concept of nostalgia; though the broader phenomenon of nostalgia is not usually seen as based on a biased perspective.\n\u003c/p\u003e\u003cp\u003eThe English idiom \"rose-colored glasses\" or \"rose-tinted glasses\" refers to perceiving something more positively than it is in reality.\n\u003c/p\u003e\u003cp\u003eThe Romans occasionally referred to this phenomenon with the Latin phrase \"\u003cspan title=\"Latin-language text\"\u003e\u003ci lang=\"la\"\u003ememoria praeteritorum bonorum\u003c/i\u003e\u003c/span\u003e\", which translates into English roughly as \"memory of good past\", or more idiomatically as \"good old days\".\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Hindsight bias",
        "article": "Hindsight_bias",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\u003cp\u003e\u003cb\u003eHindsight bias\u003c/b\u003e, also known as the \u003cb\u003eknew-it-all-along phenomenon\u003c/b\u003e or \u003cb\u003ecreeping determinism\u003c/b\u003e, is the common tendency for people to perceive past events as having been more predictable than they were.\n\u003c/p\u003e\u003cp\u003eAfter an event has occurred, people often believe that they could have predicted or perhaps even known with a high degree of certainty what the outcome of the event would be before it occurred. Hindsight bias may cause distortions of memories of what was known or believed before an event occurred and is a significant source of overconfidence in one’s ability to predict the outcomes of future events. Examples of hindsight bias can be seen in the writings of historians describing the outcomes of battles, in physicians’ recall of clinical trials, and in criminal or civil trials as people tend to assign responsibility on the basis of the supposed predictability of accidents.\n\u003c/p\u003e\u003cp\u003eIn some countries, 20/20 indicates normal visual acuity at 20 feet, from which derives the idiom \"hindsight is 20/20\".\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Outcome bias",
        "article": "Outcome_bias",
        "summary": "\u003cp\u003eThe \u003cb\u003eoutcome bias\u003c/b\u003e is an error made in evaluating the quality of a decision when the outcome of that decision is already known. Specifically, the outcome effect occurs when the same \"behavior produce[s] more ethical condemnation when it happen[s] to produce bad rather than good outcome, even if the outcome is determined by chance.\"\n\u003c/p\u003e\u003cp\u003eWhile similar to the hindsight bias, the two phenomena are markedly different. Hindsight bias focuses on memory distortion to favor the actor, while the outcome bias focuses exclusively on weighting the outcome heavier than other pieces of information in deciding if a past decision was correct.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Moral luck",
        "article": "Moral_luck",
        "summary": "\u003cp\u003e\u003cb\u003eMoral luck\u003c/b\u003e describes circumstances whereby a moral agent is assigned moral blame or praise for an action or its consequences, even if it is clear that said agent did not have full control over either the action or its consequences. This term, introduced by Bernard Williams, has been developed, along with its significance to a coherent moral theory, by Williams and Thomas Nagel in their respective essays on the subject.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Declinism",
        "article": "Declinism",
        "summary": "\u003cp\u003e\u003cb\u003eDeclinism\u003c/b\u003e is the belief that a society or institution is tending towards decline. Particularly, it is the predisposition, caused by cognitive biases such as rosy retrospection, to view the past more favourably and the future more negatively.\n\u003c/p\u003e\u003cp\u003e\"The great summit of declinism\" according to Adam Gopnick, \"was established in 1918, in the book that gave decline its good name in publishing: the German historian Oswald Spengler's best-selling, thousand-page work \u003ci\u003eThe Decline of the West\u003c/i\u003e.\"\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Impact bias",
        "article": "Impact_bias",
        "summary": "\u003cp\u003eIn the psychology of affective forecasting, the \u003cb\u003eimpact bias\u003c/b\u003e, a form of which is the \u003cb\u003edurability bias\u003c/b\u003e, is the tendency for people to overestimate the length or the intensity of future emotional states.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Pessimism bias",
        "article": "Optimism_bias#Pessimism_bias",
        "summary": "\u003cp\u003e\u003cb\u003eOptimism bias\u003c/b\u003e (or the \u003cb\u003eoptimistic bias\u003c/b\u003e) is a cognitive bias that causes someone to believe that they themselves are less likely to experience a negative event. It is also known as \u003cb\u003edelusional optimism\u003c/b\u003e, \u003cb\u003eunrealistic optimism\u003c/b\u003e or \u003cb\u003ecomparative optimism\u003c/b\u003e.\n\u003c/p\u003e\u003cp\u003eOptimism bias is common and transcends gender, ethnicity, nationality, and age. Optimistic biases are even reported in animals such as rats and birds. However, autistic people are less susceptible to optimistic biases.\n\u003c/p\u003e\u003cp\u003eFour factors can cause a person to be optimistically biased: their desired end state, their cognitive mechanisms, the information they have about themselves versus others, and overall mood. The optimistic bias is seen in a number of situations. For example: people believing that they are less at risk of being a crime victim, smokers believing that they are less likely to contract lung cancer or disease than other smokers, first-time bungee jumpers believing that they are less at risk of an injury than other jumpers, or traders who think they are less exposed to potential losses in the markets.\n\u003c/p\u003e\u003cp\u003eAlthough the optimism bias occurs for both positive events (such as believing oneself to be more financially successful than others) and negative events (such as being less likely to have a drinking problem), there is more research and evidence suggesting that the bias is stronger for negative events (the \u003ci\u003evalence effect\u003c/i\u003e). Different consequences result from these two types of events: positive events often lead to feelings of well being and self-esteem, while negative events lead to consequences involving more risk, such as engaging in risky behaviors and not taking precautionary measures for safety.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Planning fallacy",
        "article": "Planning_fallacy",
        "summary": "\u003cp\u003eThe \u003cb\u003eplanning fallacy\u003c/b\u003e is a phenomenon in which predictions about how much time will be needed to complete a future task display an optimism bias and underestimate the time needed. This phenomenon sometimes occurs regardless of the individual's knowledge that past tasks of a similar nature have taken longer to complete than generally planned. The bias affects predictions only about one's own tasks. On the other hand, when outside observers predict task completion times, they tend to exhibit a pessimistic bias, overestimating the time needed. The planning fallacy involves estimates of task completion times more optimistic than those encountered in similar projects in the past.\n\u003c/p\u003e\n\n\u003cp\u003eThe planning fallacy was first proposed by Daniel Kahneman and Amos Tversky in 1979. In 2003, Lovallo and Kahneman proposed an expanded definition as the tendency to underestimate the time, costs, and risks of future actions and at the same time overestimate the benefits of the same actions. According to this definition, the planning fallacy results in not only time overruns, but also cost overruns and benefit shortfalls.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Time-saving bias",
        "article": "Time-saving_bias",
        "summary": "\u003cp\u003e\u003cb\u003eTime-saving bias\u003c/b\u003e is a concept that describes people's tendency to misestimate the time that could be saved (or lost) when increasing (or decreasing) speed.\n\u003c/p\u003e\u003cp\u003eIn general, people underestimate the time that could be saved when increasing from a relatively low speed—e.g., 25 mph (40 km/h) or 40 mph (64 km/h)—and overestimate the time that could be saved when increasing from a relatively high speed—e.g., 55 mph (89 km/h) or 90 mph (140 km/h). People also underestimate the time that could be lost when decreasing from a low speed and overestimate the time that could be lost when decreasing from a high speed.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Pro-innovation bias",
        "article": "Pro-innovation_bias",
        "summary": "\u003cp\u003eIn diffusion of innovation theory, a \u003cb\u003epro-innovation bias\u003c/b\u003e is a belief that innovation should be adopted by the whole society without the need for its alteration. The innovation's \"champion\" has a such strong bias in favor of the innovation, that they may not see its limitations or weaknesses and continue to promote it nonetheless.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Projection bias",
        "article": "Affective_forecasting#Projection_bias",
        "summary": "\u003cp\u003e\n\u003cb\u003eAffective forecasting\u003c/b\u003e, also known as \u003cb\u003ehedonic forecasting\u003c/b\u003e or the \u003cb\u003ehedonic forecasting mechanism\u003c/b\u003e, is the prediction of one's affect (emotional state) in the future. As a process that influences preferences, decisions, and behavior, affective forecasting is studied by both psychologists and economists, with broad applications.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Restraint bias",
        "article": "Restraint_bias",
        "summary": "\u003cp\u003e\u003cb\u003eRestraint bias\u003c/b\u003e is the tendency for people to overestimate their ability to control impulsive behavior. An inflated self-control belief may lead to greater exposure to temptation, and increased impulsiveness. Therefore, the restraint bias has bearing on addiction. For example, someone might use drugs, simply because they believe they can resist any potential addiction.\nAn individual's inability to control, or their temptation can come from several different  visceral impulses. Visceral impulses can include hunger, sexual arousal, and fatigue. These impulses provide information about the current state and behavior needed to keep the body satisfied.\n\u003c/p\u003e\u003cp\u003e\u003cb\u003eEmpathy Gap Effect:\u003c/b\u003e\nThe Empathy Gap Effect deals with individuals having trouble appreciating the power that the impulse states have on their behavior. There is a cold-to-hot empathy gap that states when people are in a cold state, like not experiencing hunger, they tended to underestimate those influences in a hot state. The underestimation of the visceral impulses can be contributed to restricted memory for the visceral experience which means the individual can recall the impulsive state but cannot recreate the sensation of the impulsive state.\n\u003c/p\u003e\u003cp\u003e\u003cb\u003eImpulse Control and Attention:\u003c/b\u003e\nStudies have concluded that when people believe that they have stronger sense of self-control over situations in their environment, they have greater impulse control. Individuals also tend to overestimate their capacity for self-control when one is told that they have a high capacity for self-restraint. The more someone is told that they have a high capacity for self-restraint, the more they believe it and display higher levels of impulse control. Attention has a lot to do with biases, self and impulse controls in our environment. The less attention an individual pays to something, the less control they have over whatever they are doing. Focusing attention to oneself can lead to successful self-control which can be helpful in many aspects of life. Self-control engages conflict between competing pressures, pressures that can be brought on by situational or internal prompts from the environment. Some of the cues make the individual act on or engage in that behavior or act to prevent the individual from taking action.\n\u003c/p\u003e"
    },
    {
        "category": "Not Enough Meaning",
        "subcategory": "We project our current mindset and assumptions onto the past and future",
        "name": "Self-consistency bias",
        "article": "List_of_cognitive_biases#Consistency_bias",
        "summary": "\u003cp\u003eCognitive biases are systematic patterns of deviation from norm and/or rationality in judgment. They are often studied in psychology, sociology and behavioral economics.\n\u003c/p\u003e\u003cp\u003eAlthough the reality of most of these biases is confirmed by reproducible research, there are often controversies about how to classify these biases or how to explain them. Several theoretical causes are known for some cognitive biases, which provides a classification of biases by their common generative mechanism (such as noisy information-processing). Gerd Gigerenzer has criticized the framing of cognitive biases as errors in judgment, and favors interpreting them as arising from rational deviations from logical thought.\n\u003c/p\u003e\u003cp\u003eExplanations include information-processing rules (i.e., mental shortcuts), called \u003ci\u003eheuristics\u003c/i\u003e, that the brain uses to produce decisions or judgments. Biases have a variety of forms and appear as cognitive (\"cold\") bias, such as mental noise, or motivational (\"hot\") bias, such as when beliefs are distorted by wishful thinking. Both effects can be present at the same time.\n\u003c/p\u003e\u003cp\u003eThere are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill; a way to establish a connection with the other person.\n\u003c/p\u003e\u003cp\u003eAlthough this research overwhelmingly involves human subjects, some findings that demonstrate bias have been found in non-human animals as well. For example, loss aversion has been shown in monkeys and hyperbolic discounting has been observed in rats, pigeons, and monkeys.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Overconfidence effect",
        "article": "Overconfidence_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003eoverconfidence effect\u003c/b\u003e is a well-established bias in which a person's subjective \u003ci\u003econfidence\u003c/i\u003e in their judgments is reliably greater than the objective \u003ci\u003eaccuracy\u003c/i\u003e of those judgments, especially when confidence is relatively high. Overconfidence is one example of a miscalibration of subjective probabilities. Throughout the research literature, overconfidence has been defined in three distinct ways: (1) \u003ci\u003eoverestimation\u003c/i\u003e of one's actual performance; (2) \u003ci\u003eoverplacement\u003c/i\u003e of one's performance relative to others; and (3) \u003ci\u003eoverprecision\u003c/i\u003e in expressing unwarranted certainty in the accuracy of one's beliefs.\n\u003c/p\u003e\u003cp\u003eThe most common way in which overconfidence has been studied is by asking people how confident they are of specific beliefs they hold or answers they provide.  The data show that confidence systematically exceeds accuracy, implying people are more sure that they are correct than they deserve to be. If human confidence had perfect calibration, judgments with 100% confidence would be correct 100% of the time, 90% confidence correct 90% of the time, and so on for the other levels of confidence. By contrast, the key finding is that confidence exceeds accuracy so long as the subject is answering hard questions about an unfamiliar topic. For example, in a spelling task, subjects were correct about 80% of the time, whereas they claimed to be 100% certain. Put another way, the error rate was 20% when subjects expected it to be 0%.  In a series where subjects made true-or-false responses to general knowledge statements, they were overconfident at all levels. When they were 100% certain of their answer to a question, they were wrong 20% of the time.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Social desirability bias",
        "article": "Social_desirability_bias",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐dgr65\nCached time: 20240701122010\nCache expiry: 2592000\nReduced expiry: false\nComplications: [vary‐revision‐sha1, is‐preview]\nCPU time usage: 0.058 seconds\nReal time usage: 0.077 seconds\nPreprocessor visited node count: 110/1000000\nPost‐expand include size: 4756/2097152 bytes\nTemplate argument size: 1099/2097152 bytes\nHighest expansion depth: 13/100\nExpensive parser function count: 1/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 1653/5000000 bytes\nLua time usage: 0.031/10.000 seconds\nLua memory usage: 786446/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%   68.658      1 -total\n100.00%   68.658      1 Template:Redirect_category_shell\n 96.20%   66.048      1 Template:Mbox\n 19.48%   13.377      1 Template:R_from_move\n  9.20%    6.318      1 Template:R_from_move/except\n  7.59%    5.211      1 Template:Redirect_template\n  3.13%    2.150      1 Template:Talk_other\n--\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Third-person effect",
        "article": "Third-person_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003ethird-person effect\u003c/b\u003e  hypothesis predicts that people tend to perceive that mass media messages have a greater effect on others than on themselves, based on personal biases. The third-person effect manifests itself through an individual's overestimation of the effect of a mass communicated message on the generalized other, or an underestimation of the effect of a mass communicated message on themselves.\n\u003c/p\u003e\u003cp\u003eThese types of perceptions stem from a self-motivated social desirability (not feeling influenced by mass messages promotes self-esteem), a social-distance corollary (choosing to dissociate oneself from the others who may be influenced), and a perceived exposure to a message (others choose to be influenced by persuasive communication). Other names for the effect are \"Third-person perception\" and \"Web Third-person effect\". From 2015, the effect is named \"Web Third-person effect\" when it is verified in social media, media websites, blogs and in websites in general.  \n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "False consensus effect",
        "article": "False_consensus_effect",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1126788409\"\u003e\n\u003cp\u003eIn psychology, the \u003cb\u003efalse consensus effect\u003c/b\u003e, also known as \u003cb\u003econsensus bias\u003c/b\u003e, is a pervasive cognitive bias that causes people to \"see their own behavioral choices and judgments as relatively common and appropriate to existing circumstances\". In other words, they assume that their personal qualities, characteristics, beliefs, and actions are relatively widespread through the general population.\n\u003c/p\u003e\u003cp\u003eThis false consensus is significant because it increases self-esteem (overconfidence effect). It can be derived from a desire to conform and be liked by others in a social environment. This bias is especially prevalent in group settings where one thinks the collective opinion of their own group matches that of the larger population. Since the members of a group reach a consensus and rarely encounter those who dispute it, they tend to believe that everybody thinks the same way. The false-consensus effect is not restricted to cases where people believe that their values are shared by the majority, but it still manifests as an overestimate of the extent of their belief.\n\u003c/p\u003e\u003cp\u003eAdditionally, when confronted with evidence that a consensus does not exist, people often assume that those who do not agree with them are defective in some way. There is no single cause for this cognitive bias; the availability heuristic, self-serving bias, and naïve realism have been suggested as at least partial underlying factors. The bias may also result, at least in part, from non-social stimulus-reward associations. Maintenance of this cognitive bias may be related to the tendency to make decisions with relatively little information. When faced with uncertainty and a limited sample from which to make decisions, people often \"project\" themselves onto the situation. When this personal knowledge is used as input to make generalizations, it often results in the false sense of being part of the majority.\n\u003c/p\u003e\u003cp\u003eThe false consensus effect has been widely observed and supported by empirical evidence. Previous research has suggested that cognitive and perceptional factors (motivated projection, accessibility of information, emotion, etc.) may contribute to the consensus bias, while recent studies have focused on its neural mechanisms. One recent study has shown that consensus bias may improve decisions about other people's preferences. Ross, Green and House first defined the false consensus effect in 1977 with emphasis on the relative commonness that people perceive about their own responses; however, similar projection phenomena had already caught attention in psychology. Specifically, concerns with respect to connections between individual's personal predispositions and their estimates of peers appeared in the literature for a while. For instances, Katz and Allport in 1931 illustrated that students’ estimates of the amount of others on the frequency of cheating was positively correlated to their own behavior. Later, around 1970, same phenomena were found on political beliefs and prisoner's dilemma situation. In 2017, researchers identified a persistent egocentric bias when participants learned about other people's snack-food preferences. Moreover, recent studies suggest that the false consensus effect can also affect professional decision makers; specifically, it has been shown that even experienced marketing managers project their personal product preferences onto consumers.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Hard-easy effect",
        "article": "Hard-easy_effect",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐dc82l\nCached time: 20240701122011\nCache expiry: 2592000\nReduced expiry: false\nComplications: [vary‐revision‐sha1, is‐preview]\nCPU time usage: 0.023 seconds\nReal time usage: 0.035 seconds\nPreprocessor visited node count: 43/1000000\nPost‐expand include size: 1141/2097152 bytes\nTemplate argument size: 0/2097152 bytes\nHighest expansion depth: 8/100\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 0/5000000 bytes\nLua time usage: 0.007/10.000 seconds\nLua memory usage: 627552/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%   29.479      1 Template:R_from_move\n100.00%   29.479      1 -total\n 74.31%   21.907      1 Template:Redirect_template\n 19.07%    5.621      1 Template:R_from_move/except\n--\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Lake Wobegone effect",
        "article": "Lake_Wobegon#The_Lake_Wobegon_effect",
        "summary": "\u003cp\u003e\u003cb\u003eLake Wobegon\u003c/b\u003e is a fictional town created by Garrison Keillor as the setting of the recurring segment \"News from Lake Wobegon\" for the radio program \u003ci\u003eA Prairie Home Companion\u003c/i\u003e broadcast from St Paul, Minnesota. The fictional town serves as the setting for many of Keillor's stories and novels, gaining an international audience with \u003ci\u003eLake Wobegon Days\u003c/i\u003e in 1985. Described as a small rural town in central Minnesota, the events and adventures of the townspeople provided Keillor with a wealth of humorous and often touching stories.\n\u003c/p\u003e\u003cp\u003eKeillor has said that people often ask him if it is a real town, and when he replied that it was not, they seemed disappointed because \"people want stories to be true\". So he began to say it was in \"central Minnesota, near Stearns County, up around Holdingford, not far from St. Rosa and Albany and Freeport, northwest of St. Cloud\", which he says is \"sort of the truth, I guess\".\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Dunning-Kruger effect",
        "article": "Dunning-Kruger_effect",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐dgr65\nCached time: 20240701122012\nCache expiry: 2592000\nReduced expiry: false\nComplications: [vary‐revision‐sha1, is‐preview]\nCPU time usage: 0.074 seconds\nReal time usage: 0.103 seconds\nPreprocessor visited node count: 154/1000000\nPost‐expand include size: 12193/2097152 bytes\nTemplate argument size: 4265/2097152 bytes\nHighest expansion depth: 13/100\nExpensive parser function count: 1/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 1653/5000000 bytes\nLua time usage: 0.035/10.000 seconds\nLua memory usage: 926491/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%   88.699      1 Template:Redirect_category_shell\n100.00%   88.699      1 -total\n 96.19%   85.323      1 Template:Mbox\n 12.64%   11.208      1 Template:Redirect_from_move\n 11.10%    9.850      3 Template:Redirect_template\n 10.26%    9.104      1 Template:Redirect_from_alternative_hyphenation\n  7.69%    6.818      1 Template:R_from_move/except\n  7.45%    6.605      1 Template:Redirect_unprintworthy\n  2.73%    2.421      1 Template:Big\n  2.53%    2.246      1 Template:Talk_other\n--\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Egocentric bias",
        "article": "Egocentric_bias",
        "summary": "\u003cp\u003e\u003cb\u003eEgocentric bias\u003c/b\u003e is the tendency to rely too heavily on one's own perspective and/or have a higher opinion of oneself than reality. It appears to be the result of the psychological need to satisfy one's ego and to be advantageous for memory consolidation. Research has shown  that experiences, ideas, and beliefs are more easily recalled when they match one's own, causing an egocentric outlook. Michael Ross and Fiore Sicoly first identified this cognitive bias in their 1979 paper, \"Egocentric biases in availability and attribution\". Egocentric bias is referred to by most psychologists as a general umbrella term under which other related phenomena fall.\n\u003c/p\u003e\u003cp\u003eThe effects of egocentric bias can differ based on personal characteristics, such as age and the number of languages one speaks.   Thus far, there have been many studies focusing on specific implications of egocentric bias in different contexts.  Research on collaborative group tasks have emphasized that people view their own contributions differently than they view that of others.  Other areas of research have been aimed at studying how mental health patients display egocentric bias, and at the relationship between egocentric bias and voter distribution.  These types of studies surrounding egocentric bias usually involve written or verbal questionnaires, based on the subject's personal life or their decision in various hypothetical scenarios.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Optimism bias",
        "article": "Optimism_bias",
        "summary": "\u003cp\u003e\u003cb\u003eOptimism bias\u003c/b\u003e (or the \u003cb\u003eoptimistic bias\u003c/b\u003e) is a cognitive bias that causes someone to believe that they themselves are less likely to experience a negative event. It is also known as \u003cb\u003edelusional optimism\u003c/b\u003e, \u003cb\u003eunrealistic optimism\u003c/b\u003e or \u003cb\u003ecomparative optimism\u003c/b\u003e.\n\u003c/p\u003e\u003cp\u003eOptimism bias is common and transcends gender, ethnicity, nationality, and age. Optimistic biases are even reported in animals such as rats and birds. However, autistic people are less susceptible to optimistic biases.\n\u003c/p\u003e\u003cp\u003eFour factors can cause a person to be optimistically biased: their desired end state, their cognitive mechanisms, the information they have about themselves versus others, and overall mood. The optimistic bias is seen in a number of situations. For example: people believing that they are less at risk of being a crime victim, smokers believing that they are less likely to contract lung cancer or disease than other smokers, first-time bungee jumpers believing that they are less at risk of an injury than other jumpers, or traders who think they are less exposed to potential losses in the markets.\n\u003c/p\u003e\u003cp\u003eAlthough the optimism bias occurs for both positive events (such as believing oneself to be more financially successful than others) and negative events (such as being less likely to have a drinking problem), there is more research and evidence suggesting that the bias is stronger for negative events (the \u003ci\u003evalence effect\u003c/i\u003e). Different consequences result from these two types of events: positive events often lead to feelings of well being and self-esteem, while negative events lead to consequences involving more risk, such as engaging in risky behaviors and not taking precautionary measures for safety.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Forer effect",
        "article": "Barnum_effect",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1033289096\"\u003e\n\u003cp class=\"mw-empty-elt\"\u003e\n\n\u003c/p\u003e\u003cp\u003eThe \u003cb\u003eBarnum effect\u003c/b\u003e, also called the \u003cb\u003eForer effect\u003c/b\u003e or, less commonly, the \u003cb\u003eBarnum–Forer effect\u003c/b\u003e, is a common psychological phenomenon whereby individuals give high accuracy ratings to descriptions of their personality that supposedly are tailored specifically to them, yet which are in fact vague and general enough to apply to a wide range of people. This effect can provide a partial explanation for the widespread acceptance of some paranormal beliefs and practices, such as astrology, fortune telling, aura reading, and some types of personality tests.\n\u003c/p\u003e\u003cp\u003ePsychologist Bertram Forer originally named it the \"fallacy of personal validation\". The term \"Barnum effect\" was coined in 1956 by psychologist Paul Meehl in his essay \"Wanted – A Good Cookbook\", because he relates the vague personality descriptions used in certain \"pseudo-successful\" psychological tests to those given by showman P. T. Barnum.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Barnum effect",
        "article": "Barnum_effect",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1033289096\"\u003e\n\u003cp class=\"mw-empty-elt\"\u003e\n\n\u003c/p\u003e\u003cp\u003eThe \u003cb\u003eBarnum effect\u003c/b\u003e, also called the \u003cb\u003eForer effect\u003c/b\u003e or, less commonly, the \u003cb\u003eBarnum–Forer effect\u003c/b\u003e, is a common psychological phenomenon whereby individuals give high accuracy ratings to descriptions of their personality that supposedly are tailored specifically to them, yet which are in fact vague and general enough to apply to a wide range of people. This effect can provide a partial explanation for the widespread acceptance of some paranormal beliefs and practices, such as astrology, fortune telling, aura reading, and some types of personality tests.\n\u003c/p\u003e\u003cp\u003ePsychologist Bertram Forer originally named it the \"fallacy of personal validation\". The term \"Barnum effect\" was coined in 1956 by psychologist Paul Meehl in his essay \"Wanted – A Good Cookbook\", because he relates the vague personality descriptions used in certain \"pseudo-successful\" psychological tests to those given by showman P. T. Barnum.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Self-serving bias",
        "article": "Self-serving_bias",
        "summary": "\u003cp\u003eA \u003cb\u003eself-serving bias\u003c/b\u003e is any cognitive or perceptual process that is distorted by the need to maintain and enhance self-esteem, or the tendency to perceive oneself in an overly favorable manner. It is the belief that individuals tend to ascribe success to their own abilities and efforts, but ascribe failure to external factors. When individuals reject the validity of negative feedback, focus on their strengths and achievements but overlook their faults and failures, or take more credit for their group's work than they give to other members, they are protecting their self-esteem from threat and injury. These cognitive and perceptual tendencies perpetuate illusions and error, but they also serve the self's need for esteem.  For example, a student who attributes earning a good grade on an exam to their own intelligence and preparation but attributes earning a poor grade to the teacher's poor teaching ability or unfair test questions might be exhibiting a self-serving bias. Studies have shown that similar attributions are made in various situations, such as the workplace, interpersonal relationships, sports, and consumer decisions.\n\u003c/p\u003e\u003cp\u003eBoth motivational processes (i.e. self-enhancement, self-presentation) and cognitive processes (i.e. locus of control, self-esteem) influence the self-serving bias. There are both cross-cultural (i.e. individualistic and collectivistic culture differences) and special clinical population (i.e. depression) considerations within the bias. Much of the research on the self-serving bias has used participant self-reports of attribution based on experimental manipulation of task outcomes or in naturalistic situations. Some more modern research, however, has shifted focus to physiological manipulations, such as emotional inducement and neural activation, in an attempt to better understand the biological mechanisms that contribute to the self-serving bias.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Actor-observer bias",
        "article": "Actor-observer_asymmetry#bias",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐n99tg\nCached time: 20240701122013\nCache expiry: 2592000\nReduced expiry: false\nComplications: [is‐preview]\nCPU time usage: 0.032 seconds\nReal time usage: 0.047 seconds\nPreprocessor visited node count: 206/1000000\nPost‐expand include size: 10596/2097152 bytes\nTemplate argument size: 759/2097152 bytes\nHighest expansion depth: 7/100\nExpensive parser function count: 0/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 0/5000000 bytes\nLua time usage: 0.006/10.000 seconds\nLua memory usage: 627520/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%   34.614      1 Template:R_from_modification\n100.00%   34.614      1 -total\n 93.14%   32.238      1 Template:Redirect_template\n 17.10%    5.920     11 Template:Tl\n  5.04%    1.745      1 Template:Em\n  5.02%    1.737     22 Template:Nowrap\n--\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Illusion of control",
        "article": "Illusion_of_control",
        "summary": "\u003cp\u003eThe \u003cb\u003eillusion of control\u003c/b\u003e is the tendency for people to overestimate their ability to control events. It was named by U.S. psychologist Ellen Langer and is thought to influence gambling behavior and belief in the paranormal. Along with illusory superiority and optimism bias, the illusion of control is one of the positive illusions.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Illusory superiority",
        "article": "Illusory_superiority",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\n\n\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\n\n\u003cp\u003eIn social psychology, \u003cb\u003eillusory superiority\u003c/b\u003e is a cognitive bias wherein people overestimate their own qualities and abilities compared to others. Illusory superiority is one of many positive illusions, relating to the self, that are evident in the study of intelligence, the effective performance of tasks and tests, and the possession of desirable personal characteristics and personality traits. Overestimation of abilities compared to an objective measure is known as the \u003ci\u003eoverconfidence effect\u003c/i\u003e.\n\u003c/p\u003e\u003cp\u003eThe term \"illusory superiority\" was first used by the researchers Van Yperen and Buunk, in 1991. The phenomenon is also known as the \u003cb\u003eabove-average effect\u003c/b\u003e, the \u003cb\u003esuperiority bias\u003c/b\u003e, the \u003cb\u003eleniency error\u003c/b\u003e, the \u003cb\u003esense of relative superiority\u003c/b\u003e, the \u003cb\u003e\u003ci\u003eprimus inter pares\u003c/i\u003e effect\u003c/b\u003e, and the \u003cb\u003eLake Wobegon effect\u003c/b\u003e, named after the fictional town where all the children are above average. The Dunning-Kruger effect is a form of illusory superiority shown by people on a task where their level of skill is low.\n\u003c/p\u003e\u003cp\u003e\nA vast majority of the literature on illusory superiority originates from studies on participants in the United States. However, research that only investigates the effects in one specific population is severely limited as this may not be a true representation of human psychology. More recent research investigating self-esteem in other countries suggests that illusory superiority depends on culture. Some studies indicate that East Asians tend to underestimate their own abilities in order to improve themselves and get along with others.\u003c/p\u003e\n"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Fundamental attribution error",
        "article": "Fundamental_attribution_error",
        "summary": "\u003cp\u003eIn social psychology, \u003cb\u003efundamental attribution error\u003c/b\u003e, also known as \u003cb\u003ecorrespondence bias\u003c/b\u003e or \u003cb\u003eattribution effect\u003c/b\u003e, is a cognitive attribution bias in which observers underemphasize situational and environmental factors for the behavior of an actor while overemphasizing dispositional or personality factors. In other words, observers tend to overattribute the behaviors of others to their personality (e.g., \u003ci\u003ehe is late because he's selfish\u003c/i\u003e) and underattribute them to the situation or context (e.g., \u003ci\u003ehe is late because he got stuck in traffic\u003c/i\u003e). Although personality traits and predispositions are considered to be observable facts in psychology, the fundamental attribution error is an error because it misinterprets their effects.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Defensive attribution hypothesis",
        "article": "Defensive_attribution_hypothesis",
        "summary": "\u003cp\u003eThe \u003cb\u003edefensive attribution hypothesis\u003c/b\u003e (or \u003ci\u003ebias\u003c/i\u003e, \u003ci\u003etheory\u003c/i\u003e, or simply \u003ci\u003e\u003cb\u003edefensive attribution\u003c/b\u003e\u003c/i\u003e) is a social psychological term where an observer attributes the causes for a mishap to minimize their fear of being a victim or a cause in a similar situation. The attributions of blame are negatively correlated to similarities between the observer and the people involved in the mishap, i.e. more responsibility is attributed to the people involved who are dissimilar to the observer. Assigning responsibility allows the observer to believe that the mishap was controllable and thus preventable.\n\u003c/p\u003e\u003cp\u003eA defensive attribution may also be used to protect the person's self-esteem if, despite everything, the mishap does occur, because blame can be assigned to the \"other\" (person or situation). The use of defensive attributions is considered a cognitive bias because an individual will change their beliefs about a situation based upon their motivations or desires rather than the factual characteristics of the situation.\u003csup class=\"reference nowrap\"\u003e\u003cspan title=\"Page / location: 112\"\u003e: 112 \u003c/span\u003e\u003c/sup\u003e\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Trait ascription bias",
        "article": "Trait_ascription_bias",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\n\u003cp\u003e\u003cb\u003eTrait ascription bias\u003c/b\u003e is the tendency for people to view \u003ci\u003ethemselves\u003c/i\u003e as relatively variable in terms of personality, behavior and mood while viewing others as much more predictable in their personal traits across different situations. More specifically, it is a tendency to describe one's own behaviour in terms of situational factors while preferring to describe another's behaviour by ascribing fixed dispositions to their personality. This may occur because peoples' own internal states are more readily observable and available to them than those of others.\n\u003c/p\u003e\u003cp\u003eThis attributional bias intuitively plays a role in the formation and maintenance of stereotypes and prejudice, combined with the negativity effect. However, trait ascription and trait-based models of personality remain contentious in modern psychology and social science research. Trait ascription bias refers to the situational and dispositional evaluation and description of personality traits on a personal level. A similar bias on the group level is called the outgroup homogeneity bias.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Effort justification",
        "article": "Effort_justification",
        "summary": "\u003cp\u003e\u003cb\u003eEffort justification\u003c/b\u003e is an idea and paradigm in social psychology stemming from Leon Festinger's theory of cognitive dissonance. Effort justification is a person's tendency to attribute the value of an outcome they put effort into achieving as greater than the objective value of the outcome.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Risk compensation",
        "article": "Risk_compensation",
        "summary": "\u003cp\u003e\u003cb\u003eRisk compensation\u003c/b\u003e  is a theory which suggests that people typically adjust their behavior in response to perceived levels of risk, becoming more careful where they sense greater risk and less careful if they feel more protected. Although usually small in comparison to the fundamental benefits of safety interventions, it may result in a lower net benefit than expected or even higher risks.\n\u003c/p\u003e\u003cp\u003eBy way of example, it has been observed that motorists drove closer to the vehicle in front when the vehicles were fitted with anti-lock brakes. There is also evidence that the risk compensation phenomenon could explain the failure of condom distribution programs to reverse HIV prevalence and that condoms may foster disinhibition, with people engaging in risky sex both with and without condoms.\n\u003c/p\u003e\u003cp\u003eBy contrast, shared space is an urban street design method which consciously aims to increase the level of perceived risk and uncertainty, thereby slowing traffic and reducing the number and seriousness of injuries.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To act, we must be confident we can make an impact and feel what we do is important",
        "name": "Peltzman effect",
        "article": "Risk_compensation#Peltzman_effect",
        "summary": "\u003cp\u003e\u003cb\u003eRisk compensation\u003c/b\u003e  is a theory which suggests that people typically adjust their behavior in response to perceived levels of risk, becoming more careful where they sense greater risk and less careful if they feel more protected. Although usually small in comparison to the fundamental benefits of safety interventions, it may result in a lower net benefit than expected or even higher risks.\n\u003c/p\u003e\u003cp\u003eBy way of example, it has been observed that motorists drove closer to the vehicle in front when the vehicles were fitted with anti-lock brakes. There is also evidence that the risk compensation phenomenon could explain the failure of condom distribution programs to reverse HIV prevalence and that condoms may foster disinhibition, with people engaging in risky sex both with and without condoms.\n\u003c/p\u003e\u003cp\u003eBy contrast, shared space is an urban street design method which consciously aims to increase the level of perceived risk and uncertainty, thereby slowing traffic and reducing the number and seriousness of injuries.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To stay focused, we favor the immediate, relatable thing in front of us",
        "name": "Hyperbolic discounting",
        "article": "Hyperbolic_discounting",
        "summary": "\u003cp\u003eIn economics, \u003cb\u003ehyperbolic discounting\u003c/b\u003e is a time-\u003ci\u003einconsistent\u003c/i\u003e model of delay discounting. It is one of the cornerstones of behavioral economics and its brain-basis is actively being studied by neuroeconomics researchers.\n\u003c/p\u003e\u003cp\u003eAccording to the discounted utility approach, intertemporal choices are no different from other choices, except that some consequences are delayed and hence must be anticipated and discounted (i.e., reweighted to take into account the delay).\n\u003c/p\u003e\u003cp\u003eGiven two similar rewards, humans show a preference for one that arrives in a more prompt timeframe. Humans are said to \u003ci\u003ediscount\u003c/i\u003e the value of the later reward, by a factor that increases with the length of the delay. In the financial world, this process is normally modeled in the form of exponential discounting, a time-\u003ci\u003econsistent\u003c/i\u003e model of discounting. Many psychological studies have since demonstrated deviations in instinctive preference from the constant discount rate assumed in exponential discounting. Hyperbolic discounting is an alternative mathematical model that agrees more closely with these findings.\n\u003c/p\u003e\u003cp\u003eAccording to hyperbolic discounting, valuations fall relatively rapidly for earlier delay periods (as in, from now to one week), but then fall more slowly for longer delay periods (for instance, more than a few days). For example, in an early study subjects said they would be indifferent between receiving $15 immediately or $30 after 3 months, $60 after 1 year, or $100 after 3 years. These indifferences reflect annual discount rates that declined from 277% to 139% to 63% as delays got longer.  This contrasts with exponential discounting, in which valuation falls by a constant factor per unit delay and the discount rate stays the same.\n\u003c/p\u003e\u003cp\u003eThe standard experiment used to reveal a test subject's hyperbolic discounting curve is to compare short-term preferences with long-term preferences. For instance: \"Would you prefer a dollar today or three dollars tomorrow?\" or \"Would you prefer a dollar in one year or three dollars in one year and one day?\" It has been claimed that a significant fraction of subjects will take the lesser amount today, but will gladly wait one extra day in a year in order to receive the higher amount instead.  Individuals with such preferences are described as \"present-biased\".\n\u003c/p\u003e\u003cp\u003eThe most important consequence of hyperbolic discounting is that it creates temporary preferences for small rewards that occur sooner over larger, later ones. Individuals using hyperbolic discounting reveal a strong tendency to make choices that are inconsistent over time – they make choices today that their future self would prefer not to have made, despite knowing the same information. This dynamic inconsistency happens because hyperbolas distort the relative value of options with a fixed difference in delays in proportion to how far the choice-maker is from those options.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To stay focused, we favor the immediate, relatable thing in front of us",
        "name": "Appeal to novelty",
        "article": "Appeal_to_novelty",
        "summary": "\u003cp\u003eThe \u003cb\u003eappeal to novelty\u003c/b\u003e (also called \u003cb\u003eappeal to modernity\u003c/b\u003e or \u003ci\u003e\u003cb\u003eargumentum ad novitatem\u003c/b\u003e\u003c/i\u003e) is a fallacy in which one prematurely claims that an idea or proposal is correct or superior, \u003ci\u003eexclusively\u003c/i\u003e because it is new and modern. In a controversy between status quo and new inventions, an appeal to novelty argument is not in itself a valid argument. The fallacy may take two forms: overestimating the new and modern, prematurely and without investigation assuming it to be best-case, or underestimating status quo, prematurely and without investigation assuming it to be worst-case.\n\u003c/p\u003e\u003cp\u003eInvestigation may prove these claims to be true, but it is a fallacy to prematurely conclude this \u003ci\u003eonly from the general claim that all novelty is good\u003c/i\u003e.\n\u003c/p\u003e\u003cp\u003eChronological snobbery is a form of appeal to novelty, in which one argues that the only relevant knowledge and practices are those established in the last decades. The opposite of an appeal to novelty is an appeal to tradition, in which one argues that the \"old ways\" are always superior to new ideas.\n\u003c/p\u003e\u003cp\u003eAppeals to novelty are often successful in a modern world where everyone is eager to be on the \"cutting edge\" of technology. The dot-com bubble of the early 2000s could easily be interpreted as a sign of the dangers of naïvely embracing new ideas without first viewing them with a critical eye. Also, advertisers frequently extoll the newness of their products as a reason to buy.  Conversely, this is satirised by skeptics as bleeding edge technology, which may itself be an example of an appeal to tradition.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To stay focused, we favor the immediate, relatable thing in front of us",
        "name": "Identifiable victim effect",
        "article": "Identifiable_victim_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003eidentifiable victim effect\u003c/b\u003e is the tendency of individuals to offer greater aid when a specific, identifiable person (\"victim\") is observed under hardship, as compared to a large, vaguely defined group with the same need. \n\u003c/p\u003e\u003cp\u003eThe identifiable victim effect has two components. People are more inclined to help an identified victim than an unidentified one, and people are more inclined to help a single identified victim than a group of identified victims. Although helping an identified victim may be commendable, the identifiable victim effect is considered a cognitive bias. From a consequentialist point of view, the cognitive error is the failure to offer N times as much help to N unidentified victims.\n\u003c/p\u003e\u003cp\u003eThe identifiable victim effect has a mirror image that is sometimes called the identifiable perpetrator effect. Research has shown that individuals are more inclined to mete out punishment, even at their own expense, when they are punishing a specific, identified perpetrator.\n\u003c/p\u003e\u003cp\u003eThe conceptualization of the identifiable victim effect as it is known today is commonly attributed to American economist Thomas Schelling. He wrote that harm to a particular person invokes “anxiety and sentiment, guilt and awe, responsibility and religion, [but]…most of this awesomeness disappears when we deal with statistical death”.\n\u003c/p\u003e\u003cp\u003eHistorical figures from Joseph Stalin to Mother Teresa are credited with statements that epitomize the identifiable victim effect. The remark \"One death is a tragedy; a million deaths is a statistic\" is widely, although probably incorrectly, attributed to Stalin. The remark \"If I look at the mass I will never act. If I look at the one, I will,\" is attributed to Mother Teresa.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Sunk cost fallacy",
        "article": "Sunk_cost#Loss_aversion_and_the_sunk_cost_fallacy",
        "summary": "\u003cp\u003eIn economics and business decision-making, a \u003cb\u003esunk cost\u003c/b\u003e (also known as \u003cb\u003eretrospective cost\u003c/b\u003e) is a cost that has already been incurred and cannot be recovered. Sunk costs are contrasted with \u003ci\u003eprospective costs\u003c/i\u003e, which are future costs that may be avoided if action is taken. In other words, a sunk cost is a sum paid in the past that is no longer relevant to decisions about the future. Even though economists argue that sunk costs are no longer relevant to future rational decision-making, people in everyday life often take previous expenditures in situations, such as repairing a car or house, into their future decisions regarding those properties.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Irrational escalation",
        "article": "Escalation_of_commitment",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\u003cp\u003e\n\u003cb\u003eEscalation of commitment\u003c/b\u003e is a human behavior pattern in which an individual or group facing increasingly negative outcomes from a decision, action, or investment nevertheless continue the behavior instead of altering course. The actor maintains behaviors that are irrational, but align with previous decisions and actions.\n\u003c/p\u003e\u003cp\u003eEconomists and behavioral scientists use a related term, \u003ci\u003esunk-cost fallacy\u003c/i\u003e, to describe the justification of increased investment of money or effort in a decision, based on the cumulative prior investment (\"sunk cost\") despite new evidence suggesting that the future cost of continuing the behavior outweighs the expected benefit.\n\u003c/p\u003e\u003cp\u003eIn sociology, \u003ci\u003eirrational escalation of commitment\u003c/i\u003e or \u003ci\u003ecommitment bias\u003c/i\u003e describe similar behaviors. The phenomenon and the sentiment underlying them are reflected in such proverbial images as \"throwing good money after bad\", or \"In for a penny, in for a pound\", or \"It's never the wrong time to make the right decision\", or \"If you find yourself in a hole, stop digging.\"\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Escalation of commitment",
        "article": "Escalation_of_commitment",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\u003cp\u003e\n\u003cb\u003eEscalation of commitment\u003c/b\u003e is a human behavior pattern in which an individual or group facing increasingly negative outcomes from a decision, action, or investment nevertheless continue the behavior instead of altering course. The actor maintains behaviors that are irrational, but align with previous decisions and actions.\n\u003c/p\u003e\u003cp\u003eEconomists and behavioral scientists use a related term, \u003ci\u003esunk-cost fallacy\u003c/i\u003e, to describe the justification of increased investment of money or effort in a decision, based on the cumulative prior investment (\"sunk cost\") despite new evidence suggesting that the future cost of continuing the behavior outweighs the expected benefit.\n\u003c/p\u003e\u003cp\u003eIn sociology, \u003ci\u003eirrational escalation of commitment\u003c/i\u003e or \u003ci\u003ecommitment bias\u003c/i\u003e describe similar behaviors. The phenomenon and the sentiment underlying them are reflected in such proverbial images as \"throwing good money after bad\", or \"In for a penny, in for a pound\", or \"It's never the wrong time to make the right decision\", or \"If you find yourself in a hole, stop digging.\"\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Generation effect",
        "article": "Generation_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003egeneration effect\u003c/b\u003e is a phenomenon whereby information is better remembered if it is generated from one's own mind rather than simply read. Researchers have struggled to account for why the generated information is better recalled than read information, but no single explanation has been sufficient to explain everything.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Loss aversion",
        "article": "Loss_aversion",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\n\n\u003cp\u003e\u003cb\u003eLoss aversion\u003c/b\u003e is a psychological and economic concept, which refers to how outcomes are interpreted as gains and losses where losses are subject to more sensitivity in people's responses compared to equivalent gains acquired. Kahneman and Tversky (1992) suggested that losses can be twice as powerful psychologically as gains.\n\u003c/p\u003e\u003cp\u003eWhen defined in terms of the utility function shape as in the cumulative prospect theory (CPT), losses have a steeper utility than gains, thus being more \"painful\" than the satisfaction from a comparable gain, as shown in Figure 1. Loss aversion was first proposed by Amos Tversky and Daniel Kahneman as an important framework for prospect theory – an analysis of decision under risk. Finance and insurance are the sub fields of economics with the most active applications.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "IKEA effect",
        "article": "IKEA_effect",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\n\u003cp\u003eThe \u003cb\u003eIKEA effect\u003c/b\u003e is a cognitive bias in which consumers place a disproportionately high value on products they partially created. The name refers to Swedish manufacturer and furniture retailer IKEA, which sells many items of furniture that require assembly.\n\u003c/p\u003e\u003cp\u003eA 2011 study found that subjects were willing to pay 63% more for furniture they had assembled themselves than for equivalent pre-assembled items.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Unit bias",
        "article": "List_of_cognitive_biases",
        "summary": "\u003cp\u003eCognitive biases are systematic patterns of deviation from norm and/or rationality in judgment. They are often studied in psychology, sociology and behavioral economics.\n\u003c/p\u003e\u003cp\u003eAlthough the reality of most of these biases is confirmed by reproducible research, there are often controversies about how to classify these biases or how to explain them. Several theoretical causes are known for some cognitive biases, which provides a classification of biases by their common generative mechanism (such as noisy information-processing). Gerd Gigerenzer has criticized the framing of cognitive biases as errors in judgment, and favors interpreting them as arising from rational deviations from logical thought.\n\u003c/p\u003e\u003cp\u003eExplanations include information-processing rules (i.e., mental shortcuts), called \u003ci\u003eheuristics\u003c/i\u003e, that the brain uses to produce decisions or judgments. Biases have a variety of forms and appear as cognitive (\"cold\") bias, such as mental noise, or motivational (\"hot\") bias, such as when beliefs are distorted by wishful thinking. Both effects can be present at the same time.\n\u003c/p\u003e\u003cp\u003eThere are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill; a way to establish a connection with the other person.\n\u003c/p\u003e\u003cp\u003eAlthough this research overwhelmingly involves human subjects, some findings that demonstrate bias have been found in non-human animals as well. For example, loss aversion has been shown in monkeys and hyperbolic discounting has been observed in rats, pigeons, and monkeys.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Zero-risk bias",
        "article": "Zero-risk_bias",
        "summary": "\u003cp\u003e\u003cb\u003eZero-risk bias\u003c/b\u003e is a tendency to prefer the complete elimination of risk in a sub-part over alternatives with greater \u003ci\u003eoverall\u003c/i\u003e risk reduction. It often manifests in cases where decision makers address problems concerning health, safety, and the environment. Its effect on decision making has been observed in surveys presenting hypothetical scenarios.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Disposition effect",
        "article": "Disposition_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003edisposition effect\u003c/b\u003e is an anomaly discovered in behavioral finance. It relates to the tendency of investors to sell assets that have increased in value, while keeping assets that have dropped in value.\n\u003c/p\u003e\u003cp\u003eHersh Shefrin and Meir Statman identified and named the effect in their 1985 paper, which found that people dislike losing significantly more than they enjoy winning. The disposition effect has been described as one of the foremost vigorous actualities around individual investors because investors will hold stocks that have lost value yet sell stocks that have gained value.\"\n\u003c/p\u003e\u003cp\u003eIn 1979, Daniel Kahneman and Amos Tversky traced the cause of the disposition effect to the so-called \"prospect theory\". The prospect theory proposes that when an individual is presented with two equal choices, one having possible gains and the other with possible losses, the individual is more likely to opt for the former choice even though both would yield the same economic result.\n\u003c/p\u003e\u003cp\u003eThe disposition effect can be minimized by a mental approach called \"hedonic framing\".\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Pseudocertainty effect",
        "article": "Pseudocertainty_effect",
        "summary": "\u003cp\u003eIn prospect theory, the \u003cb\u003epseudocertainty effect\u003c/b\u003e is the tendency for people to perceive an outcome as certain while it is actually uncertain in multi-stage decision making. The evaluation of the certainty of the outcome in a previous stage of decisions is disregarded when selecting an option in subsequent stages. Not to be confused with certainty effect, the pseudocertainty effect was discovered from an attempt at providing a normative use of decision theory for the certainty effect by relaxing the cancellation rule.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Processing difficulty effect",
        "article": "List_of_cognitive_biases#Processing_difficulty_effect",
        "summary": "\u003cp\u003eCognitive biases are systematic patterns of deviation from norm and/or rationality in judgment. They are often studied in psychology, sociology and behavioral economics.\n\u003c/p\u003e\u003cp\u003eAlthough the reality of most of these biases is confirmed by reproducible research, there are often controversies about how to classify these biases or how to explain them. Several theoretical causes are known for some cognitive biases, which provides a classification of biases by their common generative mechanism (such as noisy information-processing). Gerd Gigerenzer has criticized the framing of cognitive biases as errors in judgment, and favors interpreting them as arising from rational deviations from logical thought.\n\u003c/p\u003e\u003cp\u003eExplanations include information-processing rules (i.e., mental shortcuts), called \u003ci\u003eheuristics\u003c/i\u003e, that the brain uses to produce decisions or judgments. Biases have a variety of forms and appear as cognitive (\"cold\") bias, such as mental noise, or motivational (\"hot\") bias, such as when beliefs are distorted by wishful thinking. Both effects can be present at the same time.\n\u003c/p\u003e\u003cp\u003eThere are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill; a way to establish a connection with the other person.\n\u003c/p\u003e\u003cp\u003eAlthough this research overwhelmingly involves human subjects, some findings that demonstrate bias have been found in non-human animals as well. For example, loss aversion has been shown in monkeys and hyperbolic discounting has been observed in rats, pigeons, and monkeys.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Endowment effect",
        "article": "Endowment_effect",
        "summary": "\u003cp\u003eIn psychology and behavioral economics, the \u003cb\u003eendowment effect\u003c/b\u003e, also known as \u003cb\u003edivestiture aversion\u003c/b\u003e, is the finding that people are more likely to retain an object they own than acquire that same object when they do not own it. The endowment theory can be defined as \"an application of prospect theory positing that loss aversion associated with ownership explains observed exchange asymmetries.\"\n\u003c/p\u003e\u003cp\u003eThis is typically illustrated in two ways. In a valuation paradigm, people's maximum willingness to pay (WTP) to acquire an object is typically lower than the least amount they are willing to accept (WTA) to give up that same object when they own it—even when there is no cause for attachment, or even if the item was only obtained minutes ago. In an exchange paradigm, people given a good are reluctant to trade it for another good of similar value. For example, participants first given a pen of equal expected value to that of a coffee mug were generally unwilling to trade, whilst participants first given the coffee mug were also unwilling to trade it for the pen.\n\u003c/p\u003e\u003cp\u003eA more controversial third paradigm used to elicit the endowment effect is the mere ownership paradigm, primarily used in experiments in psychology, marketing, and organizational behavior. In this paradigm, people who are randomly assigned to receive a good (\"owners\") evaluate it more positively than people who are not randomly assigned to receive the good (\"controls\"). The distinction between this paradigm and the first two is that it is not incentive-compatible. In other words, participants are not explicitly incentivized to reveal the extent to which they truly like or value the good.\n\u003c/p\u003e\u003cp\u003eThe endowment effect can be equated to the behavioural model willingness to accept or pay (WTAP), a formula sometimes used to find out how much a consumer or person is willing to put up with or lose for different outcomes. However, this model has come under recent criticism as potentially inaccurate.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To get things done, we tend to complete things we've invested time and energy in",
        "name": "Backfire effect",
        "article": "Confirmation_bias#backfire_effect",
        "summary": "\u003cp\u003e\n\n\u003cb\u003eConfirmation bias\u003c/b\u003e (also \u003cb\u003econfirmatory bias\u003c/b\u003e, \u003cb\u003emyside bias\u003c/b\u003e, or \u003cb\u003econgeniality bias\u003c/b\u003e) is the tendency to search for, interpret, favor, and recall information in a way that confirms or supports one's prior beliefs or values. People display this bias when they select information that supports their views, ignoring contrary information, or when they interpret ambiguous evidence as supporting their existing attitudes. The effect is strongest for desired outcomes, for emotionally charged issues, and for deeply entrenched beliefs. Confirmation bias is insuperable for most people, but they can manage it, for example, by education and training in critical thinking skills.\n\u003c/p\u003e\u003cp\u003eBiased search for information, biased interpretation of this information, and biased memory recall, have been invoked to explain four specific effects:\n\u003c/p\u003e\n\u003col\u003e\u003cli\u003e\u003ci\u003eattitude polarization\u003c/i\u003e (when a disagreement becomes more extreme even though the different parties are exposed to the same evidence)\u003c/li\u003e\n\u003cli\u003e\u003ci\u003ebelief perseverance\u003c/i\u003e (when beliefs persist after the evidence for them is shown to be false)\u003c/li\u003e\n\u003cli\u003ethe \u003ci\u003eirrational primacy effect\u003c/i\u003e (a greater reliance on information encountered early in a series)\u003c/li\u003e\n\u003cli\u003e\u003ci\u003eillusory correlation\u003c/i\u003e (when people falsely perceive an association between two events or situations).\u003c/li\u003e\u003c/ol\u003e\n\u003cp\u003eA series of psychological experiments in the 1960s suggested that people are biased toward confirming their existing beliefs. Later work re-interpreted these results as a tendency to test ideas in a one-sided way, focusing on one possibility and ignoring alternatives. Explanations for the observed biases include wishful thinking and the limited human capacity to process information. Another proposal is that people show confirmation bias because they are pragmatically assessing the costs of being wrong, rather than investigating in a neutral, scientific way.\n\u003c/p\u003e\u003cp\u003eFlawed decisions due to confirmation bias have been found in a wide range of political, organizational, financial and scientific contexts. These biases contribute to overconfidence in personal beliefs and can maintain or strengthen beliefs in the face of contrary evidence. For example, confirmation bias produces systematic errors in scientific research based on inductive reasoning (the gradual accumulation of supportive evidence). Similarly, a police detective may identify a suspect early in an investigation, but then may only seek confirming rather than disconfirming evidence. A medical practitioner may prematurely focus on a particular disorder early in a diagnostic session, and then seek only confirming evidence. In social media, confirmation bias is amplified by the use of filter bubbles, or \"algorithmic editing\", which display to individuals only information they are likely to agree with, while excluding opposing views.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To avoid mistakes, we aim to preserve autonomy and group status, and avoid irreversible decisions",
        "name": "System justification",
        "article": "System_justification",
        "summary": "\u003cp\u003e\u003cb\u003eSystem justification theory\u003c/b\u003e is a theory within social psychology that system-justifying beliefs serve a psychologically palliative function. It proposes that people have several underlying needs, which vary from individual to individual, that can be satisfied by the defense and justification of the status quo, even when the system may be disadvantageous to certain people. People have epistemic, existential, and relational needs that are met by and manifest as ideological support for the prevailing structure of social, economic, and political norms. Need for order and stability, and thus resistance to change or alternatives, for example, can be a motivator for individuals to see the status quo as good, legitimate, and even desirable.\n\u003c/p\u003e\u003cp\u003eAccording to system justification theory, people desire not only to hold favorable attitudes about themselves (ego-justification) and the groups to which they belong (group-justification), but also to hold positive attitudes about the overarching social structure in which they are entwined and find themselves obligated to (system-justification). This system-justifying motive sometimes produces the phenomenon known as out-group favoritism, an acceptance of inferiority among low-status groups and a positive image of relatively higher status groups. Thus, the notion that individuals are simultaneously supporters and victims of the system-instilled norms is a central idea in system justification theory. Additionally, the passive ease of supporting the current structure, when compared to the potential price (material, social, psychological) of acting out against the status quo, leads to a shared environment in which the existing social, economic, and political arrangements tend to be preferred. Alternatives to the status quo tend to be disparaged, and inequality tends to perpetuate.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To avoid mistakes, we aim to preserve autonomy and group status, and avoid irreversible decisions",
        "name": "Reverse psychology",
        "article": "Reverse_psychology",
        "summary": "\u003cp\u003e\u003cb\u003eReverse psychology\u003c/b\u003e is a technique involving the assertion of a belief or behavior that is opposite to the one desired, with the expectation that this approach will encourage the subject of the persuasion to do what is actually desired. This technique relies on the psychological phenomenon of reactance, in which a person has a negative emotional reaction to being persuaded, and thus chooses the option which is being advocated against. This may work especially well on a person who is resistant by nature, while direct requests work best for people who are compliant. The one being manipulated is usually unaware of what is really going on.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To avoid mistakes, we aim to preserve autonomy and group status, and avoid irreversible decisions",
        "name": "Reactance",
        "article": "Reactance_(psychology)",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\n\u003cp\u003eIn psychology, \u003cb\u003ereactance\u003c/b\u003e is an unpleasant motivational reaction to offers, persons, rules, or regulations that threaten or eliminate specific behavioral freedoms. Reactance occurs when an individual feels that an agent is attempting to limit one's choice of response and/or range of alternatives.\n\u003c/p\u003e\u003cp\u003eReactance can occur when someone is heavily pressured into accepting a certain view or attitude. Reactance can encourage an individual to adopt or strengthen a view or attitude which is indeed contrary to that which was \u003cspan\u003eintended\u003cspan\u003e \u003c/span\u003e—\u003c/span\u003e\u003cspan\u003e \u003c/span\u003ewhich is to say, to a response of \u003cspan\u003enoncompliance\u003cspan\u003e \u003c/span\u003e—\u003c/span\u003e\u003cspan\u003e \u003c/span\u003eand can also increase resistance to persuasion. Some individuals might employ reverse psychology in a bid to exploit reactance for their benefit, in an attempt to influence someone to choose the opposite of what is being requested. Reactance can occur when an individual senses that someone is trying to compel them to do something; often the individual will offer resistance and attempt to extricate themselves from the situation.\n\u003c/p\u003e\u003cp\u003eSome individuals are naturally high in reactance, a personality characteristic called \u003ci\u003etrait reactance\u003c/i\u003e.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To avoid mistakes, we aim to preserve autonomy and group status, and avoid irreversible decisions",
        "name": "Decoy effect",
        "article": "Decoy_effect",
        "summary": "\u003cp\u003eIn marketing, the \u003cb\u003edecoy effect\u003c/b\u003e (or \u003cb\u003eattraction effect\u003c/b\u003e or \u003cb\u003easymmetric dominance effect\u003c/b\u003e) is the phenomenon whereby consumers will tend to have a specific change in preference between two options when also presented with a third option that is \u003ci\u003easymmetrically dominated\u003c/i\u003e. An option is asymmetrically dominated when it is inferior in all respects to one option; but, in comparison to the other option, it is inferior in some respects and superior in others. In other words, in terms of specific attributes determining preferences, it is completely dominated by (i.e., inferior to) one option and only partially dominated by the other. When the asymmetrically dominated option is present, a higher percentage of consumers will prefer the dominating option than when the asymmetrically dominated option is absent. The asymmetrically dominated option is therefore a decoy serving to increase preference for the dominating option. The decoy effect is also an example of the violation of the independence of irrelevant alternatives axiom of decision theory.  More simply, when deciding between two options, an unattractive third option can change the perceived preference between the other two.\n\u003c/p\u003e\u003cp\u003eThe decoy effect is considered particularly important in choice theory because it is a violation of the assumption of \"regularity\" present in all axiomatic choice models, for example in a Luce model of choice.  Regularity means that it should not be possible for the market share of any alternative to increase when another alternative is added to the choice set. The new alternative should reduce, or at best leave unchanged, the choice share of existing alternatives. Regularity is violated in the example shown below where a new alternative C not only changes the relative shares of A and B but actually increases the share of A in absolute terms.  Similarly, the introduction of a new alternative D increases the share of B in absolute terms.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To avoid mistakes, we aim to preserve autonomy and group status, and avoid irreversible decisions",
        "name": "Social comparison effect",
        "article": "Social_comparison_bias",
        "summary": "\u003cp\u003e\u003cb\u003eSocial comparison bias\u003c/b\u003e is the tendency to have feelings of dislike and competitiveness with someone seen as physically, socially, or mentally better than oneself. Social comparison bias or \u003cb\u003esocial comparison theory\u003c/b\u003e is the idea that individuals determine their own worth based on how they compare to others. The theory was developed in 1954 by psychologist Leon Festinger. This can be compared to social comparison, which is believed to be central to achievement motivation, feelings of injustice, depression, jealousy, and people's willingness to remain in relationships or jobs. The basis of the theory is that people are believed to compete for the best outcome in relation to their peers. For example, one might make a comparison between the low-end department stores they go to frequently and the designer stores of their peers. Such comparisons may evoke feelings of resentment, anger , and envy with their peers. This bias revolves mostly around wealth and social status; it is unconscious and people who make these are largely unaware of them.  In most cases, people try to compare themselves to those in their peer group or with whom they are similar.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "To avoid mistakes, we aim to preserve autonomy and group status, and avoid irreversible decisions",
        "name": "Status quo bias",
        "article": "Status_quo_bias",
        "summary": "\u003cp\u003eA \u003cb\u003estatus quo bias\u003c/b\u003e is a cognitive bias which results from a preference for the maintenance of one's existing state of affairs. The current baseline (or status quo) is taken as a reference point, and any change from that baseline is perceived as a loss or gain. Corresponding to different alternatives, this current baseline or default option is perceived and evaluated by individuals as a positive.\n\u003c/p\u003e\u003cp\u003eStatus quo bias should be distinguished from a rational preference for the status quo ante, as when the current state of affairs is objectively superior to the available alternatives, or when imperfect information is a significant problem. A large body of evidence, however, shows that status quo bias frequently affects human decision-making. Status quo bias should also be distinguished from psychological inertia, which refers to a lack of intervention in the current course of affairs.\n\u003c/p\u003e\u003cp\u003eThe bias intersects with other non-rational cognitive processes such as loss aversion, in which losses comparative to gains are weighed to a greater extent. Further non-rational cognitive processes include existence bias, endowment effect, longevity, mere exposure, and regret avoidance.  Experimental evidence for the detection of status quo bias is seen through the use of the reversal test. A vast amount of experimental and field examples exist. Behaviour in regard to economics, retirement plans, health, and ethical choices show evidence of the status quo bias.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "We favor simple-looking options and complete information over complex, ambiguous options",
        "name": "Ambiguity bias",
        "article": "Ambiguity_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003eambiguity effect\u003c/b\u003e is a cognitive tendency where decision making is affected by a lack of information, or \"ambiguity\". The effect implies that people tend to select options for which the probability of a favorable outcome is known, over an option for which the probability of a favorable outcome is unknown. The effect was first described by Daniel Ellsberg in 1961.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "We favor simple-looking options and complete information over complex, ambiguous options",
        "name": "Information bias",
        "article": "Information_bias_(psychology)",
        "summary": "\u003cp\u003e\u003cb\u003eInformation bias\u003c/b\u003e is a cognitive bias to seek information when it does not affect action. An example of information bias is believing that the more information that can be acquired to make a decision, the better, even if that extra information is irrelevant for the decision.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "We favor simple-looking options and complete information over complex, ambiguous options",
        "name": "Belief bias",
        "article": "Belief_bias",
        "summary": "\u003cp\u003e\u003cb\u003eBelief bias\u003c/b\u003e is the tendency to judge the strength of arguments based on the plausibility of their conclusion rather than how strongly they justify that conclusion. A person is more likely to accept an argument that supports a conclusion that aligns with their values, beliefs and prior knowledge, while rejecting counter arguments to the conclusion.  Belief bias is an extremely common and therefore significant form of error; we can easily be blinded by our beliefs and reach the wrong conclusion. Belief bias has been found to influence various reasoning tasks, including conditional reasoning, relation reasoning and transitive reasoning.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "We favor simple-looking options and complete information over complex, ambiguous options",
        "name": "Rhyme-as-reason effect",
        "article": "Rhyme-as-reason_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003erhyme-as-reason effect\u003c/b\u003e, also known as the \u003cb\u003eEaton–Rosen phenomenon\u003c/b\u003e, is a cognitive bias where sayings or aphorisms are perceived as more accurate or truthful when they rhyme.\n\u003c/p\u003e\u003cp\u003eIn experiments, participants evaluated variations of sayings that either rhymed or did not rhyme. Those that rhymed were consistently judged as more truthful, even when the meaning was controlled for. For instance, the rhyming saying \"What sobriety conceals, alcohol reveals\" was rated as more accurate on average than its non-rhyming counterpart, \"What sobriety conceals, alcohol unmasks,\" across different groups of subjects (each group assessed the accuracy of only one version of the statement).\n\u003c/p\u003e\u003cp\u003eThis effect may be explained by the Keats heuristic, which suggests that people assess a statement's truth based on its aesthetic qualities. Another explanation is the fluency heuristic, which posits that statements are preferred due to their ease of cognitive processing.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "We favor simple-looking options and complete information over complex, ambiguous options",
        "name": "Bike-shedding effect",
        "article": "Law_of_triviality",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\n\u003c/p\u003e\u003cp\u003eThe \u003cb\u003elaw of triviality\u003c/b\u003e is C. Northcote Parkinson's 1957 argument that people within an organization commonly give disproportionate weight to trivial issues. Parkinson provides the example of a fictional committee whose job was to approve the plans for a nuclear power plant spending the majority of its time on discussions about relatively minor but easy-to-grasp issues, such as what materials to use for the staff bicycle shed, while neglecting the proposed design of the plant itself, which is far more important and a far more difficult and complex task.\n\u003c/p\u003e\u003cp\u003eThe law has been applied to software development and other activities. The terms \u003cb\u003ebicycle-shed effect\u003c/b\u003e, \u003cb\u003ebike-shed effect\u003c/b\u003e, and \u003cb\u003ebike-shedding\u003c/b\u003e were coined based on Parkinson's example; it was popularised in the Berkeley Software Distribution community by the Danish software developer Poul-Henning Kamp in 1999 and, due to that, has since become popular within the field of software development generally.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "We favor simple-looking options and complete information over complex, ambiguous options",
        "name": "Law of Triviality",
        "article": "Law_of_triviality",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\n\u003c/p\u003e\u003cp\u003eThe \u003cb\u003elaw of triviality\u003c/b\u003e is C. Northcote Parkinson's 1957 argument that people within an organization commonly give disproportionate weight to trivial issues. Parkinson provides the example of a fictional committee whose job was to approve the plans for a nuclear power plant spending the majority of its time on discussions about relatively minor but easy-to-grasp issues, such as what materials to use for the staff bicycle shed, while neglecting the proposed design of the plant itself, which is far more important and a far more difficult and complex task.\n\u003c/p\u003e\u003cp\u003eThe law has been applied to software development and other activities. The terms \u003cb\u003ebicycle-shed effect\u003c/b\u003e, \u003cb\u003ebike-shed effect\u003c/b\u003e, and \u003cb\u003ebike-shedding\u003c/b\u003e were coined based on Parkinson's example; it was popularised in the Berkeley Software Distribution community by the Danish software developer Poul-Henning Kamp in 1999 and, due to that, has since become popular within the field of software development generally.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "We favor simple-looking options and complete information over complex, ambiguous options",
        "name": "Conjunction fallacy",
        "article": "Conjunction_fallacy",
        "summary": "\u003cp\u003eThe \u003cb\u003econjunction fallacy\u003c/b\u003e (also known as the \u003cb\u003eLinda problem\u003c/b\u003e) is an inference that a conjoint set of two or more specific conclusions is likelier than any single member of that same set, in violation of the laws of probability. It is a type of formal fallacy.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "We favor simple-looking options and complete information over complex, ambiguous options",
        "name": "Occam's razor",
        "article": "Occam's_razor",
        "summary": "\u003cp\u003e\nIn philosophy, \u003cb\u003eOccam's razor\u003c/b\u003e (also spelled \u003cb\u003eOckham's razor\u003c/b\u003e or \u003cb\u003eOcham's razor\u003c/b\u003e; Latin: \u003ci lang=\"la\"\u003enovacula Occami\u003c/i\u003e) is the problem-solving principle that recommends searching for explanations constructed with the smallest possible set of elements. It is also known as the \u003cb\u003eprinciple of parsimony\u003c/b\u003e or the \u003cb\u003elaw of parsimony\u003c/b\u003e (Latin: \u003ci lang=\"la\"\u003elex parsimoniae\u003c/i\u003e). Attributed to William of Ockham, a 14th-century English philosopher and theologian, it is frequently cited as \u003cspan title=\"Latin-language text\"\u003e\u003ci lang=\"la\"\u003eEntia non sunt multiplicanda praeter necessitatem\u003c/i\u003e\u003c/span\u003e, which translates as \"Entities must not be multiplied beyond necessity\", although Occam never used these exact words. Popularly, the principle is sometimes paraphrased as \"The simplest explanation is usually the best one.\"\n\u003c/p\u003e\u003cp\u003eThis philosophical razor advocates that when presented with competing hypotheses about the same prediction and both theories have equal explanatory power one should prefer the hypothesis that requires the fewest assumptions and that this is not meant to be a way of choosing between hypotheses that make different predictions. Similarly, in science, Occam's razor is used as an abductive heuristic in the development of theoretical models rather than as a rigorous arbiter between candidate models.\n\u003c/p\u003e"
    },
    {
        "category": "Need To Act Fast",
        "subcategory": "We favor simple-looking options and complete information over complex, ambiguous options",
        "name": "Less-is-better effect",
        "article": "Less-is-better_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003eless-is-better effect\u003c/b\u003e is a type of preference reversal that occurs when the lesser or smaller alternative of a proposition is preferred when evaluated separately, but not evaluated together. The term was first proposed by Christopher Hsee.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We edit and reinforce some memories after the fact",
        "name": "Misattribution of memory",
        "article": "Misattribution_of_memory",
        "summary": "\u003cp\u003eIn psychology, the \u003cb\u003emisattribution of memory\u003c/b\u003e or \u003cb\u003esource misattribution\u003c/b\u003e is the misidentification of the origin of a memory by the person making the memory recall. Misattribution is likely to occur when individuals are unable to monitor and control the influence of their attitudes, toward their judgments, at the time of retrieval. Misattribution is divided into three components: cryptomnesia, false memories, and source confusion. It was originally noted as one of Daniel Schacter's seven sins of memory.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We edit and reinforce some memories after the fact",
        "name": "Source confusion",
        "article": "Misattribution_of_memory#Source_confusion",
        "summary": "\u003cp\u003eIn psychology, the \u003cb\u003emisattribution of memory\u003c/b\u003e or \u003cb\u003esource misattribution\u003c/b\u003e is the misidentification of the origin of a memory by the person making the memory recall. Misattribution is likely to occur when individuals are unable to monitor and control the influence of their attitudes, toward their judgments, at the time of retrieval. Misattribution is divided into three components: cryptomnesia, false memories, and source confusion. It was originally noted as one of Daniel Schacter's seven sins of memory.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We edit and reinforce some memories after the fact",
        "name": "Cryptomnesia",
        "article": "Cryptomnesia",
        "summary": "\u003cp\u003e\u003cb\u003eCryptomnesia\u003c/b\u003e occurs when a forgotten memory returns without its being recognized as such by the subject, who believes it is something new and original. It is a memory bias whereby a person may falsely recall generating a thought, an idea, a tune, a name, or a joke; they are not deliberately engaging in plagiarism, but are experiencing a memory as if it were a new inspiration.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We edit and reinforce some memories after the fact",
        "name": "False memory",
        "article": "False_memory",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\n\n\u003cp class=\"mw-empty-elt\"\u003e\n\u003c/p\u003e\u003cp\u003eIn psychology, a \u003cb\u003efalse memory\u003c/b\u003e is a phenomenon where someone recalls something that did not actually happen or recalls it differently from the way it actually happened. Suggestibility, activation of associated information, the incorporation of misinformation, and source misattribution have been suggested to be several mechanisms underlying a variety of types of false memory.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We edit and reinforce some memories after the fact",
        "name": "Suggestibility",
        "article": "Suggestibility",
        "summary": "\u003cp\u003e\n\u003cb\u003eSuggestibility\u003c/b\u003e is the quality of being inclined to accept and act on the suggestions of others. One may fill in gaps in certain memories with false information given by another when recalling a scenario or moment. Suggestibility uses cues to distort recollection: when the subject has been persistently told something about a past event, his or her memory of the event conforms to the repeated message.\n\u003c/p\u003e\u003cp\u003eA person experiencing intense emotions tends to be more receptive to ideas and therefore more suggestible. Generally, suggestibility decreases as age increases. However, psychologists have found that individual levels of self-esteem and assertiveness can make some people more suggestible than others; this finding led to the concept of a spectrum of suggestibility.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We edit and reinforce some memories after the fact",
        "name": "Spacing effect",
        "article": "Spacing_effect",
        "summary": "\u003cp class=\"mw-empty-elt\"\u003e\n\n\u003c/p\u003e\n\n\u003cp\u003eThe \u003cb\u003espacing effect\u003c/b\u003e demonstrates that learning is more effective when study sessions are spaced out.  This effect shows that more information is encoded into long-term memory by spaced study sessions, also known as \u003ci\u003espaced repetition\u003c/i\u003e or \u003ci\u003espaced presentation\u003c/i\u003e, than by massed presentation (\"cramming\").\n\u003c/p\u003e\u003cp\u003eThe phenomenon was first identified by Hermann Ebbinghaus, and his detailed study of it was published in the 1885 book \u003cspan title=\"German-language text\"\u003e\u003ci lang=\"de\"\u003eÜber das Gedächtnis. Untersuchungen zur experimentellen Psychologie\u003c/i\u003e\u003c/span\u003e (\u003ci\u003eMemory: A Contribution to Experimental Psychology\u003c/i\u003e), which suggests that active recall with increasing time intervals reduces the probability of forgetting information. This robust finding has been supported by studies of many explicit memory tasks such as free recall, recognition, cued-recall, and frequency estimation (for reviews see Crowder 1976; Greene, 1989).\n\u003c/p\u003e\u003cp\u003eResearchers have offered several possible explanations of the spacing effect, and much research has been conducted that supports its impact on recall.  In spite of these findings, the robustness of this phenomenon and its resistance to experimental manipulation have made empirical testing of its parameters difficult.\n\u003c/p\u003e\u003cp\u003eWhile many others have contributed important research regarding the spacing effect, Robert Bjork and his associates in the Bjork Learning and Forgetting Lab and Cogfog group at UCLA have performed much research into various aspects of this phenomenon as well as into its practical application for education.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We discard specifics to form generalities",
        "name": "Implicit association",
        "article": "Implicit_stereotype",
        "summary": "\u003cp\u003eAn \u003cb\u003eimplicit bias\u003c/b\u003e or \u003cb\u003eimplicit stereotype\u003c/b\u003e is the pre-reflective attribution of particular qualities by an individual to a member of some social out group.  Recent studies have determined that \"implicit bias\" towards those of the opposite gender may be even more influential than racial implicit bias.\n\u003c/p\u003e\u003cp\u003eImplicit stereotypes are thought to be shaped by experience and based on learned associations between particular qualities and social categories, including race and/or gender. Individuals' perceptions and behaviors can be influenced by the implicit stereotypes they hold, even if they are \u003ci\u003esometimes\u003c/i\u003e unaware they hold such stereotypes. Implicit bias is an aspect of implicit social cognition: the phenomenon that perceptions, attitudes, and stereotypes can operate prior to conscious intention or endorsement. The existence of implicit bias is supported by a variety of scientific articles in psychological literature. Implicit stereotype was first defined by psychologists Mahzarin Banaji and Anthony Greenwald in 1995.\n\u003c/p\u003e\u003cp\u003e\u003cb\u003eExplicit stereotypes\u003c/b\u003e, by contrast, are consciously endorsed, intentional, and sometimes controllable thoughts and beliefs.\n\u003c/p\u003e\u003cp\u003eImplicit biases, however, are thought to be the product of associations learned through \u003ci\u003epast\u003c/i\u003e experiences. Implicit biases can be activated by the environment and operate prior to a person's intentional, conscious endorsement. Implicit bias can persist even when an individual rejects the bias explicitly.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We discard specifics to form generalities",
        "name": "Implicit stereotypes",
        "article": "Implicit_stereotype",
        "summary": "\u003cp\u003eAn \u003cb\u003eimplicit bias\u003c/b\u003e or \u003cb\u003eimplicit stereotype\u003c/b\u003e is the pre-reflective attribution of particular qualities by an individual to a member of some social out group.  Recent studies have determined that \"implicit bias\" towards those of the opposite gender may be even more influential than racial implicit bias.\n\u003c/p\u003e\u003cp\u003eImplicit stereotypes are thought to be shaped by experience and based on learned associations between particular qualities and social categories, including race and/or gender. Individuals' perceptions and behaviors can be influenced by the implicit stereotypes they hold, even if they are \u003ci\u003esometimes\u003c/i\u003e unaware they hold such stereotypes. Implicit bias is an aspect of implicit social cognition: the phenomenon that perceptions, attitudes, and stereotypes can operate prior to conscious intention or endorsement. The existence of implicit bias is supported by a variety of scientific articles in psychological literature. Implicit stereotype was first defined by psychologists Mahzarin Banaji and Anthony Greenwald in 1995.\n\u003c/p\u003e\u003cp\u003e\u003cb\u003eExplicit stereotypes\u003c/b\u003e, by contrast, are consciously endorsed, intentional, and sometimes controllable thoughts and beliefs.\n\u003c/p\u003e\u003cp\u003eImplicit biases, however, are thought to be the product of associations learned through \u003ci\u003epast\u003c/i\u003e experiences. Implicit biases can be activated by the environment and operate prior to a person's intentional, conscious endorsement. Implicit bias can persist even when an individual rejects the bias explicitly.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We discard specifics to form generalities",
        "name": "Stereotypical bias",
        "article": "Implicit_stereotype",
        "summary": "\u003cp\u003eAn \u003cb\u003eimplicit bias\u003c/b\u003e or \u003cb\u003eimplicit stereotype\u003c/b\u003e is the pre-reflective attribution of particular qualities by an individual to a member of some social out group.  Recent studies have determined that \"implicit bias\" towards those of the opposite gender may be even more influential than racial implicit bias.\n\u003c/p\u003e\u003cp\u003eImplicit stereotypes are thought to be shaped by experience and based on learned associations between particular qualities and social categories, including race and/or gender. Individuals' perceptions and behaviors can be influenced by the implicit stereotypes they hold, even if they are \u003ci\u003esometimes\u003c/i\u003e unaware they hold such stereotypes. Implicit bias is an aspect of implicit social cognition: the phenomenon that perceptions, attitudes, and stereotypes can operate prior to conscious intention or endorsement. The existence of implicit bias is supported by a variety of scientific articles in psychological literature. Implicit stereotype was first defined by psychologists Mahzarin Banaji and Anthony Greenwald in 1995.\n\u003c/p\u003e\u003cp\u003e\u003cb\u003eExplicit stereotypes\u003c/b\u003e, by contrast, are consciously endorsed, intentional, and sometimes controllable thoughts and beliefs.\n\u003c/p\u003e\u003cp\u003eImplicit biases, however, are thought to be the product of associations learned through \u003ci\u003epast\u003c/i\u003e experiences. Implicit biases can be activated by the environment and operate prior to a person's intentional, conscious endorsement. Implicit bias can persist even when an individual rejects the bias explicitly.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We discard specifics to form generalities",
        "name": "Prejudice",
        "article": "Prejudice",
        "summary": "\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"\u003e\u003clink rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1066933788\"\u003e\n\u003cp\u003e\u003cb\u003ePrejudice\u003c/b\u003e can be an affective feeling towards a person based on their perceived group membership. The word is often used to refer to a preconceived (usually unfavourable) evaluation or classification of another person based on that person's perceived personal characteristics, such as political affiliation, sex, gender, gender identity, beliefs, values, social class, age, disability, religion, sexuality, race, ethnicity, language, nationality, culture, complexion, beauty, height, body weight, occupation, wealth, education, criminality, sport-team affiliation, music tastes or other perceived characteristics.\n\u003c/p\u003e\u003cp\u003eThe word \"prejudice\" can also refer to unfounded or pigeonholed beliefs and it may apply to \"any unreasonable attitude that is unusually resistant to rational influence\". Gordon Allport defined prejudice as a \"feeling, favorable or unfavorable, toward a person or thing, prior to, or not based on, actual experience\". Auestad (2015) defines prejudice as characterized by \"symbolic transfer\", transfer of a value-laden meaning content onto a socially-formed category and then on to individuals who are taken to belong to that category, resistance to change, and overgeneralization.\n\u003c/p\u003e\u003cp\u003eThe United Nations Institute on Globalization, Culture and Mobility has highlighted research considering prejudice as a  global security threat due to its use in scapegoating some populations and inciting others to commit  violent acts towards them and how this can endanger individuals, countries, and the international community.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We discard specifics to form generalities",
        "name": "Negativity bias",
        "article": "Negativity_bias",
        "summary": "\u003cp\u003eThe \u003cb\u003enegativity bias\u003c/b\u003e, also known as the \u003cb\u003enegativity effect\u003c/b\u003e, is a cognitive bias that, even when positive or neutral things of equal intensity occur, things of a more negative nature (e.g. unpleasant thoughts, emotions, or social interactions; harmful/traumatic events) have a greater effect on one's psychological state and processes than neutral or positive things.  In other words, something very positive will generally have less of an impact on a person's behavior and cognition than something equally emotional but negative.  The negativity bias has been investigated within many different domains, including the formation of impressions and general evaluations; attention, learning, and memory; and decision-making and risk considerations.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We discard specifics to form generalities",
        "name": "Fading affect bias",
        "article": "Fading_affect_bias",
        "summary": "\u003cp\u003eThe \u003cb\u003efading affect bias\u003c/b\u003e, more commonly known as \u003cb\u003eFAB\u003c/b\u003e, is a psychological phenomenon in which memories associated with negative emotions tend to be forgotten more quickly than those associated with positive emotions. FAB only refers to the feelings one has associated with the memories and not the content of the memories themselves. Early research studied FAB retrospectively, or through personal reflection, which brought about some criticism because retrospective analysis can be affected by subjective retrospective biases. However, new research using non-retrospective recall studies have found evidence for FAB, and the phenomenon has become largely accepted.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Peak-end rule",
        "article": "Peak-end_rule",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐6js2z\nCached time: 20240701122022\nCache expiry: 2592000\nReduced expiry: false\nComplications: [is‐preview]\nCPU time usage: 0.050 seconds\nReal time usage: 0.069 seconds\nPreprocessor visited node count: 142/1000000\nPost‐expand include size: 8991/2097152 bytes\nTemplate argument size: 2933/2097152 bytes\nHighest expansion depth: 13/100\nExpensive parser function count: 1/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 1653/5000000 bytes\nLua time usage: 0.026/10.000 seconds\nLua memory usage: 703841/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%   61.499      1 Template:Redirect_category_shell\n100.00%   61.499      1 -total\n 96.55%   59.380      1 Template:Mbox\n 22.64%   13.921      1 Template:R_from_incorrect_hyphenation\n 17.13%   10.534      1 Template:Redirect_template\n  5.55%    3.416      1 Template:Tl\n  4.60%    2.831      1 Template:C\n  2.75%    1.691      1 Template:Talk_other\n  2.50%    1.537      1 Template:Main_other\n  1.79%    1.099      2 Template:Nowrap\n--\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Leveling and sharpening",
        "article": "Leveling_and_sharpening",
        "summary": "\u003cp\u003e\u003cb\u003eLeveling and sharpening\u003c/b\u003e are two functions that are automatic and exist within memory. \u003ci\u003eSharpening\u003c/i\u003e is usually the way people remember small details in the retelling of stories they have experienced or are retelling those stories. \u003ci\u003eLeveling\u003c/i\u003e is when people keep out parts of stories and try to tone those stories down so that some parts are excluded. Therefore, it makes it easier to fill in the memory gaps that exist.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Misinformation effect",
        "article": "Misinformation_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003emisinformation effect \u003c/b\u003eoccurs when a person's recall of episodic memories becomes less accurate because of post-event information. The misinformation effect has been studied since the mid-1970s. Elizabeth Loftus is one of the most influential researchers in the field. One theory is that original information and the misleading information that was presented after the fact become blended together. Another theory is that the misleading information overwrites the original information. Scientists suggest that because the misleading information is the most recent, it is more easily retrieved.\n\u003c/p\u003e\n\n\u003cp\u003eThe misinformation effect is an example of retroactive interference which occurs when information presented later interferes with the ability to retain previously encoded information. Individuals have also been shown to be susceptible to incorporating misleading information into their memory when it is presented within a question. Essentially, the new information that a person receives works backward in time to distort memory of the original event. One mechanism through which the misinformation effect occurs is source misattribution, in which the false information given after the event becomes incorporated into people's memory of the actual event. The misinformation effect also appears to stem from memory impairment, meaning that post-event misinformation makes it harder for people to remember the event. The misinformation reflects two of the cardinal sins of memory: \u003ci\u003esuggestibility\u003c/i\u003e, the influence of others' expectations on our memory; and \u003ci\u003emisattribution,\u003c/i\u003e information attributed to an incorrect source.\n\u003c/p\u003e\u003cp\u003eResearch on the misinformation effect has uncovered concerns about the permanence and reliability of memory. Understanding the misinformation effect is also important given its implications for the accuracy of eyewitness testimony, as there are many chances for misinformation to be incorporated into witnesses' memories through conversations with other witnesses, police questioning, and court appearances.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Serial recall effect",
        "article": "Recall_(memory)#Serial_recall",
        "summary": "\u003cp\u003e\u003cb\u003eRecall\u003c/b\u003e in memory refers to the mental process of retrieval of information from the past. Along with encoding and storage, it is one of the three core processes of memory. There are three main types of recall: free recall, cued recall and serial recall. Psychologists test these forms of recall as a way to study the memory processes of humans and animals.\nTwo main theories of the process of recall are the two-stage theory and the theory of encoding specificity.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "List-length effect",
        "article": "Recall_(memory)#Serial_recall",
        "summary": "\u003cp\u003e\u003cb\u003eRecall\u003c/b\u003e in memory refers to the mental process of retrieval of information from the past. Along with encoding and storage, it is one of the three core processes of memory. There are three main types of recall: free recall, cued recall and serial recall. Psychologists test these forms of recall as a way to study the memory processes of humans and animals.\nTwo main theories of the process of recall are the two-stage theory and the theory of encoding specificity.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Duration neglect",
        "article": "Duration_neglect",
        "summary": "\u003cp\u003e\u003cb\u003eDuration neglect\u003c/b\u003e is the psychological observation that people's judgments of the unpleasantness of painful experiences depend very little on the duration of those experiences. Multiple experiments have found that these judgments tend to be affected by two factors: the \u003ci\u003epeak\u003c/i\u003e (when the experience was the most painful) and how quickly the pain diminishes. If it diminishes more slowly, the experience is judged to be less painful. Hence, the term \"peak–end rule\" describes this process of evaluation.\n\u003c/p\u003e\u003cp\u003eDuration neglect is a specific form of the more general extension neglect.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Modality effect",
        "article": "Modality_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003emodality effect\u003c/b\u003e is a term used in experimental psychology, most often in the fields dealing with memory and learning, to refer to how learner performance depends on the presentation mode of studied items.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Memory inhibition",
        "article": "Memory_inhibition",
        "summary": "\u003cp\u003eIn psychology, \u003cb\u003ememory inhibition\u003c/b\u003e is the ability \u003ci\u003enot\u003c/i\u003e to remember irrelevant information. The scientific concept of memory inhibition should not be confused with everyday uses of the word \"inhibition\". Scientifically speaking, memory inhibition is a type of cognitive inhibition, which is the stopping or overriding of a mental process, in whole or in part, with or without intention.\n\u003c/p\u003e\u003cp\u003eMemory inhibition is a critical component of an effective memory system. While some memories are retained for a lifetime, most memories are forgotten. According to evolutionary psychologists, forgetting is adaptive because it facilitates selectivity of rapid, efficient recollection. For example, a person trying to remember where they parked their car would not want to remember every place they have ever parked. In order to remember something, therefore, it is essential not only to activate the relevant information, but also to inhibit irrelevant information. \n\u003c/p\u003e\u003cp\u003eThere are many memory phenomena that seem to involve inhibition, although there is often debate about the distinction between interference and inhibition.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Primacy effect",
        "article": "Serial-position_effect#Primacy_effect",
        "summary": "\u003cp\u003e\u003cb\u003eSerial-position effect\u003c/b\u003e is the tendency of a person to recall the first and last items in a series best, and the middle items worst. The term was coined by Hermann Ebbinghaus through studies he performed on himself, and refers to the finding that recall accuracy varies as a function of an item's position within a study list. When asked to recall a list of items in any order (free recall), people tend to begin recall with the end of the list, recalling those items best (the \u003cb\u003erecency effect\u003c/b\u003e). Among earlier list items, the first few items are recalled more frequently than the middle items (the \u003cb\u003eprimacy effect\u003c/b\u003e).\n\u003c/p\u003e\u003cp\u003eOne suggested reason for the primacy effect is that the initial items presented are most effectively stored in long-term memory because of the greater amount of processing devoted to them. (The first list item can be rehearsed by itself; the second must be rehearsed along with the first, the third along with the first and second, and so on.) The primacy effect is reduced when items are presented quickly and is enhanced when presented slowly (factors that reduce and enhance processing of each item and thus permanent storage). Longer presentation lists have been found to reduce the primacy effect.\n\u003c/p\u003e\u003cp\u003eOne theorised reason for the recency effect is that these items are still present in working memory when recall is solicited. Items that benefit from neither (the middle items) are recalled most poorly. An additional explanation for the recency effect is related to temporal context: if tested immediately after rehearsal, the current temporal context can serve as a retrieval cue, which would predict more recent items to have a higher likelihood of recall than items that were studied in a different temporal context (earlier in the list). The recency effect is reduced when an interfering task is given. Intervening tasks involve working memory, as the distractor activity, if exceeding 15 to 30 seconds in duration, can cancel out the recency effect. Additionally, if recall comes immediately after the test, the recency effect is consistent regardless of the length of the studied list, or presentation rate.\n\u003c/p\u003e\u003cp\u003eAmnesiacs with poor ability to form permanent long-term memories do not show a primacy effect, but do show a recency effect if recall comes immediately after study. People with Alzheimer's disease exhibit a reduced primacy effect but do not produce a recency effect in recall.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Recency effect",
        "article": "Serial-position_effect#Recency_effect",
        "summary": "\u003cp\u003e\u003cb\u003eSerial-position effect\u003c/b\u003e is the tendency of a person to recall the first and last items in a series best, and the middle items worst. The term was coined by Hermann Ebbinghaus through studies he performed on himself, and refers to the finding that recall accuracy varies as a function of an item's position within a study list. When asked to recall a list of items in any order (free recall), people tend to begin recall with the end of the list, recalling those items best (the \u003cb\u003erecency effect\u003c/b\u003e). Among earlier list items, the first few items are recalled more frequently than the middle items (the \u003cb\u003eprimacy effect\u003c/b\u003e).\n\u003c/p\u003e\u003cp\u003eOne suggested reason for the primacy effect is that the initial items presented are most effectively stored in long-term memory because of the greater amount of processing devoted to them. (The first list item can be rehearsed by itself; the second must be rehearsed along with the first, the third along with the first and second, and so on.) The primacy effect is reduced when items are presented quickly and is enhanced when presented slowly (factors that reduce and enhance processing of each item and thus permanent storage). Longer presentation lists have been found to reduce the primacy effect.\n\u003c/p\u003e\u003cp\u003eOne theorised reason for the recency effect is that these items are still present in working memory when recall is solicited. Items that benefit from neither (the middle items) are recalled most poorly. An additional explanation for the recency effect is related to temporal context: if tested immediately after rehearsal, the current temporal context can serve as a retrieval cue, which would predict more recent items to have a higher likelihood of recall than items that were studied in a different temporal context (earlier in the list). The recency effect is reduced when an interfering task is given. Intervening tasks involve working memory, as the distractor activity, if exceeding 15 to 30 seconds in duration, can cancel out the recency effect. Additionally, if recall comes immediately after the test, the recency effect is consistent regardless of the length of the studied list, or presentation rate.\n\u003c/p\u003e\u003cp\u003eAmnesiacs with poor ability to form permanent long-term memories do not show a primacy effect, but do show a recency effect if recall comes immediately after study. People with Alzheimer's disease exhibit a reduced primacy effect but do not produce a recency effect in recall.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Part-set cueing effect",
        "article": "Memory_inhibition#Part-set_cuing_effect",
        "summary": "\u003cp\u003eIn psychology, \u003cb\u003ememory inhibition\u003c/b\u003e is the ability \u003ci\u003enot\u003c/i\u003e to remember irrelevant information. The scientific concept of memory inhibition should not be confused with everyday uses of the word \"inhibition\". Scientifically speaking, memory inhibition is a type of cognitive inhibition, which is the stopping or overriding of a mental process, in whole or in part, with or without intention.\n\u003c/p\u003e\u003cp\u003eMemory inhibition is a critical component of an effective memory system. While some memories are retained for a lifetime, most memories are forgotten. According to evolutionary psychologists, forgetting is adaptive because it facilitates selectivity of rapid, efficient recollection. For example, a person trying to remember where they parked their car would not want to remember every place they have ever parked. In order to remember something, therefore, it is essential not only to activate the relevant information, but also to inhibit irrelevant information. \n\u003c/p\u003e\u003cp\u003eThere are many memory phenomena that seem to involve inhibition, although there is often debate about the distinction between interference and inhibition.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Serial-position effect",
        "article": "Serial-position_effect",
        "summary": "\u003cp\u003e\u003cb\u003eSerial-position effect\u003c/b\u003e is the tendency of a person to recall the first and last items in a series best, and the middle items worst. The term was coined by Hermann Ebbinghaus through studies he performed on himself, and refers to the finding that recall accuracy varies as a function of an item's position within a study list. When asked to recall a list of items in any order (free recall), people tend to begin recall with the end of the list, recalling those items best (the \u003cb\u003erecency effect\u003c/b\u003e). Among earlier list items, the first few items are recalled more frequently than the middle items (the \u003cb\u003eprimacy effect\u003c/b\u003e).\n\u003c/p\u003e\u003cp\u003eOne suggested reason for the primacy effect is that the initial items presented are most effectively stored in long-term memory because of the greater amount of processing devoted to them. (The first list item can be rehearsed by itself; the second must be rehearsed along with the first, the third along with the first and second, and so on.) The primacy effect is reduced when items are presented quickly and is enhanced when presented slowly (factors that reduce and enhance processing of each item and thus permanent storage). Longer presentation lists have been found to reduce the primacy effect.\n\u003c/p\u003e\u003cp\u003eOne theorised reason for the recency effect is that these items are still present in working memory when recall is solicited. Items that benefit from neither (the middle items) are recalled most poorly. An additional explanation for the recency effect is related to temporal context: if tested immediately after rehearsal, the current temporal context can serve as a retrieval cue, which would predict more recent items to have a higher likelihood of recall than items that were studied in a different temporal context (earlier in the list). The recency effect is reduced when an interfering task is given. Intervening tasks involve working memory, as the distractor activity, if exceeding 15 to 30 seconds in duration, can cancel out the recency effect. Additionally, if recall comes immediately after the test, the recency effect is consistent regardless of the length of the studied list, or presentation rate.\n\u003c/p\u003e\u003cp\u003eAmnesiacs with poor ability to form permanent long-term memories do not show a primacy effect, but do show a recency effect if recall comes immediately after study. People with Alzheimer's disease exhibit a reduced primacy effect but do not produce a recency effect in recall.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We reduce events and lists to their key elements",
        "name": "Suffix effect",
        "article": "List_of_cognitive_biases#Suffix_effect",
        "summary": "\u003cp\u003eCognitive biases are systematic patterns of deviation from norm and/or rationality in judgment. They are often studied in psychology, sociology and behavioral economics.\n\u003c/p\u003e\u003cp\u003eAlthough the reality of most of these biases is confirmed by reproducible research, there are often controversies about how to classify these biases or how to explain them. Several theoretical causes are known for some cognitive biases, which provides a classification of biases by their common generative mechanism (such as noisy information-processing). Gerd Gigerenzer has criticized the framing of cognitive biases as errors in judgment, and favors interpreting them as arising from rational deviations from logical thought.\n\u003c/p\u003e\u003cp\u003eExplanations include information-processing rules (i.e., mental shortcuts), called \u003ci\u003eheuristics\u003c/i\u003e, that the brain uses to produce decisions or judgments. Biases have a variety of forms and appear as cognitive (\"cold\") bias, such as mental noise, or motivational (\"hot\") bias, such as when beliefs are distorted by wishful thinking. Both effects can be present at the same time.\n\u003c/p\u003e\u003cp\u003eThere are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill; a way to establish a connection with the other person.\n\u003c/p\u003e\u003cp\u003eAlthough this research overwhelmingly involves human subjects, some findings that demonstrate bias have been found in non-human animals as well. For example, loss aversion has been shown in monkeys and hyperbolic discounting has been observed in rats, pigeons, and monkeys.\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We store memories differently based on how they were experienced",
        "name": "Levels-of-processing effect",
        "article": "Levels-of-processing_effect",
        "summary": "\u003c!-- \nNewPP limit report\nParsed by mw‐api‐ext.eqiad.main‐b6798d7c6‐t2zfx\nCached time: 20240701122024\nCache expiry: 2592000\nReduced expiry: false\nComplications: [vary‐revision‐sha1, is‐preview]\nCPU time usage: 0.053 seconds\nReal time usage: 0.159 seconds\nPreprocessor visited node count: 110/1000000\nPost‐expand include size: 4764/2097152 bytes\nTemplate argument size: 1099/2097152 bytes\nHighest expansion depth: 13/100\nExpensive parser function count: 1/500\nUnstrip recursion depth: 0/20\nUnstrip post‐expand size: 1653/5000000 bytes\nLua time usage: 0.031/10.000 seconds\nLua memory usage: 786459/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n--\u003e\n\u003c!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%   62.246      1 -total\n100.00%   62.246      1 Template:Redirect_category_shell\n 96.56%   60.106      1 Template:Mbox\n 15.91%    9.901      1 Template:R_from_move\n  7.78%    4.841      1 Template:R_from_move/except\n  6.20%    3.858      1 Template:Redirect_template\n  2.52%    1.567      1 Template:Talk_other\n--\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We store memories differently based on how they were experienced",
        "name": "Absent-mindedness",
        "article": "Absent-mindedness",
        "summary": "\u003cp\u003eIn the field of psychology, \u003cb\u003eabsent-mindedness\u003c/b\u003e is a mental state wherein a person is forgetfully inattentive. It is the opposite mental state of mindfulness.\n\u003c/p\u003e\u003cp\u003eAbsentmindedness is often caused by things such as boredom, sleepiness, rumination, distraction, or preoccupation with one's own internal monologue. When experiencing absent-mindedness, people exhibit signs of memory lapses and weak recollection of recent events.\n\u003c/p\u003e\u003cp\u003eAbsent-mindedness can usually be a result of a variety of other conditions often diagnosed by clinicians, such as attention deficit hyperactivity disorder and depression. In addition to absent-mindedness leading to an array of consequences affecting daily life, it can have more severe, long-term problems.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We store memories differently based on how they were experienced",
        "name": "Testing effect",
        "article": "Testing_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003etesting effect\u003c/b\u003e (also known as \u003cb\u003eretrieval practice\u003c/b\u003e, \u003cb\u003eactive recall\u003c/b\u003e, \u003cb\u003epractice testing\u003c/b\u003e, or \u003cb\u003etest-enhanced learning\u003c/b\u003e) suggests long-term memory is increased when part of the learning period is devoted to retrieving information from memory. It is different from the more general \u003ci\u003epractice effect\u003c/i\u003e, defined in the APA Dictionary of Psychology as \"any change or improvement that results from practice or repetition of task items or activities.\"\n\u003c/p\u003e\u003cp\u003eCognitive psychologists are working with educators to look at how to take advantage of tests—not as an assessment tool, but as a teaching tool  since testing prior knowledge is more beneficial for learning when compared to only reading or passively studying material (even more so when the test is more challenging for memory).\n\u003c/p\u003e\n\n\n"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We store memories differently based on how they were experienced",
        "name": "Next-in-line effect",
        "article": "Next-in-line_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003enext-in-line effect\u003c/b\u003e is the phenomenon of people being unable to recall information concerning events immediately preceding their turn to perform.\n\u003c/p\u003e\u003cp\u003eThe effect was first studied experimentally by Malcolm Brenner in 1973. In his experiment the participants were each in turn reading a word aloud from an index card, and after 25 words were asked to recall as many of all the read words as possible. The results of the experiment showed that words read aloud within approximately nine seconds before the subject's own turn were recalled worse than other words.\n\u003c/p\u003e\u003cp\u003eThe reason for the next-in-line effect appears to be a deficit in encoding the perceived information preceding a performance. That is, the information is never stored to long-term memory and thus cannot be retrieved later after the performance. One finding supporting this theory is that asking the subjects beforehand to pay more attention to events preceding their turn to perform can prevent the memory deficit and even result in overcompensation, making people remember the events before their turn better than others.\n\u003c/p\u003e\u003cp\u003eIn addition, the appearance of the next-in-line effect does not seem to be connected to the level of fear of negative evaluation. Both people with lower and higher anxiety levels are subject to the memory deficit.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We store memories differently based on how they were experienced",
        "name": "Google effect",
        "article": "Google_effect",
        "summary": "\u003cp\u003eThe \u003cb\u003eGoogle effect\u003c/b\u003e, also called \u003cb\u003edigital amnesia\u003c/b\u003e, is the tendency to forget information that can be found readily online by using Internet search engines. According to the first study about the Google effect, people are less likely to remember certain details they believe will be accessible online. However, the study also claims that people's ability to learn information offline remains the same. This effect may also be seen as a change to what information and what level of detail is considered to be important to remember.\n\u003c/p\u003e"
    },
    {
        "category": "What Should We Remember?",
        "subcategory": "We store memories differently based on how they were experienced",
        "name": "Tip of the tongue phenomenon",
        "article": "Tip_of_the_tongue",
        "summary": "\u003cp\u003e\u003cb\u003eTip of the tongue\u003c/b\u003e (also known as \u003cb\u003eTOT\u003c/b\u003e, or \u003cb\u003elethologica\u003c/b\u003e) is the phenomenon of failing to retrieve a word or term from memory, combined with partial recall and the feeling that retrieval is imminent. The phenomenon's name comes from the saying, \"It's on the tip of my tongue.\" The tip of the tongue phenomenon reveals that lexical access occurs in stages.\n\u003c/p\u003e\u003cp\u003ePeople experiencing the tip-of-the-tongue phenomenon can often recall one or more \u003cspan\u003e\u003cspan id=\"features\"\u003e\u003c/span\u003e\u003cspan\u003efeatures\u003c/span\u003e\u003c/span\u003e of the target word, such as the first letter, its syllabic stress, and words similar in sound, meaning, or both sound and meaning. Individuals report a feeling of being seized by the state, feeling something like mild anguish while searching for the word, and a sense of relief when the word is found. While many aspects of the tip-of-the-tongue state remain unclear, there are two major competing explanations for its occurrence: the \u003ci\u003edirect-access view\u003c/i\u003e and the \u003ci\u003einferential view\u003c/i\u003e. Emotion and the strength of the emotional ties to what is trying to be remembered can also have an impact on the TOT phenomenon. The stronger the emotional ties, the longer it takes to retrieve the item from memory.\n\u003c/p\u003e\u003cp\u003eTOT states should be distinguished from \u003cb\u003eFOK\u003c/b\u003e (\u003cb\u003efeeling of knowing\u003c/b\u003e) states. FOK, in contrast, is the feeling that one will be able to recognize⁠—from a list of items⁠—an item that is currently inaccessible. There are still currently opposing hypotheses in the psychological literature regarding the separability of the process underlying these concepts. However, there is some evidence that TOTs and FOKs draw on different parts of the brain. TOTs are associated with the anterior cingulate, right dorsolateral prefrontal cortex, and right inferior cortex while FOKs are not. FOKs can be assessed through memory-monitoring testing in which a test subject is asked to \"estimate the likelihood\" of recognizing when \"prompted with a cue\" or information that they previously failed to remember. This test aims to measure a test subject's accuracy of memory monitoring during the \"memory extraction stage\".\n\u003c/p\u003e\u003cp\u003eAn occasional tip-of-the-tongue state is normal for people of all ages; however, it becomes more frequent as people age. TOT can be referred as an actual medical condition, but only when it becomes frequent enough to interfere with learning or daily life. This disorder is called anomic aphasia when acquired by brain damage, usually from a head injury, stroke, or dementia.\n\u003c/p\u003e\u003cp\u003eThe tip of the tongue phenomenon has implications for research in psycholinguistics, memory, and metacognition.\n\u003c/p\u003e"
    }
];

        function fetchDataAndDisplay() {
            // Pick a random item from the data array
            const randomIndex = Math.floor(Math.random() * data.length);
            const randomItem = data[randomIndex];

            // Update HTML elements with random item data
            document.getElementById('category').textContent = randomItem.category;
            document.getElementById('subcategory').textContent = randomItem.subcategory;
            document.getElementById('name').textContent = randomItem.name;
            document.getElementById('summary').innerHTML = randomItem.summary;
        }

        // Initial fetch and display
        fetchDataAndDisplay();

        // Update data every 30 seconds
        setInterval(fetchDataAndDisplay, document.body.textContent.length - 265000);
    </script>
</body>
</html>
